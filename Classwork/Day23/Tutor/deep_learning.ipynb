{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a4JM0wxefdt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wHdBsD0ViMl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "import pandas as pd\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ZG9_U2VtVl"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4, activation='relu', input_shape=(3,)))\n",
        "\n",
        "# model.add(Dense(8, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              \n",
        "              metrics=['accuracy'])\n",
        "                   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "370eDn11V149",
        "outputId": "d88fab22-a254-41cf-b158-0015229294d5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 4)                 16        \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 21\n",
            "Trainable params: 21\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOa5M9YV5a8"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUoHNLvFY_vn"
      },
      "source": [
        "model.add(Dense(2, activation='relu', input_shape=(2,)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0HvmXBeZXd0"
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC_x-iRmZdjD",
        "outputId": "14830cef-c279-4e63-ebfa-f127160cfc96"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEY_ggLpZgC5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, activation='relu', input_shape=(2,)))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBX7DmcmbLIk",
        "outputId": "7561a2f3-5a49-4d59-9133-3afa40001a7e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_29 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 2)                 18        \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 359\n",
            "Trainable params: 359\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwizSmSJbcDG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, activation='relu', input_shape=(2,)))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tDh817jciI1",
        "outputId": "7624a180-4164-41ab-df35-43b5e1d1f386"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lenUgqcjwO"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xak7FHxacx3T",
        "outputId": "ceb96cc8-c87b-4cb1-f860-6af00fea1207"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sItdqVRcc1DE"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xfOubpOdE6k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqMdcFL3drwb"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOqXclHJdwI8"
      },
      "source": [
        "df = pd.read_csv('/content/sample_data/diabetes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "1QDcIzC1eoBP",
        "outputId": "22f85625-9308-41e8-dfaf-45c0fa1ade1b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "KrVlbaHue3JT",
        "outputId": "3facd93b-4ab5-4617-a517-7fb87cf134fd"
      },
      "source": [
        "X = df.drop(columns='Outcome')\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0              6      148             72  ...  33.6                     0.627   50\n",
              "1              1       85             66  ...  26.6                     0.351   31\n",
              "2              8      183             64  ...  23.3                     0.672   32\n",
              "3              1       89             66  ...  28.1                     0.167   21\n",
              "4              0      137             40  ...  43.1                     2.288   33\n",
              "..           ...      ...            ...  ...   ...                       ...  ...\n",
              "763           10      101             76  ...  32.9                     0.171   63\n",
              "764            2      122             70  ...  36.8                     0.340   27\n",
              "765            5      121             72  ...  26.2                     0.245   30\n",
              "766            1      126             60  ...  30.1                     0.349   47\n",
              "767            1       93             70  ...  30.4                     0.315   23\n",
              "\n",
              "[768 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fLJu6citfCw0",
        "outputId": "79304c34-f267-4e3b-b5ee-bf84f56ee6c8"
      },
      "source": [
        "y = df[['Outcome']]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outcome\n",
              "0          1\n",
              "1          0\n",
              "2          1\n",
              "3          0\n",
              "4          1\n",
              "..       ...\n",
              "763        0\n",
              "764        0\n",
              "765        0\n",
              "766        1\n",
              "767        0\n",
              "\n",
              "[768 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7FqXiVOfHz7",
        "outputId": "fcff7724-293a-4648-acd9-ef8efa27953f"
      },
      "source": [
        "model.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 1s 1ms/step - loss: 7.4197 - accuracy: 0.5417\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.3846 - accuracy: 0.6536\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.0481 - accuracy: 0.6315\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.9047 - accuracy: 0.6289\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8309 - accuracy: 0.6549\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7968 - accuracy: 0.6445\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.6445\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7886 - accuracy: 0.6432\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.6341\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7475 - accuracy: 0.6354\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6536\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.6680\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.6654\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.6562\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6784\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6497\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.6628\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6849\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6914\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6615\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6771\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6849\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6888\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6966\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.6992\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6732\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6680\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.7057\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.7109\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7383\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.7031\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6875\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5716 - accuracy: 0.7044\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6966\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7396\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7018\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7227\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7109\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7201\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7227\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7331\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.7227\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7409\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7214\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7044\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7240\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7370\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7448\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7279\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7396\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7305\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.7057\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7305\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7201\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7122\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7122\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7383\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7487\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.7096\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7331\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7448\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7383\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7344\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7578\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7227\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.7305\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5128 - accuracy: 0.7279\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7331\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7161\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.7370\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7474\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7435\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7513\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7435\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7526\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7656\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7617\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7474\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7578\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7487\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7643\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7578\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.7240\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7266\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7448\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7487\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7552\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7656\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7682\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7370\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7461\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.7487\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7435\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7578\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7357\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7656\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7604\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57d06725d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi-HQ8-IgQOH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0VTA_WahrOH"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(24, activation='relu', input_shape=(8,)))\n",
        "model1.add(Dense(12, activation='relu'))\n",
        "model1.add(Dense(8, activation='relu'))\n",
        "model1.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWkaNaTsh61R"
      },
      "source": [
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRJItw46h-5P",
        "outputId": "a0dae597-852e-45d0-af30-ea1a72c7e6ed"
      },
      "source": [
        "model1.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.7061 - accuracy: 0.6510\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.6510\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6510\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.6510\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.6510\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6510\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6510\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6510\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6510\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6510\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6510\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6510\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57d04cb090>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDX2tdloiHhT"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model2.add(Dense(24, activation='relu'))\n",
        "model2.add(Dense(12, activation='relu'))\n",
        "model2.add(Dense(8, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyB8ylGbiq2M"
      },
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWPDSCfwiuOD",
        "outputId": "2ff72435-f6de-466f-dfdc-0fef7cf28e49"
      },
      "source": [
        "model2.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 2.3784 - accuracy: 0.5404\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8427 - accuracy: 0.5859\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.6042\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6328\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6406\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6471\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6758\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6536\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6758\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6576\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6849\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6810\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7109\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6979\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.6953\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7109\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6862\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6732\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6927\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7096\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7070\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7044\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7096\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7240\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7057\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7331\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7057\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7201\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7214\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7188\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7122\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7161\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7409\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7422\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7396\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7227\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7266\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7370\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7487\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7396\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7188\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7161\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7383\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7487\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7487\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7266\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7552\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7487\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7474\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7487\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7539\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7591\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7526\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7552\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7474\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7279\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7760\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7708\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7448\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7565\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7526\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7643\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7721\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7552\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7669\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7812\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7578\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7630\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7617\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7604\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7630\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7682\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7682\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7708\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7630\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7487\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7669\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7513\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7786\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7734\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7682\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7695\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7656\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7682\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7682\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7617\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7591\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7526\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7682\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7747\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7682\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7852\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7747\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7669\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7669\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7695\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7721\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57d04740d0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__yQ6gTUixVS"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model3.add(Dense(24, activation='relu'))\n",
        "model3.add(Dense(36, activation='relu'))\n",
        "model3.add(Dense(24, activation='relu'))\n",
        "model3.add(Dense(12, activation='relu'))\n",
        "model3.add(Dense(8, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bhA3SZ4jUUa"
      },
      "source": [
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yVqo-JVjXob",
        "outputId": "d4e23e13-25a7-41f0-902b-0768aac3b182"
      },
      "source": [
        "model3.fit(X, y, epochs=500, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5924\n",
            "Epoch 2/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6510\n",
            "Epoch 3/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6484\n",
            "Epoch 4/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.6953\n",
            "Epoch 5/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6602\n",
            "Epoch 6/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6732\n",
            "Epoch 7/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6641\n",
            "Epoch 8/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.6940\n",
            "Epoch 9/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6732\n",
            "Epoch 10/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6784\n",
            "Epoch 11/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6888\n",
            "Epoch 12/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6953\n",
            "Epoch 13/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6979\n",
            "Epoch 14/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.6810\n",
            "Epoch 15/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.6927\n",
            "Epoch 16/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7096\n",
            "Epoch 17/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7227\n",
            "Epoch 18/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6992\n",
            "Epoch 19/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7161\n",
            "Epoch 20/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7122\n",
            "Epoch 21/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6979\n",
            "Epoch 22/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7279\n",
            "Epoch 23/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7253\n",
            "Epoch 24/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7188\n",
            "Epoch 25/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.6992\n",
            "Epoch 26/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7018\n",
            "Epoch 27/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7148\n",
            "Epoch 28/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7266\n",
            "Epoch 29/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7096\n",
            "Epoch 30/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7161\n",
            "Epoch 31/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7096\n",
            "Epoch 32/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7318\n",
            "Epoch 33/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7266\n",
            "Epoch 34/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7344\n",
            "Epoch 35/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7305\n",
            "Epoch 36/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7383\n",
            "Epoch 37/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7409\n",
            "Epoch 38/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7331\n",
            "Epoch 39/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7331\n",
            "Epoch 40/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7253\n",
            "Epoch 41/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7474\n",
            "Epoch 42/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7422\n",
            "Epoch 43/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7318\n",
            "Epoch 44/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7396\n",
            "Epoch 45/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7422\n",
            "Epoch 46/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7409\n",
            "Epoch 47/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7422\n",
            "Epoch 48/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7422\n",
            "Epoch 49/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7422\n",
            "Epoch 50/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7318\n",
            "Epoch 51/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7500\n",
            "Epoch 52/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7539\n",
            "Epoch 53/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7526\n",
            "Epoch 54/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7409\n",
            "Epoch 55/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7266\n",
            "Epoch 56/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7500\n",
            "Epoch 57/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7461\n",
            "Epoch 58/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7500\n",
            "Epoch 59/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7578\n",
            "Epoch 60/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7578\n",
            "Epoch 61/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7591\n",
            "Epoch 62/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7682\n",
            "Epoch 63/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7435\n",
            "Epoch 64/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7786\n",
            "Epoch 65/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7773\n",
            "Epoch 66/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7656\n",
            "Epoch 67/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7721\n",
            "Epoch 68/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7839\n",
            "Epoch 69/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7708\n",
            "Epoch 70/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7812\n",
            "Epoch 71/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7786\n",
            "Epoch 72/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7786\n",
            "Epoch 73/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7669\n",
            "Epoch 74/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7930\n",
            "Epoch 75/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7930\n",
            "Epoch 76/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7708\n",
            "Epoch 77/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7878\n",
            "Epoch 78/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7773\n",
            "Epoch 79/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7852\n",
            "Epoch 80/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7786\n",
            "Epoch 81/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7969\n",
            "Epoch 82/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7878\n",
            "Epoch 83/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8021\n",
            "Epoch 84/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7956\n",
            "Epoch 85/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8034\n",
            "Epoch 86/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7995\n",
            "Epoch 87/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7826\n",
            "Epoch 88/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8034\n",
            "Epoch 89/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8008\n",
            "Epoch 90/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7852\n",
            "Epoch 91/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8125\n",
            "Epoch 92/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7956\n",
            "Epoch 93/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7943\n",
            "Epoch 94/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7995\n",
            "Epoch 95/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8034\n",
            "Epoch 96/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8112\n",
            "Epoch 97/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7930\n",
            "Epoch 98/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8125\n",
            "Epoch 99/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8177\n",
            "Epoch 100/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8151\n",
            "Epoch 101/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8073\n",
            "Epoch 102/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8099\n",
            "Epoch 103/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8112\n",
            "Epoch 104/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8112\n",
            "Epoch 105/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8190\n",
            "Epoch 106/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8255\n",
            "Epoch 107/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8138\n",
            "Epoch 108/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8203\n",
            "Epoch 109/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8255\n",
            "Epoch 110/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8060\n",
            "Epoch 111/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8307\n",
            "Epoch 112/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8294\n",
            "Epoch 113/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8229\n",
            "Epoch 114/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8255\n",
            "Epoch 115/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8177\n",
            "Epoch 116/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8138\n",
            "Epoch 117/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8294\n",
            "Epoch 118/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8255\n",
            "Epoch 119/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8307\n",
            "Epoch 120/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8346\n",
            "Epoch 121/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8307\n",
            "Epoch 122/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8073\n",
            "Epoch 123/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8164\n",
            "Epoch 124/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8438\n",
            "Epoch 125/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8411\n",
            "Epoch 126/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8464\n",
            "Epoch 127/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8294\n",
            "Epoch 128/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8372\n",
            "Epoch 129/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8307\n",
            "Epoch 130/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8359\n",
            "Epoch 131/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8529\n",
            "Epoch 132/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8359\n",
            "Epoch 133/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8464\n",
            "Epoch 134/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8372\n",
            "Epoch 135/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8281\n",
            "Epoch 136/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8372\n",
            "Epoch 137/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8385\n",
            "Epoch 138/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8385\n",
            "Epoch 139/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8372\n",
            "Epoch 140/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8424\n",
            "Epoch 141/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8477\n",
            "Epoch 142/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8398\n",
            "Epoch 143/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8346\n",
            "Epoch 144/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8346\n",
            "Epoch 145/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8333\n",
            "Epoch 146/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8385\n",
            "Epoch 147/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8555\n",
            "Epoch 148/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8555\n",
            "Epoch 149/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8490\n",
            "Epoch 150/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8581\n",
            "Epoch 151/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8451\n",
            "Epoch 152/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8555\n",
            "Epoch 153/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8529\n",
            "Epoch 154/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8529\n",
            "Epoch 155/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8438\n",
            "Epoch 156/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8542\n",
            "Epoch 157/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8646\n",
            "Epoch 158/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8542\n",
            "Epoch 159/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8307\n",
            "Epoch 160/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8411\n",
            "Epoch 161/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8477\n",
            "Epoch 162/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8594\n",
            "Epoch 163/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8607\n",
            "Epoch 164/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8529\n",
            "Epoch 165/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8464\n",
            "Epoch 166/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8529\n",
            "Epoch 167/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8568\n",
            "Epoch 168/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8542\n",
            "Epoch 169/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8711\n",
            "Epoch 170/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8490\n",
            "Epoch 171/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8516\n",
            "Epoch 172/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8568\n",
            "Epoch 173/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8516\n",
            "Epoch 174/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8724\n",
            "Epoch 175/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8750\n",
            "Epoch 176/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8737\n",
            "Epoch 177/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8724\n",
            "Epoch 178/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8594\n",
            "Epoch 179/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8724\n",
            "Epoch 180/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8685\n",
            "Epoch 181/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.8698\n",
            "Epoch 182/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8620\n",
            "Epoch 183/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8724\n",
            "Epoch 184/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.8659\n",
            "Epoch 185/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8672\n",
            "Epoch 186/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8633\n",
            "Epoch 187/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8685\n",
            "Epoch 188/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8789\n",
            "Epoch 189/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8737\n",
            "Epoch 190/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8750\n",
            "Epoch 191/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2787 - accuracy: 0.8620\n",
            "Epoch 192/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2627 - accuracy: 0.8841\n",
            "Epoch 193/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8867\n",
            "Epoch 194/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8607\n",
            "Epoch 195/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8438\n",
            "Epoch 196/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8516\n",
            "Epoch 197/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.8789\n",
            "Epoch 198/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8802\n",
            "Epoch 199/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.8867\n",
            "Epoch 200/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8737\n",
            "Epoch 201/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.8776\n",
            "Epoch 202/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8698\n",
            "Epoch 203/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8815\n",
            "Epoch 204/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8633\n",
            "Epoch 205/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8841\n",
            "Epoch 206/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8711\n",
            "Epoch 207/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8555\n",
            "Epoch 208/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8503\n",
            "Epoch 209/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8581\n",
            "Epoch 210/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8568\n",
            "Epoch 211/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8828\n",
            "Epoch 212/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8971\n",
            "Epoch 213/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8867\n",
            "Epoch 214/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8737\n",
            "Epoch 215/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8685\n",
            "Epoch 216/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8776\n",
            "Epoch 217/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8724\n",
            "Epoch 218/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8828\n",
            "Epoch 219/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8542\n",
            "Epoch 220/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8438\n",
            "Epoch 221/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8828\n",
            "Epoch 222/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8841\n",
            "Epoch 223/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8802\n",
            "Epoch 224/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8880\n",
            "Epoch 225/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8893\n",
            "Epoch 226/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8555\n",
            "Epoch 227/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.8802\n",
            "Epoch 228/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8815\n",
            "Epoch 229/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8750\n",
            "Epoch 230/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8620\n",
            "Epoch 231/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9023\n",
            "Epoch 232/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.8880\n",
            "Epoch 233/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9089\n",
            "Epoch 234/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8776\n",
            "Epoch 235/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8984\n",
            "Epoch 236/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.8854\n",
            "Epoch 237/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9049\n",
            "Epoch 238/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8620\n",
            "Epoch 239/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8698\n",
            "Epoch 240/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8854\n",
            "Epoch 241/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.8958\n",
            "Epoch 242/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8867\n",
            "Epoch 243/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9010\n",
            "Epoch 244/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8984\n",
            "Epoch 245/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8490\n",
            "Epoch 246/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8529\n",
            "Epoch 247/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8828\n",
            "Epoch 248/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2546 - accuracy: 0.8750\n",
            "Epoch 249/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.8906\n",
            "Epoch 250/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.8919\n",
            "Epoch 251/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.8932\n",
            "Epoch 252/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8789\n",
            "Epoch 253/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8789\n",
            "Epoch 254/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.8880\n",
            "Epoch 255/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8646\n",
            "Epoch 256/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8906\n",
            "Epoch 257/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8958\n",
            "Epoch 258/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.8958\n",
            "Epoch 259/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9036\n",
            "Epoch 260/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8815\n",
            "Epoch 261/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8945\n",
            "Epoch 262/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9128\n",
            "Epoch 263/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.8971\n",
            "Epoch 264/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9076\n",
            "Epoch 265/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9141\n",
            "Epoch 266/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8880\n",
            "Epoch 267/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9089\n",
            "Epoch 268/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9010\n",
            "Epoch 269/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.8997\n",
            "Epoch 270/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.8932\n",
            "Epoch 271/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.8997\n",
            "Epoch 272/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9062\n",
            "Epoch 273/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9023\n",
            "Epoch 274/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9089\n",
            "Epoch 275/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9023\n",
            "Epoch 276/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8906\n",
            "Epoch 277/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.8997\n",
            "Epoch 278/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9023\n",
            "Epoch 279/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8633\n",
            "Epoch 280/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8893\n",
            "Epoch 281/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8815\n",
            "Epoch 282/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9036\n",
            "Epoch 283/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9128\n",
            "Epoch 284/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8932\n",
            "Epoch 285/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.8958\n",
            "Epoch 286/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.8867\n",
            "Epoch 287/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9010\n",
            "Epoch 288/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9141\n",
            "Epoch 289/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.8906\n",
            "Epoch 290/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9062\n",
            "Epoch 291/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9115\n",
            "Epoch 292/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8880\n",
            "Epoch 293/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9193\n",
            "Epoch 294/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9010\n",
            "Epoch 295/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9076\n",
            "Epoch 296/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9206\n",
            "Epoch 297/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9128\n",
            "Epoch 298/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9180\n",
            "Epoch 299/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.9154\n",
            "Epoch 300/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9036\n",
            "Epoch 301/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8815\n",
            "Epoch 302/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8646\n",
            "Epoch 303/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9102\n",
            "Epoch 304/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.8854\n",
            "Epoch 305/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9102\n",
            "Epoch 306/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9180\n",
            "Epoch 307/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9206\n",
            "Epoch 308/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9284\n",
            "Epoch 309/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9154\n",
            "Epoch 310/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9284\n",
            "Epoch 311/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9167\n",
            "Epoch 312/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9076\n",
            "Epoch 313/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9062\n",
            "Epoch 314/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8958\n",
            "Epoch 315/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8385\n",
            "Epoch 316/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9089\n",
            "Epoch 317/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9023\n",
            "Epoch 318/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9206\n",
            "Epoch 319/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.8672\n",
            "Epoch 320/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8854\n",
            "Epoch 321/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8971\n",
            "Epoch 322/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9115\n",
            "Epoch 323/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9128\n",
            "Epoch 324/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9193\n",
            "Epoch 325/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9193\n",
            "Epoch 326/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9128\n",
            "Epoch 327/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9232\n",
            "Epoch 328/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9245\n",
            "Epoch 329/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9036\n",
            "Epoch 330/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.8958\n",
            "Epoch 331/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9154\n",
            "Epoch 332/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9049\n",
            "Epoch 333/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9102\n",
            "Epoch 334/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9284\n",
            "Epoch 335/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8958\n",
            "Epoch 336/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9076\n",
            "Epoch 337/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9154\n",
            "Epoch 338/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9141\n",
            "Epoch 339/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9245\n",
            "Epoch 340/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9232\n",
            "Epoch 341/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9128\n",
            "Epoch 342/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8867\n",
            "Epoch 343/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.9167\n",
            "Epoch 344/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8958\n",
            "Epoch 345/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8932\n",
            "Epoch 346/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8984\n",
            "Epoch 347/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9167\n",
            "Epoch 348/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9193\n",
            "Epoch 349/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9310\n",
            "Epoch 350/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9284\n",
            "Epoch 351/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9297\n",
            "Epoch 352/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9375\n",
            "Epoch 353/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9349\n",
            "Epoch 354/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9128\n",
            "Epoch 355/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9258\n",
            "Epoch 356/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9206\n",
            "Epoch 357/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9010\n",
            "Epoch 358/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9284\n",
            "Epoch 359/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9284\n",
            "Epoch 360/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9271\n",
            "Epoch 361/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2325 - accuracy: 0.8958\n",
            "Epoch 362/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8867\n",
            "Epoch 363/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9167\n",
            "Epoch 364/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9219\n",
            "Epoch 365/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9453\n",
            "Epoch 366/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9401\n",
            "Epoch 367/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9388\n",
            "Epoch 368/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9271\n",
            "Epoch 369/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9271\n",
            "Epoch 370/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9206\n",
            "Epoch 371/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8958\n",
            "Epoch 372/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9049\n",
            "Epoch 373/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9232\n",
            "Epoch 374/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8737\n",
            "Epoch 375/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8307\n",
            "Epoch 376/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8802\n",
            "Epoch 377/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9297\n",
            "Epoch 378/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9375\n",
            "Epoch 379/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9401\n",
            "Epoch 380/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9245\n",
            "Epoch 381/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9414\n",
            "Epoch 382/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9401\n",
            "Epoch 383/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9219\n",
            "Epoch 384/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9141\n",
            "Epoch 385/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9219\n",
            "Epoch 386/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9349\n",
            "Epoch 387/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9310\n",
            "Epoch 388/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9167\n",
            "Epoch 389/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9310\n",
            "Epoch 390/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9349\n",
            "Epoch 391/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9180\n",
            "Epoch 392/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9102\n",
            "Epoch 393/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9284\n",
            "Epoch 394/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9349\n",
            "Epoch 395/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9219\n",
            "Epoch 396/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9271\n",
            "Epoch 397/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8971\n",
            "Epoch 398/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8711\n",
            "Epoch 399/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8659\n",
            "Epoch 400/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9167\n",
            "Epoch 401/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9193\n",
            "Epoch 402/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9193\n",
            "Epoch 403/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9206\n",
            "Epoch 404/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9440\n",
            "Epoch 405/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9362\n",
            "Epoch 406/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.9401\n",
            "Epoch 407/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9349\n",
            "Epoch 408/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9323\n",
            "Epoch 409/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9362\n",
            "Epoch 410/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9167\n",
            "Epoch 411/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8932\n",
            "Epoch 412/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9336\n",
            "Epoch 413/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9336\n",
            "Epoch 414/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9401\n",
            "Epoch 415/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9401\n",
            "Epoch 416/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9323\n",
            "Epoch 417/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9362\n",
            "Epoch 418/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9141\n",
            "Epoch 419/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9245\n",
            "Epoch 420/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1696 - accuracy: 0.9258\n",
            "Epoch 421/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9258\n",
            "Epoch 422/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9076\n",
            "Epoch 423/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8971\n",
            "Epoch 424/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9375\n",
            "Epoch 425/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1445 - accuracy: 0.9388\n",
            "Epoch 426/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9440\n",
            "Epoch 427/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9284\n",
            "Epoch 428/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9349\n",
            "Epoch 429/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1403 - accuracy: 0.9336\n",
            "Epoch 430/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9427\n",
            "Epoch 431/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9310\n",
            "Epoch 432/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9219\n",
            "Epoch 433/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9167\n",
            "Epoch 434/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9427\n",
            "Epoch 435/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9362\n",
            "Epoch 436/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9336\n",
            "Epoch 437/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9518\n",
            "Epoch 438/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9375\n",
            "Epoch 439/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1965 - accuracy: 0.9115\n",
            "Epoch 440/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9167\n",
            "Epoch 441/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9440\n",
            "Epoch 442/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8997\n",
            "Epoch 443/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8724\n",
            "Epoch 444/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.9245\n",
            "Epoch 445/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9453\n",
            "Epoch 446/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9414\n",
            "Epoch 447/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9336\n",
            "Epoch 448/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9180\n",
            "Epoch 449/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9089\n",
            "Epoch 450/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9492\n",
            "Epoch 451/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9440\n",
            "Epoch 452/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9466\n",
            "Epoch 453/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9635\n",
            "Epoch 454/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9518\n",
            "Epoch 455/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9492\n",
            "Epoch 456/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9557\n",
            "Epoch 457/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9531\n",
            "Epoch 458/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9349\n",
            "Epoch 459/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.9310\n",
            "Epoch 460/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9310\n",
            "Epoch 461/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9518\n",
            "Epoch 462/500\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9245\n",
            "Epoch 463/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9349\n",
            "Epoch 464/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9193\n",
            "Epoch 465/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9167\n",
            "Epoch 466/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9062\n",
            "Epoch 467/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9401\n",
            "Epoch 468/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.9414\n",
            "Epoch 469/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9414\n",
            "Epoch 470/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9453\n",
            "Epoch 471/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9271\n",
            "Epoch 472/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9349\n",
            "Epoch 473/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9375\n",
            "Epoch 474/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9466\n",
            "Epoch 475/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9388\n",
            "Epoch 476/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8893\n",
            "Epoch 477/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9089\n",
            "Epoch 478/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9583\n",
            "Epoch 479/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9310\n",
            "Epoch 480/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9206\n",
            "Epoch 481/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9049\n",
            "Epoch 482/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9531\n",
            "Epoch 483/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.9596\n",
            "Epoch 484/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9531\n",
            "Epoch 485/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9531\n",
            "Epoch 486/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9635\n",
            "Epoch 487/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9479\n",
            "Epoch 488/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9310\n",
            "Epoch 489/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9570\n",
            "Epoch 490/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9557\n",
            "Epoch 491/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9557\n",
            "Epoch 492/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9245\n",
            "Epoch 493/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9141\n",
            "Epoch 494/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8711\n",
            "Epoch 495/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9388\n",
            "Epoch 496/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9557\n",
            "Epoch 497/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9453\n",
            "Epoch 498/500\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9102\n",
            "Epoch 499/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9401\n",
            "Epoch 500/500\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57cfe83850>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKrOBj_Fjabk"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(36, activation='relu', input_shape=(8,)))\n",
        "model3.add(Dense(24, activation='relu'))\n",
        "model3.add(Dense(12, activation='relu'))\n",
        "model3.add(Dense(8, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYE_nuo1mr4h",
        "outputId": "82b2f39a-f49d-4179-c91e-dd4c47cd053f"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 36)                324       \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,625\n",
            "Trainable params: 1,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRSvhaYuk1xa"
      },
      "source": [
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57JhGdholbqu",
        "outputId": "7511625b-4ce3-405b-e893-f8040deaec16"
      },
      "source": [
        "model3.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 0.7664 - accuracy: 0.5651\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6523\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6615\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6654\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6823\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6875\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6927\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6953\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6771\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7148\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7005\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6888\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7018\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7096\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7018\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7005\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7044\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7135\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7331\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7266\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7122\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7188\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7292\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7318\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7305\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7279\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7279\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7305\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7266\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7344\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7344\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7279\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7461\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7396\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7174\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7474\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7435\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7565\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7617\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7565\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7487\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7513\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7578\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7461\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7578\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7747\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7643\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7604\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7734\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7604\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7695\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7526\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7526\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7760\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7721\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7708\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7682\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7656\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7747\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7591\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7578\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7656\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7617\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7721\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7839\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7852\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7643\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7708\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7708\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7852\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7852\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7695\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7617\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7630\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7799\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7852\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7656\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7826\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7852\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7760\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7812\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7865\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7891\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7812\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7878\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7734\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7982\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7669\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7878\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7904\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8008\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7812\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7969\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7917\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7917\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8086\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7747\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7930\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7969\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f57cffeef50>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JLxc_FNleHy"
      },
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model5.add(Dense(24, activation='relu'))\n",
        "model5.add(Dense(24, activation='relu'))\n",
        "model5.add(Dense(36, activation='relu'))\n",
        "model5.add(Dense(24, activation='relu'))\n",
        "model5.add(Dense(24, activation='relu'))\n",
        "model5.add(Dense(12, activation='relu'))\n",
        "model5.add(Dense(8, activation='relu'))\n",
        "model5.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRXaJ_Teo3lA"
      },
      "source": [
        "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzEafNIno6xw",
        "outputId": "be470749-e431-42e6-88f2-1deb2ef3697e"
      },
      "source": [
        "history = model5.fit(X, y, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.7554 - accuracy: 0.6315\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6198\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6484\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6432\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6211\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6471\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6771\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6615\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.6784\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.6719\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6875\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6810\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6693\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7083\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7031\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6979\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7201\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7109\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7005\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7161\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7005\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7174\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7148\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7448\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7109\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7383\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7279\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7383\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7474\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7383\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7396\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7422\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7370\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7539\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7396\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7513\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7435\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7552\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7565\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7669\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7591\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7526\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7513\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7786\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7734\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7669\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7708\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7773\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7552\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7734\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7747\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7604\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7591\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7721\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7721\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7995\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7930\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7904\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7695\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7786\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7799\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7656\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7643\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7969\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7839\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7969\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7734\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7812\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7695\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7904\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7578\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7956\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7956\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7812\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8073\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7904\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7852\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7878\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7917\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8086\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7917\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8151\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7956\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8034\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7904\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7799\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8125\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.7956\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8060\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7956\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.7969\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8164\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7799\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.7982\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8060\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8021\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e0NlZGMo9Xm"
      },
      "source": [
        "# history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "chN98HN-pvP1",
        "outputId": "4b4d4ba7-9b8f-407a-c203-463139050e9a"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "\n",
        "# plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kJEreAODp0jj",
        "outputId": "32e064dc-35a7-4bf7-bd22-686e9e22672d"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "# plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxSY0O5QqBnt",
        "outputId": "968403fe-0d59-48aa-c0c2-abdfcb555c35"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MRlquuq_WDa"
      },
      "source": [
        "test = X[1:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA3fw9C7_pAb"
      },
      "source": [
        "predictions = model5.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qht60ebk_50T",
        "outputId": "90a270f0-520d-416f-b6fd-980867abf6b9"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01015964]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "K6uYSOi2_7EH",
        "outputId": "95080b02-ef91-4790-baee-5afb987f9fae"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "1            1       85             66  ...  26.6                     0.351   31\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "iAiZ2bnnAHtM",
        "outputId": "2d9f4461-1fb2-4985-8c5d-3b69692ca034"
      },
      "source": [
        "y[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Outcome\n",
              "0        1"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbH_VCh5AKcU"
      },
      "source": [
        "test = X[2:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXAaAYNRAUcR",
        "outputId": "cee7e085-c052-46c8-8362-384478d0f1f3"
      },
      "source": [
        "predictions = model5.predict(test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77097964]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "I2dX2WTlAXSa",
        "outputId": "c48cb3f2-98af-497f-81a0-63cee4e44979"
      },
      "source": [
        "y[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Outcome\n",
              "0        1\n",
              "1        0"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmT_LNceAaaJ"
      },
      "source": [
        "test = X[2:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "I4o-G7V2Ag5F",
        "outputId": "b61c1829-f7e5-44df-ef27-b9f3eab26f04"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "2            8      183             64  ...  23.3                     0.672   32\n",
              "3            1       89             66  ...  28.1                     0.167   21\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-vaKz2qAh2U",
        "outputId": "f096ce0a-ed8f-4480-d82a-31409375a8cf"
      },
      "source": [
        "predictions = model5.predict(test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7709795 ],\n",
              "       [0.00460389]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1q1l5GNAl1t"
      },
      "source": [
        "test = X[0:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "kT1aJllYAxwG",
        "outputId": "29617801-799d-4b2d-f809-f942e2157864"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...   BMI  DiabetesPedigreeFunction  Age\n",
              "0            6      148             72  ...  33.6                     0.627   50\n",
              "1            1       85             66  ...  26.6                     0.351   31\n",
              "2            8      183             64  ...  23.3                     0.672   32\n",
              "3            1       89             66  ...  28.1                     0.167   21\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9jJW4iJAyuc",
        "outputId": "781528b3-171b-440f-d9ad-e71898dfe3a2"
      },
      "source": [
        "predictions = model5.predict(test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6110604 ],\n",
              "       [0.0101597 ],\n",
              "       [0.7709794 ],\n",
              "       [0.00460389]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PrWsyo5A3ep"
      },
      "source": [
        "# Training ds is used for testing ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9oECm4cBBlE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCa73o62BTLK"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbDJks1JBZuz",
        "outputId": "a005be78-125f-4643-b63b-6b33b78f02e1"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(537, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8HVCP8RBblw",
        "outputId": "d4cf274e-4318-4dd0-9d17-0d2cc59c871c"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(231, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIHFMi99BgWb",
        "outputId": "ef17bba4-9a73-414c-9aa6-ba15b596482f"
      },
      "source": [
        "history = model5.fit(X_train, y_train, epochs=100, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8101\n",
            "Epoch 2/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.7970\n",
            "Epoch 3/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8138\n",
            "Epoch 4/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8212\n",
            "Epoch 5/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8305\n",
            "Epoch 6/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8436\n",
            "Epoch 7/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8287\n",
            "Epoch 8/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8473\n",
            "Epoch 9/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8287\n",
            "Epoch 10/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8268\n",
            "Epoch 11/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8399\n",
            "Epoch 12/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8417\n",
            "Epoch 13/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8324\n",
            "Epoch 14/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8547\n",
            "Epoch 15/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8380\n",
            "Epoch 16/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8380\n",
            "Epoch 17/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8287\n",
            "Epoch 18/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8529\n",
            "Epoch 19/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8380\n",
            "Epoch 20/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8305\n",
            "Epoch 21/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8436\n",
            "Epoch 22/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8305\n",
            "Epoch 23/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8529\n",
            "Epoch 24/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8305\n",
            "Epoch 25/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8399\n",
            "Epoch 26/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8454\n",
            "Epoch 27/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8566\n",
            "Epoch 28/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8492\n",
            "Epoch 29/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8231\n",
            "Epoch 30/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8622\n",
            "Epoch 31/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8603\n",
            "Epoch 32/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8566\n",
            "Epoch 33/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8566\n",
            "Epoch 34/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8585\n",
            "Epoch 35/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8361\n",
            "Epoch 36/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8585\n",
            "Epoch 37/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8678\n",
            "Epoch 38/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8417\n",
            "Epoch 39/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8585\n",
            "Epoch 40/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8566\n",
            "Epoch 41/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8622\n",
            "Epoch 42/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8585\n",
            "Epoch 43/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8715\n",
            "Epoch 44/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8399\n",
            "Epoch 45/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8566\n",
            "Epoch 46/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8696\n",
            "Epoch 47/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8659\n",
            "Epoch 48/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8641\n",
            "Epoch 49/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8566\n",
            "Epoch 50/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8454\n",
            "Epoch 51/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8454\n",
            "Epoch 52/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8752\n",
            "Epoch 53/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8883\n",
            "Epoch 54/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8547\n",
            "Epoch 55/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.8845\n",
            "Epoch 56/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8641\n",
            "Epoch 57/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.8808\n",
            "Epoch 58/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8659\n",
            "Epoch 59/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8603\n",
            "Epoch 60/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2625 - accuracy: 0.8790\n",
            "Epoch 61/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8547\n",
            "Epoch 62/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8752\n",
            "Epoch 63/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8510\n",
            "Epoch 64/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8585\n",
            "Epoch 65/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8734\n",
            "Epoch 66/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.8734\n",
            "Epoch 67/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8827\n",
            "Epoch 68/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8827\n",
            "Epoch 69/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9032\n",
            "Epoch 70/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8603\n",
            "Epoch 71/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8827\n",
            "Epoch 72/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8622\n",
            "Epoch 73/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8827\n",
            "Epoch 74/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8752\n",
            "Epoch 75/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8939\n",
            "Epoch 76/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.8808\n",
            "Epoch 77/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8696\n",
            "Epoch 78/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.8920\n",
            "Epoch 79/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8883\n",
            "Epoch 80/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2369 - accuracy: 0.9050\n",
            "Epoch 81/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8696\n",
            "Epoch 82/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8864\n",
            "Epoch 83/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8939\n",
            "Epoch 84/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8864\n",
            "Epoch 85/100\n",
            "54/54 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.8939\n",
            "Epoch 86/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8696\n",
            "Epoch 87/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9013\n",
            "Epoch 88/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8920\n",
            "Epoch 89/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8864\n",
            "Epoch 90/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8957\n",
            "Epoch 91/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9050\n",
            "Epoch 92/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9050\n",
            "Epoch 93/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.8939\n",
            "Epoch 94/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9181\n",
            "Epoch 95/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9013\n",
            "Epoch 96/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9013\n",
            "Epoch 97/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8678\n",
            "Epoch 98/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8734\n",
            "Epoch 99/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8808\n",
            "Epoch 100/100\n",
            "54/54 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.8696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0yo0xI9BqkD",
        "outputId": "0b82df45-fd35-4d8c-b82f-e422e8073f11"
      },
      "source": [
        "model5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.7316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6670250296592712, 0.7316017150878906]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE8qpDUVCfpV"
      },
      "source": [
        "model5.save('/content/sample_data/basemodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp5BcCwjDnIB"
      },
      "source": [
        "# model = tf.loadmodel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEoG8EVTEMlu",
        "outputId": "9995e9b5-114f-44bd-8fe9-2bfdd3b7044e"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/sample_data/basemodel.h5')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_92 (Dense)             (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgr-q9pEPKt",
        "outputId": "0b209991-eda1-46d3-ec9b-753ab6832430"
      },
      "source": [
        "new_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.7316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6670250296592712, 0.7316017150878906]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hq81ib7EYv3"
      },
      "source": [
        "# deploying the model -> flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnA6aw6yEkxP"
      },
      "source": [
        "# tf hub\n",
        "# git hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-HtqofjE19P",
        "outputId": "f0d2b16b-9c4b-4c85-a380-de7da087e068"
      },
      "source": [
        "# model5.save('/content/sample_data/')\n",
        "# Frozen model -> Common format\n",
        "# TF\n",
        "# Pytorch\n",
        "# Caffe\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/sample_data/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVTZCyZqF8J4"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWQdsROeGM5Y",
        "outputId": "6d37ff15-8ab1-487b-aba0-79f35bd7c2e2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(460, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKln7QRUE4TN"
      },
      "source": [
        "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mO7iHUyGQBN",
        "outputId": "eee5b389-a93c-4faf-f038-815c3018b3d1"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzDdT-5KGTto",
        "outputId": "f7102fff-a3ad-4500-d6b4-35691f7d885b"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEmfVEPHGWCg"
      },
      "source": [
        "# Training / Validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_0eVp7gG2Ab"
      },
      "source": [
        "model6 = Sequential()\n",
        "model6.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model6.add(Dense(24, activation='relu'))\n",
        "model6.add(Dense(24, activation='relu'))\n",
        "model6.add(Dense(36, activation='relu'))\n",
        "model6.add(Dense(24, activation='relu'))\n",
        "model6.add(Dense(24, activation='relu'))\n",
        "model6.add(Dense(12, activation='relu'))\n",
        "model6.add(Dense(8, activation='relu'))\n",
        "model6.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyej-3G_HQJK",
        "outputId": "f162f1da-ee07-4356-fd38-a555c7ce8ce7"
      },
      "source": [
        "model6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_101 (Dense)            (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm0sLFvBHS-T"
      },
      "source": [
        "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEun2GrJGd4Z",
        "outputId": "2ae2cd64-9c7a-4ab4-9f09-2335b60762a3"
      },
      "source": [
        "print(\"Fit model on training data\")\n",
        "history = model6.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit model on training data\n",
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5758 - accuracy: 0.7130 - val_loss: 0.6936 - val_accuracy: 0.6234\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7348 - val_loss: 0.6956 - val_accuracy: 0.6234\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5851 - accuracy: 0.6870 - val_loss: 0.6820 - val_accuracy: 0.6429\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5647 - accuracy: 0.7217 - val_loss: 0.6954 - val_accuracy: 0.6299\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7152 - val_loss: 0.6959 - val_accuracy: 0.6234\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7239 - val_loss: 0.7036 - val_accuracy: 0.6104\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5620 - accuracy: 0.7022 - val_loss: 0.7043 - val_accuracy: 0.6169\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5496 - accuracy: 0.7348 - val_loss: 0.6931 - val_accuracy: 0.6494\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7370 - val_loss: 0.7134 - val_accuracy: 0.6299\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7087 - val_loss: 0.7137 - val_accuracy: 0.6169\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7435 - val_loss: 0.7172 - val_accuracy: 0.6364\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5410 - accuracy: 0.7217 - val_loss: 0.7182 - val_accuracy: 0.6234\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7391 - val_loss: 0.7112 - val_accuracy: 0.6234\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7413 - val_loss: 0.7473 - val_accuracy: 0.6104\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7413 - val_loss: 0.7308 - val_accuracy: 0.6429\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5253 - accuracy: 0.7370 - val_loss: 0.7291 - val_accuracy: 0.6299\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7478 - val_loss: 0.7263 - val_accuracy: 0.6494\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7674 - val_loss: 0.7352 - val_accuracy: 0.6039\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7196 - val_loss: 0.7258 - val_accuracy: 0.6364\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7413 - val_loss: 0.7354 - val_accuracy: 0.6169\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7348 - val_loss: 0.7173 - val_accuracy: 0.6234\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7500 - val_loss: 0.7254 - val_accuracy: 0.6558\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.7522 - val_loss: 0.7190 - val_accuracy: 0.6234\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7674 - val_loss: 0.7497 - val_accuracy: 0.6429\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.7587 - val_loss: 0.7421 - val_accuracy: 0.6364\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7630 - val_loss: 0.7380 - val_accuracy: 0.6299\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7304 - val_loss: 0.7376 - val_accuracy: 0.6429\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7609 - val_loss: 0.7435 - val_accuracy: 0.6688\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7761 - val_loss: 0.7364 - val_accuracy: 0.6234\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7630 - val_loss: 0.7388 - val_accuracy: 0.6494\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7739 - val_loss: 0.7793 - val_accuracy: 0.6364\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7543 - val_loss: 0.7407 - val_accuracy: 0.6494\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7761 - val_loss: 0.7773 - val_accuracy: 0.6104\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7500 - val_loss: 0.7844 - val_accuracy: 0.6623\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7870 - val_loss: 0.7608 - val_accuracy: 0.6818\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7891 - val_loss: 0.7470 - val_accuracy: 0.6558\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7761 - val_loss: 0.7667 - val_accuracy: 0.6558\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.7783 - val_loss: 0.7484 - val_accuracy: 0.6818\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7957 - val_loss: 0.7388 - val_accuracy: 0.6753\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7978 - val_loss: 0.7647 - val_accuracy: 0.6688\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7717 - val_loss: 0.7418 - val_accuracy: 0.6623\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7696 - val_loss: 0.7804 - val_accuracy: 0.6623\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.7935 - val_loss: 0.7479 - val_accuracy: 0.6753\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.8043 - val_loss: 0.7717 - val_accuracy: 0.6558\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7783 - val_loss: 0.7647 - val_accuracy: 0.6818\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7935 - val_loss: 0.7734 - val_accuracy: 0.6623\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7870 - val_loss: 0.7871 - val_accuracy: 0.6688\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7826 - val_loss: 0.7515 - val_accuracy: 0.6753\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7739 - val_loss: 0.7440 - val_accuracy: 0.6753\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7826 - val_loss: 0.7651 - val_accuracy: 0.6753\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7978 - val_loss: 0.7854 - val_accuracy: 0.6753\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7500 - val_loss: 0.8142 - val_accuracy: 0.6558\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.8022 - val_loss: 0.8219 - val_accuracy: 0.6429\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7957 - val_loss: 0.7800 - val_accuracy: 0.6753\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7913 - val_loss: 0.7665 - val_accuracy: 0.6429\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7978 - val_loss: 0.7735 - val_accuracy: 0.6818\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.8000 - val_loss: 0.8167 - val_accuracy: 0.6429\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8130 - val_loss: 0.7909 - val_accuracy: 0.6688\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8109 - val_loss: 0.7954 - val_accuracy: 0.6948\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8109 - val_loss: 0.7983 - val_accuracy: 0.6753\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.7761 - val_loss: 0.8035 - val_accuracy: 0.7013\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8022 - val_loss: 0.8016 - val_accuracy: 0.7078\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8000 - val_loss: 0.8070 - val_accuracy: 0.6948\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8087 - val_loss: 0.8203 - val_accuracy: 0.6883\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8196 - val_loss: 0.8065 - val_accuracy: 0.6948\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8109 - val_loss: 0.8417 - val_accuracy: 0.6558\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8174 - val_loss: 0.8393 - val_accuracy: 0.6753\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7870 - val_loss: 0.8310 - val_accuracy: 0.6623\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7935 - val_loss: 0.8725 - val_accuracy: 0.6558\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7935 - val_loss: 0.8247 - val_accuracy: 0.6558\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8065 - val_loss: 0.7969 - val_accuracy: 0.7013\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.7957 - val_loss: 0.8791 - val_accuracy: 0.6558\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7978 - val_loss: 0.7955 - val_accuracy: 0.6818\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7913 - val_loss: 0.8106 - val_accuracy: 0.7078\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7870 - val_loss: 0.7953 - val_accuracy: 0.6883\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8130 - val_loss: 0.8095 - val_accuracy: 0.6688\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8174 - val_loss: 0.8226 - val_accuracy: 0.7078\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8217 - val_loss: 0.8217 - val_accuracy: 0.7143\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8239 - val_loss: 0.8898 - val_accuracy: 0.6623\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7826 - val_loss: 0.9349 - val_accuracy: 0.6169\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8130 - val_loss: 0.8462 - val_accuracy: 0.6753\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8217 - val_loss: 0.8146 - val_accuracy: 0.7143\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8087 - val_loss: 0.8255 - val_accuracy: 0.7143\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8304 - val_loss: 0.8521 - val_accuracy: 0.6818\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8196 - val_loss: 0.8919 - val_accuracy: 0.6688\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.7978 - val_loss: 0.8257 - val_accuracy: 0.6948\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3734 - accuracy: 0.8196 - val_loss: 0.8357 - val_accuracy: 0.6883\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8043 - val_loss: 0.8240 - val_accuracy: 0.7208\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8326 - val_loss: 0.8345 - val_accuracy: 0.7078\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8174 - val_loss: 0.8642 - val_accuracy: 0.6883\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8261 - val_loss: 0.9080 - val_accuracy: 0.6688\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8217 - val_loss: 0.8811 - val_accuracy: 0.6948\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8174 - val_loss: 0.8564 - val_accuracy: 0.6883\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.7978 - val_loss: 0.8607 - val_accuracy: 0.6948\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8174 - val_loss: 0.8820 - val_accuracy: 0.6948\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8174 - val_loss: 0.9159 - val_accuracy: 0.6558\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8196 - val_loss: 0.8741 - val_accuracy: 0.6818\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8239 - val_loss: 0.8466 - val_accuracy: 0.6883\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8152 - val_loss: 0.8292 - val_accuracy: 0.7208\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8239 - val_loss: 0.8532 - val_accuracy: 0.6818\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8217 - val_loss: 0.8828 - val_accuracy: 0.6753\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8261 - val_loss: 0.8767 - val_accuracy: 0.6948\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8174 - val_loss: 0.9027 - val_accuracy: 0.6688\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8152 - val_loss: 0.8981 - val_accuracy: 0.6623\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8217 - val_loss: 0.9318 - val_accuracy: 0.6558\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8000 - val_loss: 0.8946 - val_accuracy: 0.6948\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8109 - val_loss: 0.8286 - val_accuracy: 0.6883\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8283 - val_loss: 0.8631 - val_accuracy: 0.6818\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8239 - val_loss: 0.8983 - val_accuracy: 0.6558\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8304 - val_loss: 0.8977 - val_accuracy: 0.6688\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8348 - val_loss: 0.8722 - val_accuracy: 0.7143\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8391 - val_loss: 0.8508 - val_accuracy: 0.6753\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8304 - val_loss: 0.8593 - val_accuracy: 0.6818\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8304 - val_loss: 0.9209 - val_accuracy: 0.6558\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.7891 - val_loss: 0.8773 - val_accuracy: 0.6818\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8239 - val_loss: 0.9051 - val_accuracy: 0.6883\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8174 - val_loss: 0.8410 - val_accuracy: 0.6883\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8217 - val_loss: 0.8453 - val_accuracy: 0.6429\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8239 - val_loss: 0.8708 - val_accuracy: 0.6948\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8196 - val_loss: 0.9105 - val_accuracy: 0.6948\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3480 - accuracy: 0.8283 - val_loss: 0.9227 - val_accuracy: 0.6948\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8348 - val_loss: 0.9639 - val_accuracy: 0.6623\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8326 - val_loss: 0.9243 - val_accuracy: 0.7208\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8152 - val_loss: 0.8843 - val_accuracy: 0.7013\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3347 - accuracy: 0.8261 - val_loss: 0.8957 - val_accuracy: 0.6623\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8565 - val_loss: 0.9087 - val_accuracy: 0.6623\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8326 - val_loss: 0.9169 - val_accuracy: 0.6688\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8370 - val_loss: 0.9102 - val_accuracy: 0.6753\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8413 - val_loss: 0.9158 - val_accuracy: 0.6883\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3163 - accuracy: 0.8435 - val_loss: 0.9371 - val_accuracy: 0.6688\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8500 - val_loss: 0.9705 - val_accuracy: 0.6753\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3202 - accuracy: 0.8478 - val_loss: 0.9399 - val_accuracy: 0.6688\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8435 - val_loss: 0.9322 - val_accuracy: 0.6818\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.8370 - val_loss: 0.9566 - val_accuracy: 0.6688\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3213 - accuracy: 0.8543 - val_loss: 0.9547 - val_accuracy: 0.6818\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8283 - val_loss: 0.9815 - val_accuracy: 0.6883\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8609 - val_loss: 0.9942 - val_accuracy: 0.6753\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3237 - accuracy: 0.8543 - val_loss: 1.0005 - val_accuracy: 0.6883\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8565 - val_loss: 0.9746 - val_accuracy: 0.6883\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8587 - val_loss: 0.9975 - val_accuracy: 0.6818\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.8413 - val_loss: 1.0519 - val_accuracy: 0.6623\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.8283 - val_loss: 1.0620 - val_accuracy: 0.6558\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8413 - val_loss: 0.9884 - val_accuracy: 0.7013\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8478 - val_loss: 0.9570 - val_accuracy: 0.6948\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8413 - val_loss: 1.0302 - val_accuracy: 0.6948\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8413 - val_loss: 1.1104 - val_accuracy: 0.6688\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8283 - val_loss: 1.0746 - val_accuracy: 0.6753\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8196 - val_loss: 1.0242 - val_accuracy: 0.6688\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8174 - val_loss: 0.9702 - val_accuracy: 0.6753\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3363 - accuracy: 0.8283 - val_loss: 0.9966 - val_accuracy: 0.6623\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3139 - accuracy: 0.8435 - val_loss: 1.0670 - val_accuracy: 0.6623\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3080 - accuracy: 0.8587 - val_loss: 1.0443 - val_accuracy: 0.6558\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8500 - val_loss: 1.0367 - val_accuracy: 0.6688\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3122 - accuracy: 0.8609 - val_loss: 1.0380 - val_accuracy: 0.6753\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 0.8413 - val_loss: 1.0146 - val_accuracy: 0.6753\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3177 - accuracy: 0.8348 - val_loss: 1.0236 - val_accuracy: 0.6558\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8217 - val_loss: 1.0664 - val_accuracy: 0.6883\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3177 - accuracy: 0.8435 - val_loss: 1.0417 - val_accuracy: 0.6948\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8457 - val_loss: 1.0089 - val_accuracy: 0.6948\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8326 - val_loss: 1.0430 - val_accuracy: 0.6818\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8478 - val_loss: 1.0535 - val_accuracy: 0.6753\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8326 - val_loss: 0.9975 - val_accuracy: 0.6753\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8413 - val_loss: 0.9817 - val_accuracy: 0.6688\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3516 - accuracy: 0.8130 - val_loss: 0.9972 - val_accuracy: 0.6688\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8022 - val_loss: 0.9701 - val_accuracy: 0.6753\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8217 - val_loss: 0.9665 - val_accuracy: 0.6688\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8174 - val_loss: 0.9764 - val_accuracy: 0.6688\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8348 - val_loss: 1.0175 - val_accuracy: 0.6818\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8370 - val_loss: 1.0807 - val_accuracy: 0.6818\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8457 - val_loss: 1.0414 - val_accuracy: 0.6753\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8435 - val_loss: 1.0201 - val_accuracy: 0.6753\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.8457 - val_loss: 1.0347 - val_accuracy: 0.6948\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.8565 - val_loss: 1.0341 - val_accuracy: 0.6948\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2941 - accuracy: 0.8630 - val_loss: 1.0246 - val_accuracy: 0.6688\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2878 - accuracy: 0.8609 - val_loss: 1.0580 - val_accuracy: 0.6883\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8435 - val_loss: 1.0388 - val_accuracy: 0.6753\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3132 - accuracy: 0.8478 - val_loss: 1.0177 - val_accuracy: 0.7013\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.8543 - val_loss: 1.0595 - val_accuracy: 0.6883\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3018 - accuracy: 0.8565 - val_loss: 1.0823 - val_accuracy: 0.6818\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2970 - accuracy: 0.8543 - val_loss: 1.0989 - val_accuracy: 0.6948\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2958 - accuracy: 0.8478 - val_loss: 1.0945 - val_accuracy: 0.6753\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2979 - accuracy: 0.8587 - val_loss: 1.0950 - val_accuracy: 0.6818\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.8587 - val_loss: 1.0777 - val_accuracy: 0.6429\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2833 - accuracy: 0.8652 - val_loss: 1.0954 - val_accuracy: 0.6688\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2832 - accuracy: 0.8630 - val_loss: 1.0985 - val_accuracy: 0.6558\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2899 - accuracy: 0.8652 - val_loss: 1.1476 - val_accuracy: 0.6558\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8565 - val_loss: 1.1150 - val_accuracy: 0.7013\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2835 - accuracy: 0.8565 - val_loss: 1.1183 - val_accuracy: 0.6623\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2750 - accuracy: 0.8435 - val_loss: 1.2096 - val_accuracy: 0.6688\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2918 - accuracy: 0.8587 - val_loss: 1.1858 - val_accuracy: 0.6494\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3080 - accuracy: 0.8543 - val_loss: 1.1511 - val_accuracy: 0.6688\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2953 - accuracy: 0.8543 - val_loss: 1.1625 - val_accuracy: 0.6558\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.2999 - accuracy: 0.8435 - val_loss: 1.2086 - val_accuracy: 0.6818\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8674 - val_loss: 1.1877 - val_accuracy: 0.6494\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.8522 - val_loss: 1.1934 - val_accuracy: 0.6299\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.8435 - val_loss: 1.1698 - val_accuracy: 0.6753\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8500 - val_loss: 1.1229 - val_accuracy: 0.6558\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3233 - accuracy: 0.8500 - val_loss: 1.1576 - val_accuracy: 0.6753\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8283 - val_loss: 1.0582 - val_accuracy: 0.6623\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3201 - accuracy: 0.8543 - val_loss: 1.0612 - val_accuracy: 0.6558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lmDiChIUHR0U",
        "outputId": "2aa49269-696d-487b-9022-336af6bc575f"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmtEG_9HvTc"
      },
      "source": [
        "# Complete the exercise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSi_9mVoKYUN",
        "outputId": "0f4e9061-ef8a-41ad-c102-9748aec4cacf"
      },
      "source": [
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_92 (Dense)             (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz3kDR5zKmyW"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model7.add(Dense(24, activation='relu'))\n",
        "model7.add(Dense(24, activation='relu'))\n",
        "model7.add(Dense(36, activation='relu'))\n",
        "model7.add(Dense(24, activation='relu'))\n",
        "model7.add(Dense(24, activation='relu'))\n",
        "model7.add(Dense(12, activation='relu'))\n",
        "model7.add(Dense(8, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
        "model7.add(Dense(1, activation='sigmoid'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7SdgMChK6a-"
      },
      "source": [
        "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFsCNmwiLMZF",
        "outputId": "eb5403a1-49c4-4345-9672-dd06773d5d91"
      },
      "source": [
        "history = model7.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 1.7241 - accuracy: 0.6196 - val_loss: 1.5810 - val_accuracy: 0.6753\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6269 - accuracy: 0.6522 - val_loss: 1.5246 - val_accuracy: 0.6818\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5480 - accuracy: 0.6522 - val_loss: 1.4855 - val_accuracy: 0.6818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4916 - accuracy: 0.6500 - val_loss: 1.4649 - val_accuracy: 0.6688\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4498 - accuracy: 0.6630 - val_loss: 1.4251 - val_accuracy: 0.6753\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4138 - accuracy: 0.6717 - val_loss: 1.3852 - val_accuracy: 0.6818\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3763 - accuracy: 0.6696 - val_loss: 1.3505 - val_accuracy: 0.6818\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3372 - accuracy: 0.6804 - val_loss: 1.3421 - val_accuracy: 0.6558\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2936 - accuracy: 0.6957 - val_loss: 1.3275 - val_accuracy: 0.6169\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2810 - accuracy: 0.6891 - val_loss: 1.2631 - val_accuracy: 0.6688\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.2579 - accuracy: 0.6804 - val_loss: 1.2544 - val_accuracy: 0.6558\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2115 - accuracy: 0.6870 - val_loss: 1.2312 - val_accuracy: 0.6429\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1854 - accuracy: 0.6826 - val_loss: 1.2121 - val_accuracy: 0.6429\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1534 - accuracy: 0.6891 - val_loss: 1.1787 - val_accuracy: 0.6494\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1192 - accuracy: 0.7043 - val_loss: 1.1818 - val_accuracy: 0.6039\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0814 - accuracy: 0.7304 - val_loss: 1.2007 - val_accuracy: 0.5974\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0943 - accuracy: 0.6761 - val_loss: 1.1053 - val_accuracy: 0.6494\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0784 - accuracy: 0.6913 - val_loss: 1.0980 - val_accuracy: 0.6234\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0265 - accuracy: 0.7130 - val_loss: 1.0709 - val_accuracy: 0.6558\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.0112 - accuracy: 0.7087 - val_loss: 1.0604 - val_accuracy: 0.6818\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9841 - accuracy: 0.7152 - val_loss: 1.0842 - val_accuracy: 0.6299\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9558 - accuracy: 0.7261 - val_loss: 1.0265 - val_accuracy: 0.6558\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9413 - accuracy: 0.7370 - val_loss: 1.0667 - val_accuracy: 0.6299\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9227 - accuracy: 0.7174 - val_loss: 0.9928 - val_accuracy: 0.6558\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8993 - accuracy: 0.7435 - val_loss: 1.0062 - val_accuracy: 0.6558\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8888 - accuracy: 0.7130 - val_loss: 0.9607 - val_accuracy: 0.6883\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8702 - accuracy: 0.7435 - val_loss: 0.9725 - val_accuracy: 0.6039\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8584 - accuracy: 0.7457 - val_loss: 0.9564 - val_accuracy: 0.6429\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.7326 - val_loss: 0.9773 - val_accuracy: 0.6364\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8302 - accuracy: 0.7348 - val_loss: 0.9015 - val_accuracy: 0.6883\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8123 - accuracy: 0.7304 - val_loss: 0.8957 - val_accuracy: 0.6753\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7976 - accuracy: 0.7391 - val_loss: 0.8849 - val_accuracy: 0.6623\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8108 - accuracy: 0.7196 - val_loss: 0.8845 - val_accuracy: 0.6818\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8060 - accuracy: 0.7130 - val_loss: 0.8907 - val_accuracy: 0.6558\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7757 - accuracy: 0.7370 - val_loss: 0.8594 - val_accuracy: 0.6883\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7601 - accuracy: 0.7565 - val_loss: 0.8531 - val_accuracy: 0.6558\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7598 - accuracy: 0.7304 - val_loss: 0.8324 - val_accuracy: 0.6883\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7466 - accuracy: 0.7348 - val_loss: 0.8465 - val_accuracy: 0.6753\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7232 - accuracy: 0.7413 - val_loss: 0.8323 - val_accuracy: 0.6883\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7167 - accuracy: 0.7435 - val_loss: 0.8427 - val_accuracy: 0.6429\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7236 - accuracy: 0.7457 - val_loss: 0.8158 - val_accuracy: 0.6753\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7133 - accuracy: 0.7217 - val_loss: 0.8145 - val_accuracy: 0.6688\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.7522 - val_loss: 0.8034 - val_accuracy: 0.7078\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.7391 - val_loss: 0.8221 - val_accuracy: 0.6623\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.7457 - val_loss: 0.8016 - val_accuracy: 0.6883\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.7565 - val_loss: 0.7752 - val_accuracy: 0.7078\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.7391 - val_loss: 0.7804 - val_accuracy: 0.7273\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.7391 - val_loss: 0.7647 - val_accuracy: 0.7273\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6504 - accuracy: 0.7500 - val_loss: 0.8233 - val_accuracy: 0.6299\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.7435 - val_loss: 0.7807 - val_accuracy: 0.7078\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6413 - accuracy: 0.7370 - val_loss: 0.7949 - val_accuracy: 0.6948\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.7304 - val_loss: 0.7718 - val_accuracy: 0.7078\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.7609 - val_loss: 0.8176 - val_accuracy: 0.6753\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.7435 - val_loss: 0.7471 - val_accuracy: 0.7078\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6061 - accuracy: 0.7609 - val_loss: 0.7695 - val_accuracy: 0.6883\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.7543 - val_loss: 0.7488 - val_accuracy: 0.7078\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6103 - accuracy: 0.7522 - val_loss: 0.7537 - val_accuracy: 0.7078\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7674 - val_loss: 0.7757 - val_accuracy: 0.7013\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7457 - val_loss: 0.7777 - val_accuracy: 0.6883\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.7478 - val_loss: 0.7608 - val_accuracy: 0.6883\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.7565 - val_loss: 0.7888 - val_accuracy: 0.6688\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.7370 - val_loss: 0.7450 - val_accuracy: 0.7013\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.7022 - val_loss: 0.7590 - val_accuracy: 0.6688\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.7457 - val_loss: 0.7332 - val_accuracy: 0.6948\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5852 - accuracy: 0.7413 - val_loss: 0.7433 - val_accuracy: 0.6883\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.7696 - val_loss: 0.7236 - val_accuracy: 0.7143\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5872 - accuracy: 0.7370 - val_loss: 0.7255 - val_accuracy: 0.7468\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7261 - val_loss: 0.7428 - val_accuracy: 0.6688\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7239 - val_loss: 0.7459 - val_accuracy: 0.6753\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7478 - val_loss: 0.7422 - val_accuracy: 0.6948\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7478 - val_loss: 0.7282 - val_accuracy: 0.7208\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7500 - val_loss: 0.7689 - val_accuracy: 0.6623\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5427 - accuracy: 0.7609 - val_loss: 0.7360 - val_accuracy: 0.7078\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7500 - val_loss: 0.7883 - val_accuracy: 0.6494\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7565 - val_loss: 0.7470 - val_accuracy: 0.7208\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7565 - val_loss: 0.7452 - val_accuracy: 0.6623\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7870 - val_loss: 0.7284 - val_accuracy: 0.7143\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7717 - val_loss: 0.7760 - val_accuracy: 0.6623\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7674 - val_loss: 0.7350 - val_accuracy: 0.6948\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7826 - val_loss: 0.7439 - val_accuracy: 0.7208\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7674 - val_loss: 0.7607 - val_accuracy: 0.6948\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7717 - val_loss: 0.7643 - val_accuracy: 0.6494\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7565 - val_loss: 0.7400 - val_accuracy: 0.7078\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7674 - val_loss: 0.7676 - val_accuracy: 0.6753\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7761 - val_loss: 0.7643 - val_accuracy: 0.7208\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7804 - val_loss: 0.7517 - val_accuracy: 0.7143\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7717 - val_loss: 0.7483 - val_accuracy: 0.7143\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7717 - val_loss: 0.7677 - val_accuracy: 0.7078\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7717 - val_loss: 0.7477 - val_accuracy: 0.7078\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7761 - val_loss: 0.7560 - val_accuracy: 0.7013\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7826 - val_loss: 0.7475 - val_accuracy: 0.7143\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7783 - val_loss: 0.7514 - val_accuracy: 0.6883\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7717 - val_loss: 0.7364 - val_accuracy: 0.7208\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7652 - val_loss: 0.7740 - val_accuracy: 0.7208\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7283 - val_loss: 0.7659 - val_accuracy: 0.6169\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7696 - val_loss: 0.7533 - val_accuracy: 0.7273\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5188 - accuracy: 0.7674 - val_loss: 0.7759 - val_accuracy: 0.7013\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7609 - val_loss: 0.7726 - val_accuracy: 0.6948\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7826 - val_loss: 0.7564 - val_accuracy: 0.7143\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 0.7783 - val_loss: 0.7597 - val_accuracy: 0.7078\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7978 - val_loss: 0.7623 - val_accuracy: 0.7143\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7804 - val_loss: 0.7442 - val_accuracy: 0.6494\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7761 - val_loss: 0.7633 - val_accuracy: 0.7078\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7804 - val_loss: 0.7987 - val_accuracy: 0.6688\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7652 - val_loss: 0.7724 - val_accuracy: 0.7078\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7804 - val_loss: 0.7620 - val_accuracy: 0.6883\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7957 - val_loss: 0.7253 - val_accuracy: 0.6948\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7652 - val_loss: 0.7847 - val_accuracy: 0.6818\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7652 - val_loss: 0.8060 - val_accuracy: 0.6753\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7652 - val_loss: 0.7829 - val_accuracy: 0.7143\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7891 - val_loss: 0.7763 - val_accuracy: 0.6688\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7913 - val_loss: 0.8189 - val_accuracy: 0.7208\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7935 - val_loss: 0.7847 - val_accuracy: 0.6818\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7891 - val_loss: 0.7615 - val_accuracy: 0.7143\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.8000 - val_loss: 0.8097 - val_accuracy: 0.6883\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7935 - val_loss: 0.7807 - val_accuracy: 0.7078\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7783 - val_loss: 0.7872 - val_accuracy: 0.7208\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7891 - val_loss: 0.7738 - val_accuracy: 0.6883\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7913 - val_loss: 0.7846 - val_accuracy: 0.6948\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7935 - val_loss: 0.8233 - val_accuracy: 0.6948\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7609 - val_loss: 0.7776 - val_accuracy: 0.6948\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7348 - val_loss: 0.7573 - val_accuracy: 0.6753\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7674 - val_loss: 0.8409 - val_accuracy: 0.7078\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7870 - val_loss: 0.7697 - val_accuracy: 0.6753\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.7957 - val_loss: 0.7494 - val_accuracy: 0.7273\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7978 - val_loss: 0.7740 - val_accuracy: 0.6883\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7935 - val_loss: 0.7623 - val_accuracy: 0.7143\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8022 - val_loss: 0.8201 - val_accuracy: 0.6883\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7957 - val_loss: 0.7878 - val_accuracy: 0.7143\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7848 - val_loss: 0.7708 - val_accuracy: 0.6753\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7935 - val_loss: 0.7961 - val_accuracy: 0.7143\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7848 - val_loss: 0.8094 - val_accuracy: 0.6429\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4653 - accuracy: 0.7848 - val_loss: 0.7846 - val_accuracy: 0.7143\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4696 - accuracy: 0.7870 - val_loss: 0.7899 - val_accuracy: 0.6818\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.8065 - val_loss: 0.8029 - val_accuracy: 0.7078\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8000 - val_loss: 0.7938 - val_accuracy: 0.7078\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8043 - val_loss: 0.8136 - val_accuracy: 0.6558\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7674 - val_loss: 0.8190 - val_accuracy: 0.7208\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8109 - val_loss: 0.7936 - val_accuracy: 0.6883\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7913 - val_loss: 0.7991 - val_accuracy: 0.6948\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.8022 - val_loss: 0.7668 - val_accuracy: 0.7143\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8000 - val_loss: 0.8132 - val_accuracy: 0.6688\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8109 - val_loss: 0.8928 - val_accuracy: 0.7273\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7957 - val_loss: 0.8540 - val_accuracy: 0.7013\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8130 - val_loss: 0.8345 - val_accuracy: 0.6558\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.8043 - val_loss: 0.7944 - val_accuracy: 0.7273\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8196 - val_loss: 0.8444 - val_accuracy: 0.6623\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7978 - val_loss: 0.8481 - val_accuracy: 0.7143\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8152 - val_loss: 0.8346 - val_accuracy: 0.7013\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8304 - val_loss: 0.8492 - val_accuracy: 0.7013\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8130 - val_loss: 0.8527 - val_accuracy: 0.7013\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8283 - val_loss: 0.8533 - val_accuracy: 0.7143\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8239 - val_loss: 0.8198 - val_accuracy: 0.7013\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8370 - val_loss: 0.8547 - val_accuracy: 0.6883\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7957 - val_loss: 0.8552 - val_accuracy: 0.7208\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8239 - val_loss: 0.8344 - val_accuracy: 0.6688\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.8130 - val_loss: 0.8953 - val_accuracy: 0.6883\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8261 - val_loss: 0.8172 - val_accuracy: 0.6883\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8304 - val_loss: 0.8711 - val_accuracy: 0.7143\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.8087 - val_loss: 0.8686 - val_accuracy: 0.6948\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8239 - val_loss: 0.8234 - val_accuracy: 0.6883\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7978 - val_loss: 0.8509 - val_accuracy: 0.7078\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8196 - val_loss: 0.8546 - val_accuracy: 0.7013\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8413 - val_loss: 0.8407 - val_accuracy: 0.7013\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.8022 - val_loss: 0.8614 - val_accuracy: 0.7208\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.8152 - val_loss: 0.8958 - val_accuracy: 0.6753\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.8152 - val_loss: 0.9359 - val_accuracy: 0.7143\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8065 - val_loss: 0.8478 - val_accuracy: 0.6818\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8326 - val_loss: 0.8671 - val_accuracy: 0.7143\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8196 - val_loss: 0.9537 - val_accuracy: 0.7208\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8065 - val_loss: 0.8992 - val_accuracy: 0.7013\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8261 - val_loss: 0.9200 - val_accuracy: 0.6688\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8087 - val_loss: 0.8900 - val_accuracy: 0.6818\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4169 - accuracy: 0.8065 - val_loss: 0.8773 - val_accuracy: 0.7143\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8261 - val_loss: 0.8771 - val_accuracy: 0.7273\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8152 - val_loss: 0.9233 - val_accuracy: 0.6623\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8174 - val_loss: 1.1427 - val_accuracy: 0.6883\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7717 - val_loss: 0.8655 - val_accuracy: 0.6169\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8196 - val_loss: 0.8409 - val_accuracy: 0.7013\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8000 - val_loss: 0.8738 - val_accuracy: 0.6753\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7935 - val_loss: 0.8822 - val_accuracy: 0.6818\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8196 - val_loss: 0.8908 - val_accuracy: 0.7078\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8304 - val_loss: 0.9171 - val_accuracy: 0.6948\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8543 - val_loss: 0.8660 - val_accuracy: 0.7143\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8326 - val_loss: 0.8863 - val_accuracy: 0.6948\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8478 - val_loss: 0.9242 - val_accuracy: 0.6753\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8500 - val_loss: 0.9089 - val_accuracy: 0.6818\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8565 - val_loss: 0.8799 - val_accuracy: 0.7013\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8348 - val_loss: 0.9915 - val_accuracy: 0.6753\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8326 - val_loss: 0.9463 - val_accuracy: 0.6948\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8587 - val_loss: 0.9345 - val_accuracy: 0.6623\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8261 - val_loss: 0.9398 - val_accuracy: 0.6883\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8413 - val_loss: 0.9531 - val_accuracy: 0.6948\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8587 - val_loss: 0.9980 - val_accuracy: 0.7078\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8130 - val_loss: 0.9744 - val_accuracy: 0.6299\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8283 - val_loss: 0.9648 - val_accuracy: 0.6558\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8478 - val_loss: 0.9509 - val_accuracy: 0.6948\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8565 - val_loss: 0.9547 - val_accuracy: 0.6753\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3719 - accuracy: 0.8391 - val_loss: 0.9748 - val_accuracy: 0.6234\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8609 - val_loss: 1.0111 - val_accuracy: 0.6623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZdmROIDLNb9",
        "outputId": "7de321f0-9b29-4b80-e06e-74e7ff925270"
      },
      "source": [
        "model6.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8411 - accuracy: 0.6623\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8411253690719604, 0.6623376607894897]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgRCZ4tMLX_a",
        "outputId": "b67a36c6-ab37-4965-e1cd-cf36421e4344"
      },
      "source": [
        "model7.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7775 - accuracy: 0.7208\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7774730920791626, 0.7207792401313782]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_twaWQ0LcD4",
        "outputId": "95039571-b41d-42db-92ed-f860d8b92bcb"
      },
      "source": [
        "model7.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.9904 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9904208779335022, 0.7142857313156128]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0AYjF9yLvLR"
      },
      "source": [
        "from keras.regularizers import l1\n",
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(36, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(12, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
        "model7.add(Dense(8, activation='relu'))\n",
        "model7.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov3hy2BCNtQS"
      },
      "source": [
        "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gbOxM8BNwEB",
        "outputId": "b3d8dcfa-2e33-484d-b177-fc3bda95108c"
      },
      "source": [
        "history = model7.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 38ms/step - loss: 59.2236 - accuracy: 0.6326 - val_loss: 57.6965 - val_accuracy: 0.6688\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 56.8231 - accuracy: 0.6522 - val_loss: 55.3754 - val_accuracy: 0.6753\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 54.5177 - accuracy: 0.6326 - val_loss: 53.0978 - val_accuracy: 0.6623\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 52.2490 - accuracy: 0.6587 - val_loss: 50.8571 - val_accuracy: 0.6818\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 50.0206 - accuracy: 0.6239 - val_loss: 48.6654 - val_accuracy: 0.6494\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 47.8306 - accuracy: 0.6174 - val_loss: 46.4921 - val_accuracy: 0.6753\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 45.6836 - accuracy: 0.6522 - val_loss: 44.3687 - val_accuracy: 0.6818\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 43.5815 - accuracy: 0.6217 - val_loss: 42.3028 - val_accuracy: 0.6558\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.5145 - accuracy: 0.6435 - val_loss: 40.2601 - val_accuracy: 0.6818\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 39.5093 - accuracy: 0.6522 - val_loss: 38.2766 - val_accuracy: 0.6818\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 37.5350 - accuracy: 0.6522 - val_loss: 36.3405 - val_accuracy: 0.6818\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.6150 - accuracy: 0.6522 - val_loss: 34.4515 - val_accuracy: 0.6818\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 33.7491 - accuracy: 0.6522 - val_loss: 32.6103 - val_accuracy: 0.6818\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 31.9162 - accuracy: 0.6522 - val_loss: 30.8058 - val_accuracy: 0.6818\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 30.1349 - accuracy: 0.6522 - val_loss: 29.0593 - val_accuracy: 0.6818\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.4047 - accuracy: 0.6522 - val_loss: 27.3536 - val_accuracy: 0.6818\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 26.7140 - accuracy: 0.6522 - val_loss: 25.6955 - val_accuracy: 0.6818\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 25.0818 - accuracy: 0.6522 - val_loss: 24.1001 - val_accuracy: 0.6818\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.5053 - accuracy: 0.6522 - val_loss: 22.5529 - val_accuracy: 0.6818\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.9820 - accuracy: 0.6522 - val_loss: 21.0644 - val_accuracy: 0.6818\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.5197 - accuracy: 0.6522 - val_loss: 19.6394 - val_accuracy: 0.6818\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.1099 - accuracy: 0.6522 - val_loss: 18.2614 - val_accuracy: 0.6818\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 17.7575 - accuracy: 0.6522 - val_loss: 16.9415 - val_accuracy: 0.6818\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.4527 - accuracy: 0.6522 - val_loss: 15.6639 - val_accuracy: 0.6818\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.1976 - accuracy: 0.6522 - val_loss: 14.4406 - val_accuracy: 0.6818\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.0030 - accuracy: 0.6522 - val_loss: 13.2934 - val_accuracy: 0.6818\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.8708 - accuracy: 0.6522 - val_loss: 12.1861 - val_accuracy: 0.6818\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.7885 - accuracy: 0.6522 - val_loss: 11.1387 - val_accuracy: 0.6818\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 10.7615 - accuracy: 0.6522 - val_loss: 10.1466 - val_accuracy: 0.6818\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.7919 - accuracy: 0.6522 - val_loss: 9.2083 - val_accuracy: 0.6818\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8724 - accuracy: 0.6522 - val_loss: 8.3239 - val_accuracy: 0.6818\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0108 - accuracy: 0.6522 - val_loss: 7.4980 - val_accuracy: 0.6818\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.2089 - accuracy: 0.6522 - val_loss: 6.7317 - val_accuracy: 0.6818\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4674 - accuracy: 0.6522 - val_loss: 6.0300 - val_accuracy: 0.6818\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7901 - accuracy: 0.6522 - val_loss: 5.3878 - val_accuracy: 0.6818\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1713 - accuracy: 0.6522 - val_loss: 4.8051 - val_accuracy: 0.6818\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6135 - accuracy: 0.6522 - val_loss: 4.2822 - val_accuracy: 0.6818\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1086 - accuracy: 0.6522 - val_loss: 3.8113 - val_accuracy: 0.6818\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6653 - accuracy: 0.6522 - val_loss: 3.4117 - val_accuracy: 0.6818\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2872 - accuracy: 0.6522 - val_loss: 3.0649 - val_accuracy: 0.6818\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9593 - accuracy: 0.6522 - val_loss: 2.7624 - val_accuracy: 0.6818\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6734 - accuracy: 0.6522 - val_loss: 2.5004 - val_accuracy: 0.6818\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4293 - accuracy: 0.6522 - val_loss: 2.2808 - val_accuracy: 0.6818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2216 - accuracy: 0.6522 - val_loss: 2.0946 - val_accuracy: 0.6818\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0502 - accuracy: 0.6522 - val_loss: 1.9381 - val_accuracy: 0.6818\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8981 - accuracy: 0.6522 - val_loss: 1.7956 - val_accuracy: 0.6818\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7616 - accuracy: 0.6522 - val_loss: 1.6668 - val_accuracy: 0.6818\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6385 - accuracy: 0.6522 - val_loss: 1.5553 - val_accuracy: 0.6818\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5328 - accuracy: 0.6522 - val_loss: 1.4549 - val_accuracy: 0.6818\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4388 - accuracy: 0.6522 - val_loss: 1.3712 - val_accuracy: 0.6818\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3600 - accuracy: 0.6522 - val_loss: 1.2987 - val_accuracy: 0.6818\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2929 - accuracy: 0.6522 - val_loss: 1.2397 - val_accuracy: 0.6818\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2356 - accuracy: 0.6522 - val_loss: 1.1841 - val_accuracy: 0.6818\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.1806 - accuracy: 0.6522 - val_loss: 1.1305 - val_accuracy: 0.6818\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.1300 - accuracy: 0.6522 - val_loss: 1.0831 - val_accuracy: 0.6818\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0840 - accuracy: 0.6522 - val_loss: 1.0399 - val_accuracy: 0.6818\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0421 - accuracy: 0.6522 - val_loss: 0.9992 - val_accuracy: 0.6818\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.0023 - accuracy: 0.6522 - val_loss: 0.9612 - val_accuracy: 0.6818\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9661 - accuracy: 0.6522 - val_loss: 0.9307 - val_accuracy: 0.6818\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.9372 - accuracy: 0.6522 - val_loss: 0.9010 - val_accuracy: 0.6818\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.9093 - accuracy: 0.6522 - val_loss: 0.8767 - val_accuracy: 0.6818\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8871 - accuracy: 0.6522 - val_loss: 0.8569 - val_accuracy: 0.6818\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8671 - accuracy: 0.6522 - val_loss: 0.8366 - val_accuracy: 0.6818\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8476 - accuracy: 0.6522 - val_loss: 0.8193 - val_accuracy: 0.6818\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8321 - accuracy: 0.6522 - val_loss: 0.8040 - val_accuracy: 0.6818\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8167 - accuracy: 0.6522 - val_loss: 0.7898 - val_accuracy: 0.6818\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8039 - accuracy: 0.6522 - val_loss: 0.7791 - val_accuracy: 0.6818\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7933 - accuracy: 0.6522 - val_loss: 0.7684 - val_accuracy: 0.6818\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7823 - accuracy: 0.6522 - val_loss: 0.7587 - val_accuracy: 0.6818\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7727 - accuracy: 0.6522 - val_loss: 0.7489 - val_accuracy: 0.6818\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7638 - accuracy: 0.6522 - val_loss: 0.7415 - val_accuracy: 0.6818\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7567 - accuracy: 0.6522 - val_loss: 0.7342 - val_accuracy: 0.6818\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7498 - accuracy: 0.6522 - val_loss: 0.7268 - val_accuracy: 0.6818\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7432 - accuracy: 0.6522 - val_loss: 0.7221 - val_accuracy: 0.6818\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7385 - accuracy: 0.6522 - val_loss: 0.7170 - val_accuracy: 0.6818\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7331 - accuracy: 0.6522 - val_loss: 0.7118 - val_accuracy: 0.6818\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7283 - accuracy: 0.6522 - val_loss: 0.7068 - val_accuracy: 0.6818\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.6522 - val_loss: 0.7016 - val_accuracy: 0.6818\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7187 - accuracy: 0.6522 - val_loss: 0.6980 - val_accuracy: 0.6818\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7153 - accuracy: 0.6522 - val_loss: 0.6949 - val_accuracy: 0.6818\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7127 - accuracy: 0.6522 - val_loss: 0.6927 - val_accuracy: 0.6818\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7104 - accuracy: 0.6522 - val_loss: 0.6913 - val_accuracy: 0.6818\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7098 - accuracy: 0.6522 - val_loss: 0.6909 - val_accuracy: 0.6818\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7087 - accuracy: 0.6522 - val_loss: 0.6893 - val_accuracy: 0.6818\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7079 - accuracy: 0.6522 - val_loss: 0.6883 - val_accuracy: 0.6818\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7066 - accuracy: 0.6522 - val_loss: 0.6878 - val_accuracy: 0.6818\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7060 - accuracy: 0.6522 - val_loss: 0.6877 - val_accuracy: 0.6818\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7056 - accuracy: 0.6522 - val_loss: 0.6877 - val_accuracy: 0.6818\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7048 - accuracy: 0.6522 - val_loss: 0.6866 - val_accuracy: 0.6818\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.6522 - val_loss: 0.6851 - val_accuracy: 0.6818\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7028 - accuracy: 0.6522 - val_loss: 0.6841 - val_accuracy: 0.6818\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.6522 - val_loss: 0.6838 - val_accuracy: 0.6818\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7016 - accuracy: 0.6522 - val_loss: 0.6836 - val_accuracy: 0.6818\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.6522 - val_loss: 0.6817 - val_accuracy: 0.6818\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7000 - accuracy: 0.6522 - val_loss: 0.6816 - val_accuracy: 0.6818\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.6522 - val_loss: 0.6803 - val_accuracy: 0.6818\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.6522 - val_loss: 0.6799 - val_accuracy: 0.6818\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.6522 - val_loss: 0.6789 - val_accuracy: 0.6818\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.6522 - val_loss: 0.6777 - val_accuracy: 0.6818\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.6522 - val_loss: 0.6759 - val_accuracy: 0.6818\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.6522 - val_loss: 0.6756 - val_accuracy: 0.6818\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.6522 - val_loss: 0.6754 - val_accuracy: 0.6818\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.6522 - val_loss: 0.6749 - val_accuracy: 0.6818\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.6522 - val_loss: 0.6747 - val_accuracy: 0.6818\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.6522 - val_loss: 0.6736 - val_accuracy: 0.6818\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.6522 - val_loss: 0.6732 - val_accuracy: 0.6818\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.6522 - val_loss: 0.6732 - val_accuracy: 0.6818\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6914 - accuracy: 0.6522 - val_loss: 0.6731 - val_accuracy: 0.6818\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6728 - val_accuracy: 0.6818\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6711 - val_accuracy: 0.6818\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6711 - val_accuracy: 0.6818\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.6522 - val_loss: 0.6706 - val_accuracy: 0.6818\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6711 - val_accuracy: 0.6818\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6708 - val_accuracy: 0.6818\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6709 - val_accuracy: 0.6818\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6729 - val_accuracy: 0.6818\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4EMA6GNyzO",
        "outputId": "b6b89527-2dbb-421f-f7c4-fbcd0b755801"
      },
      "source": [
        "model7.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.6169\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7122392654418945, 0.6168830990791321]"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCYOrsu5SeaT"
      },
      "source": [
        "from datetime import datetime\n",
        "    #  import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yczYlXoPRtkt",
        "outputId": "9b113eca-a2e1-47fb-9604-b93cd1eaa90b"
      },
      "source": [
        "  logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "history = model7.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        "     callbacks=[tensorboard_callback]\n",
        ")\n",
        "# model7.fit(x=x_train, \n",
        "#           y=y_train, \n",
        "#           epochs=5, \n",
        "#           validation_data=(x_test, y_test), \n",
        "#           callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6729 - val_accuracy: 0.6818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6734 - val_accuracy: 0.6818\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6711 - val_accuracy: 0.6818\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6728 - val_accuracy: 0.6818\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6732 - val_accuracy: 0.6818\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6706 - val_accuracy: 0.6818\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6706 - val_accuracy: 0.6818\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6728 - val_accuracy: 0.6818\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6708 - val_accuracy: 0.6818\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6708 - val_accuracy: 0.6818\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6717 - val_accuracy: 0.6818\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6729 - val_accuracy: 0.6818\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6713 - val_accuracy: 0.6818\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6725 - val_accuracy: 0.6818\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6709 - val_accuracy: 0.6818\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6706 - val_accuracy: 0.6818\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6710 - val_accuracy: 0.6818\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6712 - val_accuracy: 0.6818\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6715 - val_accuracy: 0.6818\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6727 - val_accuracy: 0.6818\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6903 - accuracy: 0.6522 - val_loss: 0.6716 - val_accuracy: 0.6818\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6731 - val_accuracy: 0.6818\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6728 - val_accuracy: 0.6818\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6719 - val_accuracy: 0.6818\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.6522 - val_loss: 0.6726 - val_accuracy: 0.6818\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6711 - val_accuracy: 0.6818\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6723 - val_accuracy: 0.6818\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6724 - val_accuracy: 0.6818\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6718 - val_accuracy: 0.6818\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.6522 - val_loss: 0.6720 - val_accuracy: 0.6818\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.6522 - val_loss: 0.6729 - val_accuracy: 0.6818\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6909 - accuracy: 0.6522 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6522 - val_loss: 0.6722 - val_accuracy: 0.6818\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6522 - val_loss: 0.6714 - val_accuracy: 0.6818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4-MzjTGUweu",
        "outputId": "098dc383-89b6-4b86-d130-23f01c2ec58b"
      },
      "source": [
        "model7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_214 (Dense)            (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_215 (Dense)            (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_216 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_217 (Dense)            (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_218 (Dense)            (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_219 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_220 (Dense)            (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_221 (Dense)            (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_222 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "57Fsf4B3ScIw",
        "outputId": "dbbc14fa-ba71-4f12-ea7f-279a82ca3765"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPL8p7cnTSuJ"
      },
      "source": [
        "# Take a break for 15 mins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEagQk69aT-0",
        "outputId": "f649f3bc-a57b-4b16-96cf-e05db14edfdb"
      },
      "source": [
        "model7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_214 (Dense)            (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_215 (Dense)            (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_216 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_217 (Dense)            (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_218 (Dense)            (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_219 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_220 (Dense)            (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_221 (Dense)            (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_222 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdcgj3Cb3CV"
      },
      "source": [
        "from keras.layers import Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF98VxR5baPR"
      },
      "source": [
        "model8 = Sequential()\n",
        "model8.add(Dense(12, activation='relu', input_shape=(8,)))\n",
        "model8.add(Dense(24, activation='relu'))\n",
        "\n",
        "model8.add(Dense(24, activation='relu'))\n",
        "model8.add(Dense(36, activation='relu'))\n",
        "\n",
        "\n",
        "model8.add(Dense(24, activation='relu'))\n",
        "model8.add(Dense(24, activation='relu'))\n",
        "model8.add(Dropout(0.2))\n",
        "model8.add(Dense(12, activation='relu'))\n",
        "model8.add(Dense(8, activation='relu'))\n",
        "model8.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzY0BzX5cE11"
      },
      "source": [
        "model8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tceDp9HKcVCC",
        "outputId": "d6ea0d93-3058-4071-cdb1-11314e7ba0c3"
      },
      "source": [
        "model8.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_241 (Dense)            (None, 12)                108       \n",
            "_________________________________________________________________\n",
            "dense_242 (Dense)            (None, 24)                312       \n",
            "_________________________________________________________________\n",
            "dense_243 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_244 (Dense)            (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "dense_245 (Dense)            (None, 24)                888       \n",
            "_________________________________________________________________\n",
            "dense_246 (Dense)            (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_247 (Dense)            (None, 12)                300       \n",
            "_________________________________________________________________\n",
            "dense_248 (Dense)            (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_249 (Dense)            (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 3,821\n",
            "Trainable params: 3,821\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGQK_DhRcLaS",
        "outputId": "0002dea5-ca14-4b8e-ae53-0da926a9342b"
      },
      "source": [
        "history = model8.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=200,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        "     \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 31ms/step - loss: 1.3494 - accuracy: 0.6652 - val_loss: 0.7325 - val_accuracy: 0.5974\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.8909 - accuracy: 0.6087 - val_loss: 0.6579 - val_accuracy: 0.6883\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7602 - accuracy: 0.6348 - val_loss: 0.6357 - val_accuracy: 0.6818\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.6022 - val_loss: 0.6583 - val_accuracy: 0.6299\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.6043 - val_loss: 0.6348 - val_accuracy: 0.6753\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6680 - accuracy: 0.6304 - val_loss: 0.6281 - val_accuracy: 0.6818\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.6370 - val_loss: 0.6302 - val_accuracy: 0.6948\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6416 - accuracy: 0.6413 - val_loss: 0.6279 - val_accuracy: 0.6753\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6457 - val_loss: 0.6144 - val_accuracy: 0.7143\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.6326 - val_loss: 0.6332 - val_accuracy: 0.6948\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6599 - accuracy: 0.6304 - val_loss: 0.6246 - val_accuracy: 0.6818\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.6717 - val_loss: 0.6285 - val_accuracy: 0.6818\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.6717 - val_loss: 0.6280 - val_accuracy: 0.6883\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.6500 - val_loss: 0.6283 - val_accuracy: 0.7078\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6565 - val_loss: 0.6308 - val_accuracy: 0.6883\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6630 - val_loss: 0.6406 - val_accuracy: 0.7013\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.6587 - val_loss: 0.6450 - val_accuracy: 0.6558\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.6935 - val_loss: 0.6430 - val_accuracy: 0.6818\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.6848 - val_loss: 0.6410 - val_accuracy: 0.6623\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.6609 - val_loss: 0.6442 - val_accuracy: 0.6494\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.6848 - val_loss: 0.6463 - val_accuracy: 0.6753\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.6804 - val_loss: 0.6528 - val_accuracy: 0.6494\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.6609 - val_loss: 0.6478 - val_accuracy: 0.6558\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5889 - accuracy: 0.6978 - val_loss: 0.6513 - val_accuracy: 0.6494\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5964 - accuracy: 0.6826 - val_loss: 0.6560 - val_accuracy: 0.6364\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6978 - val_loss: 0.6553 - val_accuracy: 0.6558\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.6935 - val_loss: 0.6591 - val_accuracy: 0.6753\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5982 - accuracy: 0.6739 - val_loss: 0.6516 - val_accuracy: 0.6688\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6029 - accuracy: 0.6891 - val_loss: 0.6543 - val_accuracy: 0.6429\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.6935 - val_loss: 0.6579 - val_accuracy: 0.6364\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.6935 - val_loss: 0.6553 - val_accuracy: 0.6753\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.6826 - val_loss: 0.6538 - val_accuracy: 0.7013\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.7000 - val_loss: 0.6614 - val_accuracy: 0.6753\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7022 - val_loss: 0.6494 - val_accuracy: 0.6688\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.7022 - val_loss: 0.6601 - val_accuracy: 0.6623\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.6804 - val_loss: 0.6591 - val_accuracy: 0.6494\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.6978 - val_loss: 0.6526 - val_accuracy: 0.6883\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.7022 - val_loss: 0.6505 - val_accuracy: 0.6688\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5904 - accuracy: 0.7022 - val_loss: 0.6622 - val_accuracy: 0.6688\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.6826 - val_loss: 0.6747 - val_accuracy: 0.7013\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6101 - accuracy: 0.6826 - val_loss: 0.6715 - val_accuracy: 0.6623\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6010 - accuracy: 0.6804 - val_loss: 0.6575 - val_accuracy: 0.6753\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5751 - accuracy: 0.6957 - val_loss: 0.6678 - val_accuracy: 0.6818\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.7196 - val_loss: 0.6629 - val_accuracy: 0.6558\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7000 - val_loss: 0.6670 - val_accuracy: 0.6818\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.6870 - val_loss: 0.6714 - val_accuracy: 0.6753\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5742 - accuracy: 0.7065 - val_loss: 0.6721 - val_accuracy: 0.7013\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5720 - accuracy: 0.7000 - val_loss: 0.6716 - val_accuracy: 0.6688\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7109 - val_loss: 0.6686 - val_accuracy: 0.7013\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5678 - accuracy: 0.6891 - val_loss: 0.6681 - val_accuracy: 0.6558\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5781 - accuracy: 0.7239 - val_loss: 0.6636 - val_accuracy: 0.6818\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6848 - val_loss: 0.6614 - val_accuracy: 0.6688\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6935 - val_loss: 0.6573 - val_accuracy: 0.7143\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.6739 - val_loss: 0.6664 - val_accuracy: 0.6753\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.6848 - val_loss: 0.6726 - val_accuracy: 0.6623\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7043 - val_loss: 0.6738 - val_accuracy: 0.6818\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5685 - accuracy: 0.6913 - val_loss: 0.6851 - val_accuracy: 0.6623\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.6674 - val_loss: 0.6744 - val_accuracy: 0.6623\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7087 - val_loss: 0.6679 - val_accuracy: 0.6688\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.6978 - val_loss: 0.6734 - val_accuracy: 0.6688\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5748 - accuracy: 0.6804 - val_loss: 0.6759 - val_accuracy: 0.6558\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7000 - val_loss: 0.6625 - val_accuracy: 0.6494\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5465 - accuracy: 0.7304 - val_loss: 0.6582 - val_accuracy: 0.6818\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.6848 - val_loss: 0.6578 - val_accuracy: 0.6948\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.6957 - val_loss: 0.6618 - val_accuracy: 0.7078\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7065 - val_loss: 0.6618 - val_accuracy: 0.6818\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7087 - val_loss: 0.6700 - val_accuracy: 0.6818\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.6957 - val_loss: 0.6646 - val_accuracy: 0.6818\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7130 - val_loss: 0.6665 - val_accuracy: 0.6948\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5921 - accuracy: 0.6739 - val_loss: 0.6600 - val_accuracy: 0.6883\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.7065 - val_loss: 0.6724 - val_accuracy: 0.6558\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.6957 - val_loss: 0.6682 - val_accuracy: 0.6688\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5600 - accuracy: 0.7065 - val_loss: 0.6658 - val_accuracy: 0.6883\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5567 - accuracy: 0.7000 - val_loss: 0.6660 - val_accuracy: 0.6688\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7217 - val_loss: 0.6621 - val_accuracy: 0.6494\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5513 - accuracy: 0.7174 - val_loss: 0.6667 - val_accuracy: 0.6818\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7087 - val_loss: 0.6798 - val_accuracy: 0.6623\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7174 - val_loss: 0.6772 - val_accuracy: 0.6688\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7043 - val_loss: 0.6759 - val_accuracy: 0.6558\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.7196 - val_loss: 0.6760 - val_accuracy: 0.6688\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7000 - val_loss: 0.6737 - val_accuracy: 0.7078\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7065 - val_loss: 0.6737 - val_accuracy: 0.6948\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7174 - val_loss: 0.6765 - val_accuracy: 0.7013\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5488 - accuracy: 0.7196 - val_loss: 0.6791 - val_accuracy: 0.6753\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7239 - val_loss: 0.6774 - val_accuracy: 0.7013\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7174 - val_loss: 0.6678 - val_accuracy: 0.6883\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7043 - val_loss: 0.6738 - val_accuracy: 0.6688\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7174 - val_loss: 0.6795 - val_accuracy: 0.6753\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.7174 - val_loss: 0.6801 - val_accuracy: 0.6753\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7239 - val_loss: 0.6887 - val_accuracy: 0.6753\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7109 - val_loss: 0.6806 - val_accuracy: 0.6948\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5649 - accuracy: 0.6935 - val_loss: 0.6743 - val_accuracy: 0.6623\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5546 - accuracy: 0.7043 - val_loss: 0.6731 - val_accuracy: 0.6948\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7261 - val_loss: 0.6721 - val_accuracy: 0.6818\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7130 - val_loss: 0.6773 - val_accuracy: 0.6818\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7000 - val_loss: 0.6867 - val_accuracy: 0.6883\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7304 - val_loss: 0.6696 - val_accuracy: 0.6948\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.7391 - val_loss: 0.6837 - val_accuracy: 0.6948\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7348 - val_loss: 0.6819 - val_accuracy: 0.6883\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7239 - val_loss: 0.6887 - val_accuracy: 0.6688\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7239 - val_loss: 0.6860 - val_accuracy: 0.6948\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7174 - val_loss: 0.6865 - val_accuracy: 0.6883\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7065 - val_loss: 0.6920 - val_accuracy: 0.6818\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.7304 - val_loss: 0.7021 - val_accuracy: 0.6753\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7261 - val_loss: 0.7039 - val_accuracy: 0.6623\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7130 - val_loss: 0.6887 - val_accuracy: 0.6494\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7304 - val_loss: 0.6970 - val_accuracy: 0.6883\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5640 - accuracy: 0.7348 - val_loss: 0.6881 - val_accuracy: 0.6494\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5818 - accuracy: 0.7065 - val_loss: 0.6795 - val_accuracy: 0.6753\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7261 - val_loss: 0.6839 - val_accuracy: 0.6818\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7413 - val_loss: 0.6744 - val_accuracy: 0.6494\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.6848 - val_loss: 0.6876 - val_accuracy: 0.6818\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5315 - accuracy: 0.7500 - val_loss: 0.7096 - val_accuracy: 0.6688\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.7174 - val_loss: 0.6934 - val_accuracy: 0.6818\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5373 - accuracy: 0.7174 - val_loss: 0.7072 - val_accuracy: 0.7013\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7261 - val_loss: 0.7035 - val_accuracy: 0.7078\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7087 - val_loss: 0.6936 - val_accuracy: 0.6818\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7457 - val_loss: 0.6975 - val_accuracy: 0.6753\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5369 - accuracy: 0.7217 - val_loss: 0.6729 - val_accuracy: 0.7143\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7413 - val_loss: 0.6838 - val_accuracy: 0.6818\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7283 - val_loss: 0.6783 - val_accuracy: 0.6948\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7261 - val_loss: 0.6850 - val_accuracy: 0.6818\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5185 - accuracy: 0.7174 - val_loss: 0.6705 - val_accuracy: 0.6883\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7239 - val_loss: 0.6733 - val_accuracy: 0.6818\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7391 - val_loss: 0.6722 - val_accuracy: 0.6883\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7261 - val_loss: 0.6741 - val_accuracy: 0.6883\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7348 - val_loss: 0.6835 - val_accuracy: 0.6883\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5213 - accuracy: 0.7348 - val_loss: 0.6895 - val_accuracy: 0.6623\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7457 - val_loss: 0.6805 - val_accuracy: 0.6753\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7500 - val_loss: 0.6795 - val_accuracy: 0.6948\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7413 - val_loss: 0.7125 - val_accuracy: 0.7078\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.7283 - val_loss: 0.6977 - val_accuracy: 0.6948\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7304 - val_loss: 0.7112 - val_accuracy: 0.6753\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7326 - val_loss: 0.7014 - val_accuracy: 0.7013\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7500 - val_loss: 0.7083 - val_accuracy: 0.6883\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7478 - val_loss: 0.7010 - val_accuracy: 0.6623\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7283 - val_loss: 0.7136 - val_accuracy: 0.6688\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7370 - val_loss: 0.7124 - val_accuracy: 0.6623\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.7008 - val_accuracy: 0.6883\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7587 - val_loss: 0.7038 - val_accuracy: 0.6688\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.7500 - val_loss: 0.7009 - val_accuracy: 0.6753\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7326 - val_loss: 0.7060 - val_accuracy: 0.6623\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7348 - val_loss: 0.7256 - val_accuracy: 0.6948\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7435 - val_loss: 0.7325 - val_accuracy: 0.6818\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7304 - val_loss: 0.7275 - val_accuracy: 0.6818\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7435 - val_loss: 0.7174 - val_accuracy: 0.6688\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5134 - accuracy: 0.7500 - val_loss: 0.7258 - val_accuracy: 0.6688\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7370 - val_loss: 0.7325 - val_accuracy: 0.6883\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7522 - val_loss: 0.7254 - val_accuracy: 0.6623\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7457 - val_loss: 0.7368 - val_accuracy: 0.6688\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7370 - val_loss: 0.7366 - val_accuracy: 0.6818\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7696 - val_loss: 0.7532 - val_accuracy: 0.6558\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7391 - val_loss: 0.7240 - val_accuracy: 0.6948\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7370 - val_loss: 0.7374 - val_accuracy: 0.6948\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.7376 - val_accuracy: 0.6558\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7543 - val_loss: 0.7427 - val_accuracy: 0.6818\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7457 - val_loss: 0.7387 - val_accuracy: 0.6753\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.7464 - val_accuracy: 0.6688\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7543 - val_loss: 0.7632 - val_accuracy: 0.6818\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7543 - val_loss: 0.7597 - val_accuracy: 0.6818\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7674 - val_loss: 0.7588 - val_accuracy: 0.6753\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7609 - val_loss: 0.7846 - val_accuracy: 0.6558\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7522 - val_loss: 0.7650 - val_accuracy: 0.6429\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7283 - val_loss: 0.7706 - val_accuracy: 0.7143\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7522 - val_loss: 0.7770 - val_accuracy: 0.6623\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7543 - val_loss: 0.7682 - val_accuracy: 0.6753\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7609 - val_loss: 0.7501 - val_accuracy: 0.6818\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7609 - val_loss: 0.7423 - val_accuracy: 0.6883\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7761 - val_loss: 0.7720 - val_accuracy: 0.6753\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7587 - val_loss: 0.7821 - val_accuracy: 0.6753\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7435 - val_loss: 0.7750 - val_accuracy: 0.6688\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.7587 - val_loss: 0.7700 - val_accuracy: 0.6948\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7630 - val_loss: 0.7431 - val_accuracy: 0.6623\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7587 - val_loss: 0.7650 - val_accuracy: 0.6753\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7717 - val_loss: 0.7756 - val_accuracy: 0.6818\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7761 - val_loss: 0.7765 - val_accuracy: 0.7013\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7696 - val_loss: 0.7511 - val_accuracy: 0.6429\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7261 - val_loss: 0.7423 - val_accuracy: 0.6883\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7804 - val_loss: 0.7620 - val_accuracy: 0.6688\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7630 - val_loss: 0.7751 - val_accuracy: 0.6818\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7696 - val_loss: 0.7823 - val_accuracy: 0.6818\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7717 - val_loss: 0.7944 - val_accuracy: 0.6818\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7630 - val_loss: 0.7915 - val_accuracy: 0.6623\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7630 - val_loss: 0.7950 - val_accuracy: 0.6753\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.7646 - val_accuracy: 0.6883\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.7609 - val_loss: 0.7654 - val_accuracy: 0.6948\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7804 - val_loss: 0.7790 - val_accuracy: 0.6818\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7783 - val_loss: 0.7946 - val_accuracy: 0.6753\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7761 - val_loss: 0.7962 - val_accuracy: 0.6429\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7565 - val_loss: 0.8058 - val_accuracy: 0.6948\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7783 - val_loss: 0.8246 - val_accuracy: 0.6494\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7717 - val_loss: 0.8653 - val_accuracy: 0.7013\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7891 - val_loss: 0.7899 - val_accuracy: 0.6623\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7761 - val_loss: 0.8067 - val_accuracy: 0.7013\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7587 - val_loss: 0.7913 - val_accuracy: 0.6818\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7717 - val_loss: 0.8308 - val_accuracy: 0.7208\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7913 - val_loss: 0.8257 - val_accuracy: 0.6753\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7804 - val_loss: 0.9083 - val_accuracy: 0.7013\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7674 - val_loss: 0.8664 - val_accuracy: 0.7078\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.8000 - val_loss: 0.8320 - val_accuracy: 0.6429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq1gecUfcQYc",
        "outputId": "d4fb849e-4d82-45be-da00-0147e5c6444f"
      },
      "source": [
        "model8.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6299672722816467, 0.6818181872367859]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-dxfJPucyXG"
      },
      "source": [
        "# Try dropouts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLvRD5cfUg2"
      },
      "source": [
        "df = pd.read_csv('/content/sample_data/iris.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wfm_fmKUfkj6",
        "outputId": "620e9b2f-166c-4cf9-e3f9-6834707a407d"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width    species\n",
              "0             5.1          3.5           1.4          0.2     setosa\n",
              "1             4.9          3.0           1.4          0.2     setosa\n",
              "2             4.7          3.2           1.3          0.2     setosa\n",
              "3             4.6          3.1           1.5          0.2     setosa\n",
              "4             5.0          3.6           1.4          0.2     setosa\n",
              "..            ...          ...           ...          ...        ...\n",
              "145           6.7          3.0           5.2          2.3  virginica\n",
              "146           6.3          2.5           5.0          1.9  virginica\n",
              "147           6.5          3.0           5.2          2.0  virginica\n",
              "148           6.2          3.4           5.4          2.3  virginica\n",
              "149           5.9          3.0           5.1          1.8  virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LaAjzBEkflR2",
        "outputId": "17ca7853-9593-4a74-912d-5d32a18f9fbf"
      },
      "source": [
        "X = df[['sepal_length','sepal_width', 'petal_length', 'petal_width']]\n",
        "# X = df.drop(columns='Outcome')\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "0             5.1          3.5           1.4          0.2\n",
              "1             4.9          3.0           1.4          0.2\n",
              "2             4.7          3.2           1.3          0.2\n",
              "3             4.6          3.1           1.5          0.2\n",
              "4             5.0          3.6           1.4          0.2\n",
              "..            ...          ...           ...          ...\n",
              "145           6.7          3.0           5.2          2.3\n",
              "146           6.3          2.5           5.0          1.9\n",
              "147           6.5          3.0           5.2          2.0\n",
              "148           6.2          3.4           5.4          2.3\n",
              "149           5.9          3.0           5.1          1.8\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZAjG76wbftP4",
        "outputId": "c1117817-3aab-4781-d8a3-50b2cf90b9eb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       species\n",
              "0       setosa\n",
              "1       setosa\n",
              "2       setosa\n",
              "3       setosa\n",
              "4       setosa\n",
              "..         ...\n",
              "145  virginica\n",
              "146  virginica\n",
              "147  virginica\n",
              "148  virginica\n",
              "149  virginica\n",
              "\n",
              "[150 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bQttGJ8hDrk"
      },
      "source": [
        "df.species = pd.Categorical(df.species)\n",
        "df['species'] = df.species.cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pmcClTZ8hRH6",
        "outputId": "a3632418-45db-4930-8767-7da099ef3c53"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0             5.1          3.5           1.4          0.2        0\n",
              "1             4.9          3.0           1.4          0.2        0\n",
              "2             4.7          3.2           1.3          0.2        0\n",
              "3             4.6          3.1           1.5          0.2        0\n",
              "4             5.0          3.6           1.4          0.2        0\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3        2\n",
              "146           6.3          2.5           5.0          1.9        2\n",
              "147           6.5          3.0           5.2          2.0        2\n",
              "148           6.2          3.4           5.4          2.3        2\n",
              "149           5.9          3.0           5.1          1.8        2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "iWol7kI0hTJk",
        "outputId": "7089b069-05e8-4ee1-853c-cb77f8f792a3"
      },
      "source": [
        "y = df[['species']]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     species\n",
              "0          0\n",
              "1          0\n",
              "2          0\n",
              "3          0\n",
              "4          0\n",
              "..       ...\n",
              "145        2\n",
              "146        2\n",
              "147        2\n",
              "148        2\n",
              "149        2\n",
              "\n",
              "[150 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1EoegMThwlE",
        "outputId": "98ee4a73-e43c-4904-a671-6895fe8d0b46"
      },
      "source": [
        "model9.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_314 (Dense)            (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_315 (Dense)            (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBQDbHr1hyb1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzPWWzSFiGAw",
        "outputId": "6d5ae58a-e4f1-4451-f3c5-056a611fd755"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GokjXiT9iHm-",
        "outputId": "10e6bb35-a6ba-4b4c-a1e6-dbaf8bc0b646"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRH0Dw2fiKcd",
        "outputId": "2f0ea538-ba5a-4b6e-af3b-b9499af0ce4a"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFeUTPfHlIW7"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, 3)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hNoFK94lW9Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au8hTG-Ikhaq"
      },
      "source": [
        "model9 = Sequential()\n",
        "model9.add(Dense(8, activation='relu', input_shape=(4,)))\n",
        "model9.add(Dense(9, activation='relu'))\n",
        "model9.add(Dense(3, activation='softmax'))\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy5T03cHiMPI"
      },
      "source": [
        "# Compile model\n",
        "model9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model9.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL3VC9bHiU4d",
        "outputId": "34f2e8b9-1ff8-4ed3-e397-235a403ef498"
      },
      "source": [
        "history = model9.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=250,\n",
        "\n",
        "    validation_data=(X_val, y_val),\n",
        "     \n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3601 - accuracy: 0.9556 - val_loss: 0.2721 - val_accuracy: 1.0000\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.9556 - val_loss: 0.2707 - val_accuracy: 1.0000\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 0.9556 - val_loss: 0.2707 - val_accuracy: 1.0000\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3563 - accuracy: 0.9556 - val_loss: 0.2697 - val_accuracy: 1.0000\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3547 - accuracy: 0.9556 - val_loss: 0.2675 - val_accuracy: 1.0000\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3538 - accuracy: 0.9556 - val_loss: 0.2650 - val_accuracy: 1.0000\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3523 - accuracy: 0.9556 - val_loss: 0.2649 - val_accuracy: 1.0000\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3509 - accuracy: 0.9556 - val_loss: 0.2645 - val_accuracy: 1.0000\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3495 - accuracy: 0.9556 - val_loss: 0.2634 - val_accuracy: 1.0000\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3482 - accuracy: 0.9556 - val_loss: 0.2620 - val_accuracy: 1.0000\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3470 - accuracy: 0.9556 - val_loss: 0.2615 - val_accuracy: 1.0000\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3457 - accuracy: 0.9556 - val_loss: 0.2604 - val_accuracy: 1.0000\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3443 - accuracy: 0.9556 - val_loss: 0.2587 - val_accuracy: 1.0000\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3430 - accuracy: 0.9556 - val_loss: 0.2573 - val_accuracy: 1.0000\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3416 - accuracy: 0.9556 - val_loss: 0.2564 - val_accuracy: 1.0000\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3408 - accuracy: 0.9556 - val_loss: 0.2570 - val_accuracy: 1.0000\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3390 - accuracy: 0.9556 - val_loss: 0.2556 - val_accuracy: 1.0000\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3376 - accuracy: 0.9556 - val_loss: 0.2532 - val_accuracy: 1.0000\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3365 - accuracy: 0.9556 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3349 - accuracy: 0.9556 - val_loss: 0.2509 - val_accuracy: 1.0000\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3340 - accuracy: 0.9556 - val_loss: 0.2513 - val_accuracy: 1.0000\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3332 - accuracy: 0.9556 - val_loss: 0.2482 - val_accuracy: 1.0000\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3311 - accuracy: 0.9556 - val_loss: 0.2488 - val_accuracy: 1.0000\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.3310 - accuracy: 0.9556 - val_loss: 0.2460 - val_accuracy: 1.0000\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3286 - accuracy: 0.9556 - val_loss: 0.2478 - val_accuracy: 1.0000\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3271 - accuracy: 0.9556 - val_loss: 0.2482 - val_accuracy: 1.0000\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3257 - accuracy: 0.9556 - val_loss: 0.2467 - val_accuracy: 1.0000\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3245 - accuracy: 0.9556 - val_loss: 0.2451 - val_accuracy: 1.0000\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3231 - accuracy: 0.9556 - val_loss: 0.2431 - val_accuracy: 1.0000\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3215 - accuracy: 0.9556 - val_loss: 0.2420 - val_accuracy: 1.0000\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3203 - accuracy: 0.9556 - val_loss: 0.2399 - val_accuracy: 1.0000\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.9556 - val_loss: 0.2388 - val_accuracy: 1.0000\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 0.9556 - val_loss: 0.2372 - val_accuracy: 1.0000\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3162 - accuracy: 0.9556 - val_loss: 0.2358 - val_accuracy: 1.0000\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.9556 - val_loss: 0.2354 - val_accuracy: 1.0000\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3138 - accuracy: 0.9556 - val_loss: 0.2328 - val_accuracy: 1.0000\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3125 - accuracy: 0.9556 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3110 - accuracy: 0.9556 - val_loss: 0.2307 - val_accuracy: 1.0000\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3097 - accuracy: 0.9556 - val_loss: 0.2293 - val_accuracy: 1.0000\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.3083 - accuracy: 0.9556 - val_loss: 0.2298 - val_accuracy: 1.0000\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3069 - accuracy: 0.9556 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3056 - accuracy: 0.9556 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.3042 - accuracy: 0.9556 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3028 - accuracy: 0.9556 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3014 - accuracy: 0.9556 - val_loss: 0.2230 - val_accuracy: 1.0000\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3004 - accuracy: 0.9556 - val_loss: 0.2202 - val_accuracy: 1.0000\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2992 - accuracy: 0.9556 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2979 - accuracy: 0.9556 - val_loss: 0.2192 - val_accuracy: 1.0000\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.9556 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2947 - accuracy: 0.9556 - val_loss: 0.2190 - val_accuracy: 1.0000\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2935 - accuracy: 0.9556 - val_loss: 0.2171 - val_accuracy: 1.0000\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2947 - accuracy: 0.9556 - val_loss: 0.2190 - val_accuracy: 1.0000\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2908 - accuracy: 0.9556 - val_loss: 0.2153 - val_accuracy: 1.0000\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2893 - accuracy: 0.9556 - val_loss: 0.2132 - val_accuracy: 1.0000\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2882 - accuracy: 0.9556 - val_loss: 0.2120 - val_accuracy: 1.0000\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.9556 - val_loss: 0.2101 - val_accuracy: 1.0000\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2858 - accuracy: 0.9556 - val_loss: 0.2106 - val_accuracy: 1.0000\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2842 - accuracy: 0.9556 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2835 - accuracy: 0.9556 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2817 - accuracy: 0.9778 - val_loss: 0.2107 - val_accuracy: 1.0000\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2806 - accuracy: 0.9778 - val_loss: 0.2094 - val_accuracy: 1.0000\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2789 - accuracy: 0.9556 - val_loss: 0.2067 - val_accuracy: 1.0000\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2778 - accuracy: 0.9556 - val_loss: 0.2046 - val_accuracy: 1.0000\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2764 - accuracy: 0.9556 - val_loss: 0.2026 - val_accuracy: 1.0000\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2756 - accuracy: 0.9556 - val_loss: 0.2006 - val_accuracy: 1.0000\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2739 - accuracy: 0.9556 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2735 - accuracy: 0.9556 - val_loss: 0.2030 - val_accuracy: 1.0000\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2714 - accuracy: 0.9778 - val_loss: 0.2027 - val_accuracy: 1.0000\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2701 - accuracy: 0.9778 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2694 - accuracy: 0.9778 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2674 - accuracy: 0.9778 - val_loss: 0.1976 - val_accuracy: 1.0000\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2662 - accuracy: 0.9667 - val_loss: 0.1949 - val_accuracy: 1.0000\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2651 - accuracy: 0.9556 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2637 - accuracy: 0.9556 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2624 - accuracy: 0.9556 - val_loss: 0.1921 - val_accuracy: 1.0000\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.9556 - val_loss: 0.1912 - val_accuracy: 1.0000\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.9667 - val_loss: 0.1927 - val_accuracy: 1.0000\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2588 - accuracy: 0.9778 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2574 - accuracy: 0.9778 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 0.9778 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2550 - accuracy: 0.9778 - val_loss: 0.1900 - val_accuracy: 1.0000\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9778 - val_loss: 0.1871 - val_accuracy: 1.0000\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2535 - accuracy: 0.9778 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2516 - accuracy: 0.9667 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2502 - accuracy: 0.9667 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2491 - accuracy: 0.9778 - val_loss: 0.1838 - val_accuracy: 1.0000\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2481 - accuracy: 0.9778 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2465 - accuracy: 0.9778 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2457 - accuracy: 0.9778 - val_loss: 0.1807 - val_accuracy: 1.0000\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2442 - accuracy: 0.9778 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2429 - accuracy: 0.9778 - val_loss: 0.1775 - val_accuracy: 1.0000\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2419 - accuracy: 0.9778 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2405 - accuracy: 0.9667 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2394 - accuracy: 0.9667 - val_loss: 0.1738 - val_accuracy: 1.0000\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2381 - accuracy: 0.9778 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2368 - accuracy: 0.9778 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2358 - accuracy: 0.9778 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2351 - accuracy: 0.9667 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2336 - accuracy: 0.9778 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2326 - accuracy: 0.9778 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2313 - accuracy: 0.9778 - val_loss: 0.1687 - val_accuracy: 1.0000\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2301 - accuracy: 0.9778 - val_loss: 0.1675 - val_accuracy: 1.0000\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2292 - accuracy: 0.9778 - val_loss: 0.1664 - val_accuracy: 1.0000\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2279 - accuracy: 0.9778 - val_loss: 0.1676 - val_accuracy: 1.0000\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2271 - accuracy: 0.9778 - val_loss: 0.1686 - val_accuracy: 1.0000\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2256 - accuracy: 0.9778 - val_loss: 0.1673 - val_accuracy: 1.0000\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2251 - accuracy: 0.9778 - val_loss: 0.1642 - val_accuracy: 1.0000\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2235 - accuracy: 0.9778 - val_loss: 0.1637 - val_accuracy: 1.0000\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2223 - accuracy: 0.9778 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2214 - accuracy: 0.9778 - val_loss: 0.1630 - val_accuracy: 1.0000\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2205 - accuracy: 0.9778 - val_loss: 0.1607 - val_accuracy: 1.0000\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2190 - accuracy: 0.9778 - val_loss: 0.1604 - val_accuracy: 1.0000\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9778 - val_loss: 0.1595 - val_accuracy: 1.0000\n",
            "Epoch 114/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2169 - accuracy: 0.9778 - val_loss: 0.1586 - val_accuracy: 1.0000\n",
            "Epoch 115/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2160 - accuracy: 0.9778 - val_loss: 0.1577 - val_accuracy: 1.0000\n",
            "Epoch 116/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2147 - accuracy: 0.9778 - val_loss: 0.1583 - val_accuracy: 1.0000\n",
            "Epoch 117/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2141 - accuracy: 0.9778 - val_loss: 0.1589 - val_accuracy: 1.0000\n",
            "Epoch 118/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2128 - accuracy: 0.9778 - val_loss: 0.1568 - val_accuracy: 1.0000\n",
            "Epoch 119/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9778 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
            "Epoch 120/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2106 - accuracy: 0.9778 - val_loss: 0.1544 - val_accuracy: 1.0000\n",
            "Epoch 121/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2094 - accuracy: 0.9778 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
            "Epoch 122/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 0.9778 - val_loss: 0.1512 - val_accuracy: 1.0000\n",
            "Epoch 123/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2079 - accuracy: 0.9778 - val_loss: 0.1493 - val_accuracy: 1.0000\n",
            "Epoch 124/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2073 - accuracy: 0.9778 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
            "Epoch 125/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2073 - accuracy: 0.9778 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
            "Epoch 126/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2059 - accuracy: 0.9667 - val_loss: 0.1537 - val_accuracy: 1.0000\n",
            "Epoch 127/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2036 - accuracy: 0.9667 - val_loss: 0.1511 - val_accuracy: 1.0000\n",
            "Epoch 128/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2028 - accuracy: 0.9778 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
            "Epoch 129/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2016 - accuracy: 0.9778 - val_loss: 0.1449 - val_accuracy: 1.0000\n",
            "Epoch 130/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2008 - accuracy: 0.9778 - val_loss: 0.1448 - val_accuracy: 1.0000\n",
            "Epoch 131/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1999 - accuracy: 0.9778 - val_loss: 0.1448 - val_accuracy: 1.0000\n",
            "Epoch 132/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1987 - accuracy: 0.9778 - val_loss: 0.1435 - val_accuracy: 1.0000\n",
            "Epoch 133/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1982 - accuracy: 0.9778 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
            "Epoch 134/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1970 - accuracy: 0.9778 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
            "Epoch 135/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1958 - accuracy: 0.9778 - val_loss: 0.1449 - val_accuracy: 1.0000\n",
            "Epoch 136/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1951 - accuracy: 0.9778 - val_loss: 0.1442 - val_accuracy: 1.0000\n",
            "Epoch 137/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1942 - accuracy: 0.9778 - val_loss: 0.1450 - val_accuracy: 1.0000\n",
            "Epoch 138/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1933 - accuracy: 0.9778 - val_loss: 0.1435 - val_accuracy: 1.0000\n",
            "Epoch 139/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1925 - accuracy: 0.9778 - val_loss: 0.1421 - val_accuracy: 1.0000\n",
            "Epoch 140/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1912 - accuracy: 0.9778 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
            "Epoch 141/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9778 - val_loss: 0.1384 - val_accuracy: 1.0000\n",
            "Epoch 142/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.9778 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
            "Epoch 143/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1887 - accuracy: 0.9778 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
            "Epoch 144/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1878 - accuracy: 0.9778 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
            "Epoch 145/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1875 - accuracy: 0.9778 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
            "Epoch 146/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1862 - accuracy: 0.9778 - val_loss: 0.1344 - val_accuracy: 1.0000\n",
            "Epoch 147/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.9778 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
            "Epoch 148/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9778 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
            "Epoch 149/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1836 - accuracy: 0.9778 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
            "Epoch 150/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.9778 - val_loss: 0.1355 - val_accuracy: 1.0000\n",
            "Epoch 151/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1818 - accuracy: 0.9778 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
            "Epoch 152/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1820 - accuracy: 0.9778 - val_loss: 0.1328 - val_accuracy: 1.0000\n",
            "Epoch 153/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1804 - accuracy: 0.9778 - val_loss: 0.1344 - val_accuracy: 1.0000\n",
            "Epoch 154/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1795 - accuracy: 0.9667 - val_loss: 0.1339 - val_accuracy: 1.0000\n",
            "Epoch 155/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1785 - accuracy: 0.9778 - val_loss: 0.1319 - val_accuracy: 1.0000\n",
            "Epoch 156/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1783 - accuracy: 0.9778 - val_loss: 0.1283 - val_accuracy: 1.0000\n",
            "Epoch 157/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1770 - accuracy: 0.9778 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
            "Epoch 158/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1762 - accuracy: 0.9778 - val_loss: 0.1266 - val_accuracy: 1.0000\n",
            "Epoch 159/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1754 - accuracy: 0.9778 - val_loss: 0.1269 - val_accuracy: 1.0000\n",
            "Epoch 160/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1746 - accuracy: 0.9778 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
            "Epoch 161/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1739 - accuracy: 0.9778 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
            "Epoch 162/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1730 - accuracy: 0.9778 - val_loss: 0.1277 - val_accuracy: 1.0000\n",
            "Epoch 163/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1727 - accuracy: 0.9778 - val_loss: 0.1283 - val_accuracy: 1.0000\n",
            "Epoch 164/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1715 - accuracy: 0.9778 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
            "Epoch 165/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1707 - accuracy: 0.9778 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
            "Epoch 166/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.9778 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
            "Epoch 167/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1696 - accuracy: 0.9778 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
            "Epoch 168/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1686 - accuracy: 0.9778 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
            "Epoch 169/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1681 - accuracy: 0.9778 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
            "Epoch 170/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1671 - accuracy: 0.9778 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
            "Epoch 171/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1664 - accuracy: 0.9778 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
            "Epoch 172/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1657 - accuracy: 0.9778 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
            "Epoch 173/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.9778 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
            "Epoch 174/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9778 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
            "Epoch 175/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1634 - accuracy: 0.9778 - val_loss: 0.1193 - val_accuracy: 1.0000\n",
            "Epoch 176/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9778 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
            "Epoch 177/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1620 - accuracy: 0.9778 - val_loss: 0.1171 - val_accuracy: 1.0000\n",
            "Epoch 178/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1616 - accuracy: 0.9778 - val_loss: 0.1158 - val_accuracy: 1.0000\n",
            "Epoch 179/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1609 - accuracy: 0.9778 - val_loss: 0.1170 - val_accuracy: 1.0000\n",
            "Epoch 180/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1602 - accuracy: 0.9778 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
            "Epoch 181/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1595 - accuracy: 0.9778 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
            "Epoch 182/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 0.9778 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
            "Epoch 183/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1584 - accuracy: 0.9778 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
            "Epoch 184/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1578 - accuracy: 0.9778 - val_loss: 0.1137 - val_accuracy: 1.0000\n",
            "Epoch 185/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.9778 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
            "Epoch 186/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1563 - accuracy: 0.9667 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
            "Epoch 187/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1556 - accuracy: 0.9667 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
            "Epoch 188/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1549 - accuracy: 0.9667 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
            "Epoch 189/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1542 - accuracy: 0.9778 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
            "Epoch 190/250\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1535 - accuracy: 0.9778 - val_loss: 0.1101 - val_accuracy: 1.0000\n",
            "Epoch 191/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1534 - accuracy: 0.9778 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
            "Epoch 192/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1523 - accuracy: 0.9778 - val_loss: 0.1102 - val_accuracy: 1.0000\n",
            "Epoch 193/250\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1517 - accuracy: 0.9778 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
            "Epoch 194/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1511 - accuracy: 0.9778 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
            "Epoch 195/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1507 - accuracy: 0.9778 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
            "Epoch 196/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1499 - accuracy: 0.9778 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
            "Epoch 197/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1495 - accuracy: 0.9778 - val_loss: 0.1096 - val_accuracy: 1.0000\n",
            "Epoch 198/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1487 - accuracy: 0.9778 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
            "Epoch 199/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1481 - accuracy: 0.9778 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
            "Epoch 200/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1477 - accuracy: 0.9778 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
            "Epoch 201/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1471 - accuracy: 0.9778 - val_loss: 0.1089 - val_accuracy: 1.0000\n",
            "Epoch 202/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1464 - accuracy: 0.9778 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
            "Epoch 203/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1458 - accuracy: 0.9778 - val_loss: 0.1051 - val_accuracy: 1.0000\n",
            "Epoch 204/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1454 - accuracy: 0.9778 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
            "Epoch 205/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1455 - accuracy: 0.9778 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
            "Epoch 206/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1446 - accuracy: 0.9778 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
            "Epoch 207/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1438 - accuracy: 0.9778 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
            "Epoch 208/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1432 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 1.0000\n",
            "Epoch 209/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9778 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
            "Epoch 210/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1420 - accuracy: 0.9778 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
            "Epoch 211/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1415 - accuracy: 0.9778 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
            "Epoch 212/250\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1411 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 1.0000\n",
            "Epoch 213/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1404 - accuracy: 0.9778 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
            "Epoch 214/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1399 - accuracy: 0.9778 - val_loss: 0.1029 - val_accuracy: 1.0000\n",
            "Epoch 215/250\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1394 - accuracy: 0.9778 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
            "Epoch 216/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1390 - accuracy: 0.9778 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
            "Epoch 217/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1383 - accuracy: 0.9778 - val_loss: 0.1030 - val_accuracy: 1.0000\n",
            "Epoch 218/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1381 - accuracy: 0.9778 - val_loss: 0.1032 - val_accuracy: 1.0000\n",
            "Epoch 219/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1374 - accuracy: 0.9778 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
            "Epoch 220/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1367 - accuracy: 0.9778 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
            "Epoch 221/250\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1364 - accuracy: 0.9778 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
            "Epoch 222/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1374 - accuracy: 0.9778 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
            "Epoch 223/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1358 - accuracy: 0.9778 - val_loss: 0.0957 - val_accuracy: 1.0000\n",
            "Epoch 224/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1359 - accuracy: 0.9778 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
            "Epoch 225/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1349 - accuracy: 0.9667 - val_loss: 0.1045 - val_accuracy: 1.0000\n",
            "Epoch 226/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1342 - accuracy: 0.9667 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
            "Epoch 227/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1336 - accuracy: 0.9667 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
            "Epoch 228/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1334 - accuracy: 0.9778 - val_loss: 0.0969 - val_accuracy: 1.0000\n",
            "Epoch 229/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1329 - accuracy: 0.9778 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 230/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1320 - accuracy: 0.9778 - val_loss: 0.0958 - val_accuracy: 1.0000\n",
            "Epoch 231/250\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1325 - accuracy: 0.9778 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
            "Epoch 232/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1317 - accuracy: 0.9778 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
            "Epoch 233/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1307 - accuracy: 0.9778 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
            "Epoch 234/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1300 - accuracy: 0.9778 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
            "Epoch 235/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1303 - accuracy: 0.9778 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
            "Epoch 236/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1303 - accuracy: 0.9667 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
            "Epoch 237/250\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1291 - accuracy: 0.9667 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
            "Epoch 238/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1287 - accuracy: 0.9778 - val_loss: 0.0952 - val_accuracy: 1.0000\n",
            "Epoch 239/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1286 - accuracy: 0.9778 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 240/250\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1278 - accuracy: 0.9778 - val_loss: 0.0925 - val_accuracy: 1.0000\n",
            "Epoch 241/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1272 - accuracy: 0.9778 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
            "Epoch 242/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1275 - accuracy: 0.9778 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
            "Epoch 243/250\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1267 - accuracy: 0.9778 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
            "Epoch 244/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1263 - accuracy: 0.9778 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
            "Epoch 245/250\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1258 - accuracy: 0.9778 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
            "Epoch 246/250\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1253 - accuracy: 0.9778 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
            "Epoch 247/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1250 - accuracy: 0.9778 - val_loss: 0.0929 - val_accuracy: 1.0000\n",
            "Epoch 248/250\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1252 - accuracy: 0.9778 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
            "Epoch 249/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1241 - accuracy: 0.9778 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
            "Epoch 250/250\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1236 - accuracy: 0.9778 - val_loss: 0.0902 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iztEijufiaVz",
        "outputId": "626da771-03cc-4101-b72c-ab816ba6e72f"
      },
      "source": [
        "model9.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1031 - accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10306072980165482, 0.9666666388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1IaRs0_i0ec"
      },
      "source": [
        "t1= X_test[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPf1Zwysm0FK",
        "outputId": "f5e8f8f3-ca31-4822-dc9a-9c3f8b1e63af"
      },
      "source": [
        "print(t1, y_test[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width\n",
            "73            6.1          2.8           4.7          1.2\n",
            "31            5.4          3.4           1.5          0.4\n",
            "51            6.4          3.2           4.5          1.5\n",
            "81            5.5          2.4           3.7          1.0\n",
            "9             4.9          3.1           1.5          0.1\n",
            "122           7.7          2.8           6.7          2.0\n",
            "11            4.8          3.4           1.6          0.2\n",
            "75            6.6          3.0           4.4          1.4\n",
            "36            5.5          3.5           1.3          0.2\n",
            "40            5.0          3.5           1.3          0.3\n",
            "133           6.3          2.8           5.1          1.5\n",
            "96            5.7          2.9           4.2          1.3\n",
            "15            5.7          4.4           1.5          0.4\n",
            "78            6.0          2.9           4.5          1.5\n",
            "66            5.6          3.0           4.5          1.5\n",
            "69            5.6          2.5           3.9          1.1\n",
            "68            6.2          2.2           4.5          1.5\n",
            "64            5.6          2.9           3.6          1.3\n",
            "142           5.8          2.7           5.1          1.9\n",
            "76            6.8          2.8           4.8          1.4 [[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UxosatPm0ln"
      },
      "source": [
        "import numpy as np\n",
        "prediction = np.round(model9.predict(t1),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-luOLNrnACP",
        "outputId": "aa5cc737-9fb2-4c00-867e-909b0e1547b7"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIOTtCpVnu1o",
        "outputId": "f1997fbb-0f73-441f-d989-09dc9bf6623a"
      },
      "source": [
        "for i in range(len(prediction)):\n",
        "  print(prediction[i], y_test[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.87 0.13] [0. 1. 0.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[0.   0.95 0.05] [0. 1. 0.]\n",
            "[0.01 0.96 0.03] [0. 1. 0.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[0.   0.01 0.99] [0. 0. 1.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[0.   0.96 0.04] [0. 1. 0.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[0.   0.48 0.52] [0. 0. 1.]\n",
            "[0.   0.94 0.06] [0. 1. 0.]\n",
            "[1. 0. 0.] [1. 0. 0.]\n",
            "[0.   0.82 0.18] [0. 1. 0.]\n",
            "[0.   0.81 0.18] [0. 1. 0.]\n",
            "[0.   0.95 0.05] [0. 1. 0.]\n",
            "[0.   0.36 0.64] [0. 1. 0.]\n",
            "[0.01 0.98 0.01] [0. 1. 0.]\n",
            "[0.   0.08 0.92] [0. 0. 1.]\n",
            "[0.   0.83 0.17] [0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94LPz83oTc6"
      },
      "source": [
        "# Try this one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZsaTwNuzpIdf",
        "outputId": "9e28907e-9d27-4aa4-8975-529543882946"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train loss', 'val loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhQ2VGuLpMFQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}