{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3wHdBsD0ViMl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S_ZG9_U2VtVl"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', input_shape=(3,)))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              \n",
    "              metrics=['accuracy'])\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP54ffu_PN7A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "370eDn11V149",
    "outputId": "566b9285-d0ed-456a-8ee5-26f74431014b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NuE_onGfPPZr"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='relu', input_shape=(3,)))\n",
    "\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbS3b_iQPS3H",
    "outputId": "655df989-21a2-4f7d-aed2-d9f248c9a2c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cPOa5M9YV5a8"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uUoHNLvFY_vn"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='relu', input_shape=(2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-0HvmXBeZXd0"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zC_x-iRmZdjD",
    "outputId": "59a89abd-4b18-4a8a-c96d-6d72d2ebd744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LEY_ggLpZgC5"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBX7DmcmbLIk",
    "outputId": "d4229f36-8254-47ac-c6e4-23ff1b95d9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 359\n",
      "Trainable params: 359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cwizSmSJbcDG"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, activation='relu', input_shape=(2,)))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tDh817jciI1",
    "outputId": "31f65d3c-7d6b-48a8-feff-2cbede2d5d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s8lenUgqcjwO"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xak7FHxacx3T",
    "outputId": "1088da6f-76f0-4cb2-9871-fe423015d4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sItdqVRcc1DE"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xfOubpOdE6k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uqMdcFL3drwb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gOqXclHJdwI8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "1QDcIzC1eoBP",
    "outputId": "1740fa87-20b5-4c7c-f192-d3f25eb24da3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "KrVlbaHue3JT",
    "outputId": "e6b569fc-6ac0-467a-f8ab-e195a1383678"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='Outcome')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "fLJu6citfCw0",
    "outputId": "e2f97b7b-cd57-4515-c95b-4ce05e65b9dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "763        0\n",
       "764        0\n",
       "765        0\n",
       "766        1\n",
       "767        0\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[['Outcome']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7FqXiVOfHz7",
    "outputId": "fcf531d7-9e91-400f-a7d9-b5853ae40d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 25.8995 - accuracy: 0.4167\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.8852 - accuracy: 0.6042\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5976 - accuracy: 0.5885\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1084 - accuracy: 0.6328\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7846 - accuracy: 0.6328\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6706\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6784\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7134 - accuracy: 0.6484\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6497\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6589\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.6797\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6693\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6758\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6706\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6680\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6966\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.6862\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.7005\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.6966\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.7083\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6979\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.7044\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7070\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7240\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.7083\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.7122\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7344\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6979\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7083\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7135\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5692 - accuracy: 0.7044\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.7109\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.7057\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7292\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7161\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5551 - accuracy: 0.7174\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7148\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7318\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7292\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7188\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7174\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7214\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7305\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7161\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7148\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7214\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7083\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7188\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7253\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5251 - accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7148\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7422\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7409\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7214\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7240\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7318\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7383\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7344\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7409\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7227\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7266\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7461\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7513\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7513\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7201\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7643\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7435\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7292\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7318\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7305\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7396\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7357\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7422\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7565\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7513\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7409\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7643\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7591\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7344\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7474\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7383\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7435\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7591\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7474\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7357\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7487\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7513\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7357\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7448\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7526\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7513\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7448\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7526\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7448\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7422\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b4531430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi-HQ8-IgQOH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "c0VTA_WahrOH"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(24, activation='relu', input_shape=(8,)))\n",
    "model1.add(Dense(12, activation='relu'))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iWkaNaTsh61R"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRJItw46h-5P",
    "outputId": "a02cb82f-d4e8-4be8-eefd-07de4a44de80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 2.5421 - accuracy: 0.4505\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.9829 - accuracy: 0.5859\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.6237\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6654\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6719\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6810\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6810\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6927\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.6888\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7044\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.6888\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6797\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6953\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7122\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7109\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7135\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7031\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7174\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6654\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6810\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7148\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7253\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7214\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7279\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7096\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7279\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7201\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7096\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7188\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7122\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7135\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7253\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7422\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7344\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7122\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7214\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7357\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7201\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7383\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7318\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7396\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7448\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7240\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7331\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7396\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7448\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7474\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7344\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7409\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7383\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7344\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7409\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7461\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7344\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7565\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7487\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7578\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7461\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7240\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7383\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7487\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7422\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7357\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7604\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7539\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7578\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7448\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7617\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7656\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7565\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7448\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7461\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7656\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7643\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7474\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7617\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7539\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7461\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7396\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7487\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7565\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7565\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7539\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7461\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7630\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7630\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7552\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7513\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7630\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7552\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7578\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b6d11eb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NDX2tdloiHhT"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model2.add(Dense(24, activation='relu'))\n",
    "model2.add(Dense(12, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "hyB8ylGbiq2M"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWPDSCfwiuOD",
    "outputId": "60aa34c8-7ce3-4950-9d0d-0e6dcccf0b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 2s 2ms/step - loss: 0.7723 - accuracy: 0.5794\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.6159\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6641\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6823\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6641\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.6732\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.7044\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.7005\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6953\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7070\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7044\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7148\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7096\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6927\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6979\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7070\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7161\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7122\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7383\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7227\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7331\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7474\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7266\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7279\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7305\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7201\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7357\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7266\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7396\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7292\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7383\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7552\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7474\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7409\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7357\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7487\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7461\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7513\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7617\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7461\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7526\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7578\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7617\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7643\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7474\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7643\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7695\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7448\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7591\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7604\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7539\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7565\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7630\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7630\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7669\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7461\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7591\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7747\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7487\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7656\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7682\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7734\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7669\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7630\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7669\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7904\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7734\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7708\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7708\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7852\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7865\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7773\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7695\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7812\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7721\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7878\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7799\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7591\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7760\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7904\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7982\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7852\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7891\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7604\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7799\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7904\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7904\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7760\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7943\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7917\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7812\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7956\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7760\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7812\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7969\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7865\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7891\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7917\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7799\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b70a7790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "__yQ6gTUixVS"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model3.add(Dense(24, activation='relu'))\n",
    "model3.add(Dense(36, activation='relu'))\n",
    "model3.add(Dense(24, activation='relu'))\n",
    "model3.add(Dense(12, activation='relu'))\n",
    "model3.add(Dense(8, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9bhA3SZ4jUUa"
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yVqo-JVjXob",
    "outputId": "733acbab-2ee4-4b81-b418-9b0694f67bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "77/77 [==============================] - 2s 2ms/step - loss: 0.9083 - accuracy: 0.6055\n",
      "Epoch 2/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6549\n",
      "Epoch 3/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6706\n",
      "Epoch 4/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6719\n",
      "Epoch 5/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6849\n",
      "Epoch 6/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6823\n",
      "Epoch 7/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6953\n",
      "Epoch 8/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7031\n",
      "Epoch 9/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6849\n",
      "Epoch 10/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6914\n",
      "Epoch 11/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6927\n",
      "Epoch 12/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7083\n",
      "Epoch 13/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6979\n",
      "Epoch 14/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7122\n",
      "Epoch 15/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7253\n",
      "Epoch 16/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7201\n",
      "Epoch 17/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7214\n",
      "Epoch 18/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7357\n",
      "Epoch 19/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7135\n",
      "Epoch 20/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7109\n",
      "Epoch 21/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7135\n",
      "Epoch 22/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7253\n",
      "Epoch 23/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7214\n",
      "Epoch 24/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7370\n",
      "Epoch 25/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7448\n",
      "Epoch 26/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7279\n",
      "Epoch 27/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7214\n",
      "Epoch 28/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7370\n",
      "Epoch 29/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7266\n",
      "Epoch 30/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7279\n",
      "Epoch 31/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7292\n",
      "Epoch 32/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7552\n",
      "Epoch 33/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7448\n",
      "Epoch 34/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7474\n",
      "Epoch 35/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7591\n",
      "Epoch 36/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7617\n",
      "Epoch 37/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7617\n",
      "Epoch 38/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7643\n",
      "Epoch 39/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7552\n",
      "Epoch 40/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7500\n",
      "Epoch 41/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7461\n",
      "Epoch 42/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7448\n",
      "Epoch 43/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7604\n",
      "Epoch 44/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7747\n",
      "Epoch 45/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7552\n",
      "Epoch 46/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7760\n",
      "Epoch 47/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7513\n",
      "Epoch 48/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7526\n",
      "Epoch 49/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7565\n",
      "Epoch 50/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7500\n",
      "Epoch 51/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7448\n",
      "Epoch 52/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7656\n",
      "Epoch 53/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7617\n",
      "Epoch 54/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7552\n",
      "Epoch 55/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7682\n",
      "Epoch 56/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7630\n",
      "Epoch 57/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7760\n",
      "Epoch 58/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7643\n",
      "Epoch 59/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7461\n",
      "Epoch 60/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7734\n",
      "Epoch 61/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7682\n",
      "Epoch 62/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7721\n",
      "Epoch 63/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7891\n",
      "Epoch 64/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7669\n",
      "Epoch 65/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7526\n",
      "Epoch 66/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7786\n",
      "Epoch 67/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7865\n",
      "Epoch 68/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7917\n",
      "Epoch 69/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7852\n",
      "Epoch 70/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7930\n",
      "Epoch 71/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7982\n",
      "Epoch 72/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7826\n",
      "Epoch 73/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7682\n",
      "Epoch 74/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7799\n",
      "Epoch 75/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7852\n",
      "Epoch 76/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7852\n",
      "Epoch 77/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8008\n",
      "Epoch 78/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7943\n",
      "Epoch 79/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7969\n",
      "Epoch 80/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7760\n",
      "Epoch 81/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7786\n",
      "Epoch 82/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7852\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8060\n",
      "Epoch 84/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7969\n",
      "Epoch 85/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7852\n",
      "Epoch 86/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.8034\n",
      "Epoch 87/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7878\n",
      "Epoch 88/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7786\n",
      "Epoch 89/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7995\n",
      "Epoch 90/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7826\n",
      "Epoch 91/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7799\n",
      "Epoch 92/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7995\n",
      "Epoch 93/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8086\n",
      "Epoch 94/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.7995\n",
      "Epoch 95/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7891\n",
      "Epoch 96/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8112\n",
      "Epoch 97/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7917\n",
      "Epoch 98/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7917\n",
      "Epoch 99/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8086\n",
      "Epoch 100/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8073\n",
      "Epoch 101/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8125\n",
      "Epoch 102/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7982\n",
      "Epoch 103/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8086\n",
      "Epoch 104/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8125\n",
      "Epoch 105/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8112\n",
      "Epoch 106/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8047\n",
      "Epoch 107/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8138\n",
      "Epoch 108/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8099\n",
      "Epoch 109/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8073\n",
      "Epoch 110/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8086\n",
      "Epoch 111/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8021\n",
      "Epoch 112/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8073\n",
      "Epoch 113/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8021\n",
      "Epoch 114/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8099\n",
      "Epoch 115/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8034\n",
      "Epoch 116/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969\n",
      "Epoch 117/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8086\n",
      "Epoch 118/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8086\n",
      "Epoch 119/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8125\n",
      "Epoch 120/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8151\n",
      "Epoch 121/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8177\n",
      "Epoch 122/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.7943\n",
      "Epoch 123/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8229\n",
      "Epoch 124/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7982\n",
      "Epoch 125/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8151\n",
      "Epoch 126/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8034\n",
      "Epoch 127/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8138\n",
      "Epoch 128/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8190\n",
      "Epoch 129/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8138\n",
      "Epoch 130/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8294\n",
      "Epoch 131/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8008\n",
      "Epoch 132/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8138\n",
      "Epoch 133/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8151\n",
      "Epoch 134/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8242\n",
      "Epoch 135/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8242\n",
      "Epoch 136/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8242\n",
      "Epoch 137/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8125\n",
      "Epoch 138/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8372\n",
      "Epoch 139/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8177\n",
      "Epoch 140/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8294\n",
      "Epoch 141/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8190\n",
      "Epoch 142/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8190\n",
      "Epoch 143/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8216\n",
      "Epoch 144/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8307\n",
      "Epoch 145/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8281\n",
      "Epoch 146/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8242\n",
      "Epoch 147/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8424\n",
      "Epoch 148/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8112\n",
      "Epoch 149/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8281\n",
      "Epoch 150/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8346\n",
      "Epoch 151/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8060\n",
      "Epoch 152/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8307\n",
      "Epoch 153/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8255\n",
      "Epoch 154/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8281\n",
      "Epoch 155/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8060\n",
      "Epoch 156/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8229\n",
      "Epoch 157/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8294\n",
      "Epoch 158/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8307\n",
      "Epoch 159/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8268\n",
      "Epoch 160/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.8320\n",
      "Epoch 161/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8359\n",
      "Epoch 162/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8242\n",
      "Epoch 163/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8438\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8281\n",
      "Epoch 165/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8490\n",
      "Epoch 166/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8451\n",
      "Epoch 167/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8255\n",
      "Epoch 168/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8307\n",
      "Epoch 169/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8125\n",
      "Epoch 170/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8320\n",
      "Epoch 171/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8307\n",
      "Epoch 172/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8333\n",
      "Epoch 173/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8464\n",
      "Epoch 174/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8424\n",
      "Epoch 175/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8359\n",
      "Epoch 176/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8438\n",
      "Epoch 177/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8411\n",
      "Epoch 178/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8451\n",
      "Epoch 179/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8503\n",
      "Epoch 180/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8438\n",
      "Epoch 181/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8542\n",
      "Epoch 182/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8503\n",
      "Epoch 183/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8438\n",
      "Epoch 184/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8294\n",
      "Epoch 185/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8281\n",
      "Epoch 186/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8581\n",
      "Epoch 187/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8138\n",
      "Epoch 188/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8294\n",
      "Epoch 189/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8581\n",
      "Epoch 190/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8503\n",
      "Epoch 191/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8451\n",
      "Epoch 192/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8516\n",
      "Epoch 193/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8464\n",
      "Epoch 194/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8542\n",
      "Epoch 195/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8503\n",
      "Epoch 196/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8451\n",
      "Epoch 197/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8529\n",
      "Epoch 198/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8607\n",
      "Epoch 199/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8607\n",
      "Epoch 200/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8542\n",
      "Epoch 201/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8464\n",
      "Epoch 202/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8542\n",
      "Epoch 203/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8633\n",
      "Epoch 204/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8607\n",
      "Epoch 205/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8542\n",
      "Epoch 206/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8620\n",
      "Epoch 207/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8568\n",
      "Epoch 208/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8451\n",
      "Epoch 209/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8424\n",
      "Epoch 210/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8555\n",
      "Epoch 211/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8711\n",
      "Epoch 212/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8516\n",
      "Epoch 213/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8633\n",
      "Epoch 214/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8672\n",
      "Epoch 215/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8529\n",
      "Epoch 216/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8490\n",
      "Epoch 217/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8750\n",
      "Epoch 218/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8763\n",
      "Epoch 219/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8724\n",
      "Epoch 220/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8555\n",
      "Epoch 221/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8620\n",
      "Epoch 222/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2924 - accuracy: 0.8815\n",
      "Epoch 223/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2847 - accuracy: 0.8633\n",
      "Epoch 224/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8750\n",
      "Epoch 225/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8854\n",
      "Epoch 226/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8750\n",
      "Epoch 227/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8594\n",
      "Epoch 228/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8451\n",
      "Epoch 229/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8672\n",
      "Epoch 230/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8685\n",
      "Epoch 231/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8607\n",
      "Epoch 232/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8711\n",
      "Epoch 233/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.8815\n",
      "Epoch 234/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8854\n",
      "Epoch 235/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2633 - accuracy: 0.8867\n",
      "Epoch 236/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8893\n",
      "Epoch 237/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8659\n",
      "Epoch 238/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8750\n",
      "Epoch 239/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8698\n",
      "Epoch 240/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8411\n",
      "Epoch 241/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8633\n",
      "Epoch 242/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8776\n",
      "Epoch 243/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8776\n",
      "Epoch 244/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8464\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8828\n",
      "Epoch 246/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8815\n",
      "Epoch 247/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.8802\n",
      "Epoch 248/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8854\n",
      "Epoch 249/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8776\n",
      "Epoch 250/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.8932\n",
      "Epoch 251/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8906\n",
      "Epoch 252/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8659\n",
      "Epoch 253/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8802\n",
      "Epoch 254/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9023\n",
      "Epoch 255/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.8685\n",
      "Epoch 256/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8802\n",
      "Epoch 257/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8919\n",
      "Epoch 258/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.8997\n",
      "Epoch 259/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8919\n",
      "Epoch 260/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8841\n",
      "Epoch 261/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8906\n",
      "Epoch 262/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2562 - accuracy: 0.8958\n",
      "Epoch 263/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8776\n",
      "Epoch 264/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.8893\n",
      "Epoch 265/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8750\n",
      "Epoch 266/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.8997\n",
      "Epoch 267/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8893\n",
      "Epoch 268/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8815\n",
      "Epoch 269/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8867\n",
      "Epoch 270/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8893\n",
      "Epoch 271/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8945\n",
      "Epoch 272/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8815\n",
      "Epoch 273/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.8997\n",
      "Epoch 274/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8958\n",
      "Epoch 275/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.8880\n",
      "Epoch 276/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2623 - accuracy: 0.8789\n",
      "Epoch 277/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8828\n",
      "Epoch 278/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8958\n",
      "Epoch 279/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8958\n",
      "Epoch 280/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8776\n",
      "Epoch 281/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8828\n",
      "Epoch 282/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8880\n",
      "Epoch 283/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.8984\n",
      "Epoch 284/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8854\n",
      "Epoch 285/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.8724\n",
      "Epoch 286/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8815\n",
      "Epoch 287/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9023\n",
      "Epoch 288/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.8997\n",
      "Epoch 289/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.8958\n",
      "Epoch 290/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9089\n",
      "Epoch 291/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8841\n",
      "Epoch 292/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.8789\n",
      "Epoch 293/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.8906\n",
      "Epoch 294/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9062\n",
      "Epoch 295/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9193\n",
      "Epoch 296/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9167\n",
      "Epoch 297/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8945\n",
      "Epoch 298/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.8815\n",
      "Epoch 299/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.8893\n",
      "Epoch 300/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8594\n",
      "Epoch 301/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8867\n",
      "Epoch 302/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8932\n",
      "Epoch 303/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8971\n",
      "Epoch 304/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9010\n",
      "Epoch 305/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.8893\n",
      "Epoch 306/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9023\n",
      "Epoch 307/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9219\n",
      "Epoch 308/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9076\n",
      "Epoch 309/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9180: 0s - loss: 0.2138 - accuracy: \n",
      "Epoch 310/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9115\n",
      "Epoch 311/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8516\n",
      "Epoch 312/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8581\n",
      "Epoch 313/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.8646\n",
      "Epoch 314/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9023\n",
      "Epoch 315/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9089\n",
      "Epoch 316/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9089\n",
      "Epoch 317/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9167\n",
      "Epoch 318/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.9023\n",
      "Epoch 319/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9049\n",
      "Epoch 320/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9062\n",
      "Epoch 321/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9076\n",
      "Epoch 322/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2356 - accuracy: 0.8945\n",
      "Epoch 323/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.8932\n",
      "Epoch 324/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8958\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8958\n",
      "Epoch 326/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.8984\n",
      "Epoch 327/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9049\n",
      "Epoch 328/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.3256 - accuracy: 0.8581\n",
      "Epoch 329/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.8997\n",
      "Epoch 330/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2179 - accuracy: 0.9167\n",
      "Epoch 331/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.8945\n",
      "Epoch 332/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.8971\n",
      "Epoch 333/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9115\n",
      "Epoch 334/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9102\n",
      "Epoch 335/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9049\n",
      "Epoch 336/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.8945\n",
      "Epoch 337/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8763\n",
      "Epoch 338/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8971\n",
      "Epoch 339/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9089\n",
      "Epoch 340/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9023\n",
      "Epoch 341/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9167\n",
      "Epoch 342/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9206\n",
      "Epoch 343/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9193: 0s - loss: 0.2068 - accuracy: 0.\n",
      "Epoch 344/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9180\n",
      "Epoch 345/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8880\n",
      "Epoch 346/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9036\n",
      "Epoch 347/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9180\n",
      "Epoch 348/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.8984\n",
      "Epoch 349/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9023\n",
      "Epoch 350/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9219\n",
      "Epoch 351/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2230 - accuracy: 0.8958\n",
      "Epoch 352/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9023\n",
      "Epoch 353/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9154\n",
      "Epoch 354/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9128\n",
      "Epoch 355/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.2061 - accuracy: 0.9010\n",
      "Epoch 356/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9284\n",
      "Epoch 357/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8438\n",
      "Epoch 358/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8542\n",
      "Epoch 359/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2598 - accuracy: 0.8815\n",
      "Epoch 360/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.8971\n",
      "Epoch 361/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9154\n",
      "Epoch 362/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9036\n",
      "Epoch 363/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9154\n",
      "Epoch 364/500\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.8997\n",
      "Epoch 365/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9076\n",
      "Epoch 366/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9271\n",
      "Epoch 367/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9258\n",
      "Epoch 368/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.8997\n",
      "Epoch 369/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.8958\n",
      "Epoch 370/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9219\n",
      "Epoch 371/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9232\n",
      "Epoch 372/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9193\n",
      "Epoch 373/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.8906\n",
      "Epoch 374/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8802\n",
      "Epoch 375/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8828\n",
      "Epoch 376/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.8880\n",
      "Epoch 377/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9141\n",
      "Epoch 378/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9193\n",
      "Epoch 379/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9323\n",
      "Epoch 380/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9232\n",
      "Epoch 381/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9245\n",
      "Epoch 382/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9154\n",
      "Epoch 383/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9180\n",
      "Epoch 384/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9062\n",
      "Epoch 385/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.9076\n",
      "Epoch 386/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.9271\n",
      "Epoch 387/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9115\n",
      "Epoch 388/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.8906\n",
      "Epoch 389/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.8984\n",
      "Epoch 390/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9076\n",
      "Epoch 391/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9219\n",
      "Epoch 392/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9023\n",
      "Epoch 393/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8932\n",
      "Epoch 394/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8516\n",
      "Epoch 395/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.8997\n",
      "Epoch 396/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.9167\n",
      "Epoch 397/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9245\n",
      "Epoch 398/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9232\n",
      "Epoch 399/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9193\n",
      "Epoch 400/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9154\n",
      "Epoch 401/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9258\n",
      "Epoch 402/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9141\n",
      "Epoch 403/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9128\n",
      "Epoch 404/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9036\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9232\n",
      "Epoch 406/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9141\n",
      "Epoch 407/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9128\n",
      "Epoch 408/500\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.2014 - accuracy: 0.9115\n",
      "Epoch 409/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8919\n",
      "Epoch 410/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9102\n",
      "Epoch 411/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9258\n",
      "Epoch 412/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9297\n",
      "Epoch 413/500\n",
      "77/77 [==============================] - 0s 971us/step - loss: 0.1835 - accuracy: 0.9128\n",
      "Epoch 414/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9102\n",
      "Epoch 415/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9336\n",
      "Epoch 416/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9258\n",
      "Epoch 417/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9440\n",
      "Epoch 418/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.9310\n",
      "Epoch 419/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.9128\n",
      "Epoch 420/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9076\n",
      "Epoch 421/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.8958\n",
      "Epoch 422/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.8984: 0s - loss: 0.2408 - accuracy: 0.89\n",
      "Epoch 423/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9193\n",
      "Epoch 424/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9076\n",
      "Epoch 425/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.9141\n",
      "Epoch 426/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9076\n",
      "Epoch 427/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.8932\n",
      "Epoch 428/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9310\n",
      "Epoch 429/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9219\n",
      "Epoch 430/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9245\n",
      "Epoch 431/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9180\n",
      "Epoch 432/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8867\n",
      "Epoch 433/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9102\n",
      "Epoch 434/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9284\n",
      "Epoch 435/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8932\n",
      "Epoch 436/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.9180\n",
      "Epoch 437/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9128\n",
      "Epoch 438/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9128\n",
      "Epoch 439/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9310\n",
      "Epoch 440/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9323\n",
      "Epoch 441/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9115\n",
      "Epoch 442/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8867\n",
      "Epoch 443/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9193\n",
      "Epoch 444/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9232\n",
      "Epoch 445/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.9297\n",
      "Epoch 446/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.9102\n",
      "Epoch 447/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9219\n",
      "Epoch 448/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9258\n",
      "Epoch 449/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.9245\n",
      "Epoch 450/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9245\n",
      "Epoch 451/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9336\n",
      "Epoch 452/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9167\n",
      "Epoch 453/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9193\n",
      "Epoch 454/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9245\n",
      "Epoch 455/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9219\n",
      "Epoch 456/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9141\n",
      "Epoch 457/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9089\n",
      "Epoch 458/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9023\n",
      "Epoch 459/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9297\n",
      "Epoch 460/500\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.94 - 0s 1ms/step - loss: 0.1613 - accuracy: 0.9297\n",
      "Epoch 461/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9492\n",
      "Epoch 462/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9362\n",
      "Epoch 463/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9271\n",
      "Epoch 464/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9284\n",
      "Epoch 465/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9180\n",
      "Epoch 466/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9271\n",
      "Epoch 467/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9141\n",
      "Epoch 468/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9245\n",
      "Epoch 469/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9180\n",
      "Epoch 470/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9115\n",
      "Epoch 471/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9128\n",
      "Epoch 472/500\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9128\n",
      "Epoch 473/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9310\n",
      "Epoch 474/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.2546 - accuracy: 0.8997\n",
      "Epoch 475/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9232\n",
      "Epoch 476/500\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.1464 - accuracy: 0.9362\n",
      "Epoch 477/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9258\n",
      "Epoch 478/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9323\n",
      "Epoch 479/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9453\n",
      "Epoch 480/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9388\n",
      "Epoch 481/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9232\n",
      "Epoch 482/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9310\n",
      "Epoch 483/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9271\n",
      "Epoch 484/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9349\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 980us/step - loss: 0.1888 - accuracy: 0.9115\n",
      "Epoch 486/500\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.2139 - accuracy: 0.9102\n",
      "Epoch 487/500\n",
      "77/77 [==============================] - 0s 909us/step - loss: 0.2398 - accuracy: 0.8945\n",
      "Epoch 488/500\n",
      "77/77 [==============================] - 0s 863us/step - loss: 0.1818 - accuracy: 0.9180\n",
      "Epoch 489/500\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.1750 - accuracy: 0.9232\n",
      "Epoch 490/500\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.1451 - accuracy: 0.9362\n",
      "Epoch 491/500\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.1804 - accuracy: 0.9297\n",
      "Epoch 492/500\n",
      "77/77 [==============================] - 0s 985us/step - loss: 0.1964 - accuracy: 0.9154\n",
      "Epoch 493/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9297\n",
      "Epoch 494/500\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.1403 - accuracy: 0.9427\n",
      "Epoch 495/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.9414\n",
      "Epoch 496/500\n",
      "77/77 [==============================] - 0s 942us/step - loss: 0.1415 - accuracy: 0.9336\n",
      "Epoch 497/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.9323\n",
      "Epoch 498/500\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.1744 - accuracy: 0.9271\n",
      "Epoch 499/500\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.9036\n",
      "Epoch 500/500\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.2563 - accuracy: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b846eeb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X, y, epochs=500, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sKrOBj_Fjabk"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(36, activation='relu', input_shape=(8,)))\n",
    "model3.add(Dense(24, activation='relu'))\n",
    "model3.add(Dense(12, activation='relu'))\n",
    "model3.add(Dense(8, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYE_nuo1mr4h",
    "outputId": "c011c707-57c5-4cec-aed9-48513c57ddc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 36)                324       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,625\n",
      "Trainable params: 1,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HRSvhaYuk1xa"
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57JhGdholbqu",
    "outputId": "16377c27-d282-4b60-9db3-d9dde11ed49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 854us/step - loss: 0.8297 - accuracy: 0.6224\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.6153 - accuracy: 0.6849\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6784\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6862\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6602\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 935us/step - loss: 0.6030 - accuracy: 0.6979\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 983us/step - loss: 0.6019 - accuracy: 0.6888\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.5877 - accuracy: 0.7031\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.7044\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.6875\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.5803 - accuracy: 0.7122\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5739 - accuracy: 0.7044\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.5688 - accuracy: 0.7018\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 952us/step - loss: 0.5610 - accuracy: 0.7227\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.5752 - accuracy: 0.6914\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7148\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.5576 - accuracy: 0.7214\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7083\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.5542 - accuracy: 0.7214\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7201\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.5596 - accuracy: 0.6979\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.7135\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 969us/step - loss: 0.6012 - accuracy: 0.7201\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7122\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7148\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 925us/step - loss: 0.5392 - accuracy: 0.7435\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7240\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 918us/step - loss: 0.5432 - accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7552\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.5406 - accuracy: 0.7201\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.7331\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 905us/step - loss: 0.5371 - accuracy: 0.7357\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7331\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.5347 - accuracy: 0.7214\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 985us/step - loss: 0.5296 - accuracy: 0.7448\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 1000us/step - loss: 0.5215 - accuracy: 0.7448\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 949us/step - loss: 0.5471 - accuracy: 0.7214\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.5437 - accuracy: 0.7409\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.5259 - accuracy: 0.7396\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 982us/step - loss: 0.5372 - accuracy: 0.7461\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 941us/step - loss: 0.5268 - accuracy: 0.7422\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.5209 - accuracy: 0.7461\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7422\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.5186 - accuracy: 0.7396\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 933us/step - loss: 0.5127 - accuracy: 0.7539\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.5191 - accuracy: 0.7487\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.74 - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7383\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.5204 - accuracy: 0.7435\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 946us/step - loss: 0.5213 - accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7552\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 893us/step - loss: 0.5122 - accuracy: 0.7591\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 997us/step - loss: 0.5161 - accuracy: 0.7526\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 920us/step - loss: 0.4996 - accuracy: 0.7578\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 923us/step - loss: 0.5151 - accuracy: 0.7461\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 835us/step - loss: 0.5051 - accuracy: 0.7591\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.5116 - accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 798us/step - loss: 0.5037 - accuracy: 0.7617\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 816us/step - loss: 0.4998 - accuracy: 0.7435\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 812us/step - loss: 0.5225 - accuracy: 0.7409\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 934us/step - loss: 0.5066 - accuracy: 0.7461\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 871us/step - loss: 0.5025 - accuracy: 0.7565\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 883us/step - loss: 0.4946 - accuracy: 0.7526\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 809us/step - loss: 0.5211 - accuracy: 0.7396\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 945us/step - loss: 0.4969 - accuracy: 0.7656\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7773\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7526\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7721\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7591\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7591\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7643\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7591\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.4782 - accuracy: 0.7604\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 874us/step - loss: 0.4861 - accuracy: 0.7682\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 952us/step - loss: 0.4849 - accuracy: 0.7578\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 836us/step - loss: 0.4856 - accuracy: 0.7526\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 882us/step - loss: 0.4873 - accuracy: 0.7617\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 916us/step - loss: 0.4899 - accuracy: 0.7461\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7643\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 954us/step - loss: 0.4901 - accuracy: 0.7578\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 937us/step - loss: 0.4779 - accuracy: 0.7643\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 908us/step - loss: 0.4787 - accuracy: 0.7682\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.4768 - accuracy: 0.76040s - loss: 0.4759 - accuracy: 0.74\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.4808 - accuracy: 0.7708\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 914us/step - loss: 0.4668 - accuracy: 0.7865\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 855us/step - loss: 0.4765 - accuracy: 0.7721\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.4670 - accuracy: 0.7721\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 841us/step - loss: 0.4650 - accuracy: 0.7695\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 829us/step - loss: 0.4660 - accuracy: 0.7799\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 947us/step - loss: 0.4814 - accuracy: 0.7643\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 819us/step - loss: 0.4627 - accuracy: 0.7695\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.4649 - accuracy: 0.7760\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 806us/step - loss: 0.4645 - accuracy: 0.7734\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 827us/step - loss: 0.4631 - accuracy: 0.7786\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.4584 - accuracy: 0.7630\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 838us/step - loss: 0.4589 - accuracy: 0.7852\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 823us/step - loss: 0.4584 - accuracy: 0.7826\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 802us/step - loss: 0.4613 - accuracy: 0.7682\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 805us/step - loss: 0.4663 - accuracy: 0.7786\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 894us/step - loss: 0.4795 - accuracy: 0.7617\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 825us/step - loss: 0.4476 - accuracy: 0.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b8759c70>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1JLxc_FNleHy"
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model5.add(Dense(24, activation='relu'))\n",
    "model5.add(Dense(24, activation='relu'))\n",
    "model5.add(Dense(36, activation='relu'))\n",
    "model5.add(Dense(24, activation='relu'))\n",
    "model5.add(Dense(24, activation='relu'))\n",
    "model5.add(Dense(12, activation='relu'))\n",
    "model5.add(Dense(8, activation='relu'))\n",
    "model5.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rRXaJ_Teo3lA"
   },
   "outputs": [],
   "source": [
    "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzEafNIno6xw",
    "outputId": "95129499-918c-45df-d774-eaa26b95133e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.6471\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6589\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6207 - accuracy: 0.6732\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6628\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.67 - 0s 1ms/step - loss: 0.6172 - accuracy: 0.6732\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6153 - accuracy: 0.6849\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.6927\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6745\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6914\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.67 - 0s 1ms/step - loss: 0.5968 - accuracy: 0.6953\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6979\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.7070\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7018\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.70 - 0s 1ms/step - loss: 0.5755 - accuracy: 0.7174\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6979\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7109\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7240\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7214\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7383\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7266\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7227\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7266\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7383\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7344\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7318\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7539\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7383\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7552\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7552\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7266\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7448\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.7552\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.76 - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7552\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7591\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7591\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5066 - accuracy: 0.7617\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7617\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7578\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7656\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7630\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7643\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7656\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7604\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7747\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7604\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7721\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7565\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7630\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7799\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7760\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7695: 0s - loss: 0.4643 - accuracy: 0.76\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7747\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7969\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7930\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7760\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7786\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7682\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7747\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7786\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7891\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7799\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8060\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8021\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7865\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7826\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.8125\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8060\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8047\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8034\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8008\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7786\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8086\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8047\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8125\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4092 - accuracy: 0.8047\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8125\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.7930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.7956\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8060\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8281\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8034\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8242\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8255\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8320\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8255\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8177\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8164\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8138\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.7891\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8190\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8216\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8346\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8138\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8151\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8216\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8346\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8255\n"
     ]
    }
   ],
   "source": [
    "history = model5.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "5e0NlZGMo9Xm"
   },
   "outputs": [],
   "source": [
    "# history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "chN98HN-pvP1",
    "outputId": "e544f861-4b99-427f-aa01-f64024947e35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "kJEreAODp0jj",
    "outputId": "0d46735e-7ab2-42b0-bb34-5b4694d6b4e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxSY0O5QqBnt",
    "outputId": "9a15a7fb-f554-4d58-f392-8ffdb7b9ecbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_MRlquuq_WDa"
   },
   "outputs": [],
   "source": [
    "test = X[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "BA3fw9C7_pAb"
   },
   "outputs": [],
   "source": [
    "predictions = model5.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qht60ebk_50T",
    "outputId": "d5aae83f-2c46-4d17-c49e-ef2f890521cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07903811]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "K6uYSOi2_7EH",
    "outputId": "777edc72-c9d8-4887-96a8-ebd47c0b2148"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "1            1       85             66             29        0  26.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "1                     0.351   31  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "iAiZ2bnnAHtM",
    "outputId": "43206f0e-4149-4d11-c3ae-1dfbd57a3821"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome\n",
       "0        1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "IbH_VCh5AKcU"
   },
   "outputs": [],
   "source": [
    "test = X[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXAaAYNRAUcR",
    "outputId": "7aecbab2-3f00-47a6-d06f-0a06af1007d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8311523]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model5.predict(test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "I2dX2WTlAXSa",
    "outputId": "43186ebf-83fb-46e4-f699-8e7979a0d113"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcome\n",
       "0        1\n",
       "1        0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bmT_LNceAaaJ"
   },
   "outputs": [],
   "source": [
    "test = X[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "I4o-G7V2Ag5F",
    "outputId": "deaef7ae-6176-40d4-f6e6-e1d4951ffc9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-vaKz2qAh2U",
    "outputId": "1af5e53a-1b3d-440d-8800-9ab83dceed69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8311523 ],\n",
       "       [0.00300035]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model5.predict(test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "W1q1l5GNAl1t"
   },
   "outputs": [],
   "source": [
    "test = X[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "kT1aJllYAxwG",
    "outputId": "83f76e3b-6661-40de-b36f-1aa685d49796"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9jJW4iJAyuc",
    "outputId": "606e173d-485a-4b46-9de2-de83b001b190"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81352115],\n",
       "       [0.07903802],\n",
       "       [0.83115244],\n",
       "       [0.00300035]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model5.predict(test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9PrWsyo5A3ep"
   },
   "outputs": [],
   "source": [
    "# Training ds is used for testing ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "B9oECm4cBBlE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "FCa73o62BTLK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbDJks1JBZuz",
    "outputId": "aaca7400-ef3d-4509-9c76-2bbdd46a113d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8HVCP8RBblw",
    "outputId": "5eb4b5fd-c8f6-456c-ad4d-6648f69c1480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIHFMi99BgWb",
    "outputId": "6b16b089-bb6a-4a88-fe6a-40d759dca604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8231\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8492\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8566: 0s - loss: 0.3463 - accuracy: 0.84\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8399\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8361\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8324\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8436\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8399: 0s - loss: 0.3911 - accuracy: 0.82\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.8529\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3196 - accuracy: 0.8566\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8585\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8622\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8510\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8436: 0s - loss: 0.3583 - accuracy: 0.83\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8603\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8399\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8585\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8696\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8324\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7784\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8399\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8231\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8305\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8529\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8436\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8454\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8492\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8715\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8771\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8641\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8473\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8678\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8529\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8752\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8734\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8659\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8752\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2572 - accuracy: 0.8845\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8659\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8361\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8268\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8399\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8324\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.8678\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8790\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8659: 0s - loss: 0.2993 - accuracy: 0.86\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8696\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.8790\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2611 - accuracy: 0.8864\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8864\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.8790\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8399\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8715\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8790\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8603\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8603\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8696\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8845\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8827\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8734\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.8808\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8659\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8827\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8696\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.8939\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8771\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8752\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.86 - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8510\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8976\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.8901\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.8734\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8566\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8864\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8864\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2741 - accuracy: 0.8603\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8790\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.8864\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.8957\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.8864\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8901\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.8957\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.8715\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 989us/step - loss: 0.2338 - accuracy: 0.8976\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8771\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8492\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.8883\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9050\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2118 - accuracy: 0.9088\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 993us/step - loss: 0.2200 - accuracy: 0.9088\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.8976\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.8939\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8957\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.9032\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9162\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9032\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9069\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8790\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8641\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8585\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.8901: 0s - loss: 0.2391 - accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "history = model5.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0yo0xI9BqkD",
    "outputId": "227f3c07-1e69-425c-d139-6e4b4aa6c586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 855us/step - loss: 0.8595 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8594818711280823, 0.6883116960525513]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "zp5BcCwjDnIB"
   },
   "outputs": [],
   "source": [
    "# model = tf.loadmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "5Hq81ib7EYv3"
   },
   "outputs": [],
   "source": [
    "# deploying the model -> flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "fnA6aw6yEkxP"
   },
   "outputs": [],
   "source": [
    "# tf hub\n",
    "# git hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Y-HtqofjE19P"
   },
   "outputs": [],
   "source": [
    "# model5.save('/content/sample_data/')\n",
    "# Frozen model -> Common format\n",
    "# TF\n",
    "# Pytorch\n",
    "# Caffe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "LVTZCyZqF8J4"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWQdsROeGM5Y",
    "outputId": "43e36d7d-6ce8-4f7f-e8a5-0ebbc7a8e37a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "mKln7QRUE4TN"
   },
   "outputs": [],
   "source": [
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mO7iHUyGQBN",
    "outputId": "826eaffa-4ddc-470c-92b4-f5fc095f62ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzDdT-5KGTto",
    "outputId": "b87c2268-e05f-4103-f55c-39d63df6d859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "wEmfVEPHGWCg"
   },
   "outputs": [],
   "source": [
    "# Training / Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "T_0eVp7gG2Ab"
   },
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model6.add(Dense(24, activation='relu'))\n",
    "model6.add(Dense(24, activation='relu'))\n",
    "model6.add(Dense(36, activation='relu'))\n",
    "model6.add(Dense(24, activation='relu'))\n",
    "model6.add(Dense(24, activation='relu'))\n",
    "model6.add(Dense(12, activation='relu'))\n",
    "model6.add(Dense(8, activation='relu'))\n",
    "model6.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyej-3G_HQJK",
    "outputId": "bd9c8555-aabc-4a10-df83-a5798de37314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 36)                900       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,821\n",
      "Trainable params: 3,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Nm0sLFvBHS-T"
   },
   "outputs": [],
   "source": [
    "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEun2GrJGd4Z",
    "outputId": "1c0e81ea-7b84-45cd-fba8-012032a178c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 0.8309 - accuracy: 0.5848 - val_loss: 0.7136 - val_accuracy: 0.5519\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.6304 - val_loss: 0.6616 - val_accuracy: 0.6688\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.6478 - val_loss: 0.7126 - val_accuracy: 0.5909\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6565 - val_loss: 0.6404 - val_accuracy: 0.6688\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6587 - val_loss: 0.6344 - val_accuracy: 0.6623\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6913 - val_loss: 0.6499 - val_accuracy: 0.6883\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.6826 - val_loss: 0.6425 - val_accuracy: 0.6688\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.6913 - val_loss: 0.6487 - val_accuracy: 0.6818\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.6913 - val_loss: 0.6527 - val_accuracy: 0.6883\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.6870 - val_loss: 0.6443 - val_accuracy: 0.6948\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.6935 - val_loss: 0.6364 - val_accuracy: 0.6688\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.6804 - val_loss: 0.6275 - val_accuracy: 0.6818\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.6870 - val_loss: 0.6412 - val_accuracy: 0.6558\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.6978 - val_loss: 0.6315 - val_accuracy: 0.6818\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7022 - val_loss: 0.6234 - val_accuracy: 0.6688\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.7087 - val_loss: 0.6736 - val_accuracy: 0.7013\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.6978 - val_loss: 0.6755 - val_accuracy: 0.7013\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.6935 - val_loss: 0.6513 - val_accuracy: 0.6688\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7000 - val_loss: 0.6870 - val_accuracy: 0.7078\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.6826 - val_loss: 0.6540 - val_accuracy: 0.6818\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7109 - val_loss: 0.6418 - val_accuracy: 0.6623\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5744 - accuracy: 0.6761 - val_loss: 0.7102 - val_accuracy: 0.7078\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5627 - accuracy: 0.7174 - val_loss: 0.6437 - val_accuracy: 0.6948\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7000 - val_loss: 0.6392 - val_accuracy: 0.7013\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.7065 - val_loss: 0.6598 - val_accuracy: 0.7013\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7174 - val_loss: 0.6436 - val_accuracy: 0.7013\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7261 - val_loss: 0.6619 - val_accuracy: 0.6883\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7130 - val_loss: 0.6411 - val_accuracy: 0.6688\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7326 - val_loss: 0.6463 - val_accuracy: 0.6753\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7174 - val_loss: 0.6637 - val_accuracy: 0.6818\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7348 - val_loss: 0.6657 - val_accuracy: 0.6688\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7109 - val_loss: 0.7372 - val_accuracy: 0.6948\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7217 - val_loss: 0.6588 - val_accuracy: 0.6558\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7391 - val_loss: 0.6543 - val_accuracy: 0.6753\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7087 - val_loss: 0.6406 - val_accuracy: 0.6883\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7196 - val_loss: 0.6569 - val_accuracy: 0.6753\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7196 - val_loss: 0.6786 - val_accuracy: 0.6948\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.6826 - val_loss: 0.6518 - val_accuracy: 0.6688\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.75 - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7109 - val_loss: 0.6535 - val_accuracy: 0.6623\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6261 - val_loss: 0.6651 - val_accuracy: 0.6429\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.6739 - val_loss: 0.6837 - val_accuracy: 0.6104\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.6891 - val_loss: 0.6569 - val_accuracy: 0.7013\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7174 - val_loss: 0.6879 - val_accuracy: 0.6883\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.6826 - val_loss: 0.6729 - val_accuracy: 0.7143\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7087 - val_loss: 0.6674 - val_accuracy: 0.6948\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7326 - val_loss: 0.6704 - val_accuracy: 0.7208\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7065 - val_loss: 0.6862 - val_accuracy: 0.7078\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7152 - val_loss: 0.6629 - val_accuracy: 0.6429\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7348 - val_loss: 0.6778 - val_accuracy: 0.6948\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7217 - val_loss: 0.6630 - val_accuracy: 0.7013\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7370 - val_loss: 0.6608 - val_accuracy: 0.6883\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7283 - val_loss: 0.6860 - val_accuracy: 0.6818\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7413 - val_loss: 0.6642 - val_accuracy: 0.6948\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7304 - val_loss: 0.6731 - val_accuracy: 0.6623\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7217 - val_loss: 0.7159 - val_accuracy: 0.6883\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7413 - val_loss: 0.6657 - val_accuracy: 0.6688\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.6717 - val_loss: 0.7038 - val_accuracy: 0.7078\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7261 - val_loss: 0.6852 - val_accuracy: 0.7143\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7500 - val_loss: 0.6823 - val_accuracy: 0.7013\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7348 - val_loss: 0.6869 - val_accuracy: 0.6883\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7043 - val_loss: 0.7308 - val_accuracy: 0.6818\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7391 - val_loss: 0.6787 - val_accuracy: 0.6818\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7283 - val_loss: 0.7062 - val_accuracy: 0.6948\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7435 - val_loss: 0.6915 - val_accuracy: 0.6883\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7565 - val_loss: 0.6633 - val_accuracy: 0.6948\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7674 - val_loss: 0.6935 - val_accuracy: 0.7078\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7652 - val_loss: 0.6819 - val_accuracy: 0.6883\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7500 - val_loss: 0.6631 - val_accuracy: 0.7143\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7391 - val_loss: 0.7378 - val_accuracy: 0.7208\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7500 - val_loss: 0.6640 - val_accuracy: 0.7078\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7196 - val_loss: 0.7059 - val_accuracy: 0.6883\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7500 - val_loss: 0.6724 - val_accuracy: 0.6883\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7413 - val_loss: 0.7059 - val_accuracy: 0.6688\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7522 - val_loss: 0.6563 - val_accuracy: 0.7013\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7717 - val_loss: 0.6632 - val_accuracy: 0.7013\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7478 - val_loss: 0.6879 - val_accuracy: 0.7143\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7500 - val_loss: 0.6550 - val_accuracy: 0.7338\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7370 - val_loss: 0.7137 - val_accuracy: 0.7208\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7478 - val_loss: 0.6928 - val_accuracy: 0.6688\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7478 - val_loss: 0.7072 - val_accuracy: 0.7208\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7500 - val_loss: 0.6738 - val_accuracy: 0.7208\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7587 - val_loss: 0.6907 - val_accuracy: 0.7143\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7370 - val_loss: 0.7201 - val_accuracy: 0.7013\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7565 - val_loss: 0.6728 - val_accuracy: 0.6948\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7457 - val_loss: 0.6678 - val_accuracy: 0.7078\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7630 - val_loss: 0.7058 - val_accuracy: 0.7078\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7348 - val_loss: 0.6725 - val_accuracy: 0.6623\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.6739 - val_loss: 0.6886 - val_accuracy: 0.6234\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7130 - val_loss: 0.6582 - val_accuracy: 0.6883\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7413 - val_loss: 0.7059 - val_accuracy: 0.6883\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7478 - val_loss: 0.7345 - val_accuracy: 0.6948\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7696 - val_loss: 0.7226 - val_accuracy: 0.7208\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.78 - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7543 - val_loss: 0.7006 - val_accuracy: 0.6948\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7326 - val_loss: 0.7177 - val_accuracy: 0.7078\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7217 - val_loss: 0.6926 - val_accuracy: 0.7078\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7326 - val_loss: 0.6966 - val_accuracy: 0.7208\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7587 - val_loss: 0.7519 - val_accuracy: 0.7273\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7391 - val_loss: 0.6810 - val_accuracy: 0.7208\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7609 - val_loss: 0.7852 - val_accuracy: 0.6948\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7696 - val_loss: 0.6998 - val_accuracy: 0.7338\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7522 - val_loss: 0.7123 - val_accuracy: 0.6883\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7587 - val_loss: 0.7456 - val_accuracy: 0.7013\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7630 - val_loss: 0.7225 - val_accuracy: 0.6883\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7761 - val_loss: 0.7900 - val_accuracy: 0.7208\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7522 - val_loss: 0.7425 - val_accuracy: 0.7143\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7696 - val_loss: 0.7414 - val_accuracy: 0.7078\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7435 - val_loss: 0.8267 - val_accuracy: 0.6948\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7870 - val_loss: 0.8155 - val_accuracy: 0.7273\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7804 - val_loss: 0.7735 - val_accuracy: 0.7273\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7739 - val_loss: 0.7276 - val_accuracy: 0.7143\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7717 - val_loss: 0.7357 - val_accuracy: 0.7208\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7891 - val_loss: 0.7644 - val_accuracy: 0.7013\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7522 - val_loss: 0.7608 - val_accuracy: 0.7078\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7587 - val_loss: 0.7168 - val_accuracy: 0.7143\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7565 - val_loss: 0.8815 - val_accuracy: 0.7143\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7152 - val_loss: 0.6729 - val_accuracy: 0.7532\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7283 - val_loss: 0.6695 - val_accuracy: 0.7403\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7543 - val_loss: 0.7346 - val_accuracy: 0.6818\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7435 - val_loss: 0.7178 - val_accuracy: 0.7532\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7413 - val_loss: 0.7620 - val_accuracy: 0.7143\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7652 - val_loss: 0.6906 - val_accuracy: 0.7338\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7804 - val_loss: 0.7434 - val_accuracy: 0.7273\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7652 - val_loss: 0.7157 - val_accuracy: 0.7208\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7826 - val_loss: 0.6948 - val_accuracy: 0.7208\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7717 - val_loss: 0.7808 - val_accuracy: 0.7208\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7717 - val_loss: 0.7117 - val_accuracy: 0.7273\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7826 - val_loss: 0.7576 - val_accuracy: 0.7208\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7783 - val_loss: 0.7277 - val_accuracy: 0.6948\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7978 - val_loss: 0.7709 - val_accuracy: 0.7013\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7783 - val_loss: 0.7037 - val_accuracy: 0.7273\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7717 - val_loss: 0.8222 - val_accuracy: 0.6883\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.7497 - val_accuracy: 0.6948\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7761 - val_loss: 0.8089 - val_accuracy: 0.6883\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.7623 - val_accuracy: 0.7273\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7696 - val_loss: 0.8437 - val_accuracy: 0.7013\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7761 - val_loss: 0.7298 - val_accuracy: 0.7273\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7804 - val_loss: 0.7471 - val_accuracy: 0.7273\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7761 - val_loss: 0.7819 - val_accuracy: 0.7013\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7761 - val_loss: 0.7820 - val_accuracy: 0.7078\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7783 - val_loss: 0.8085 - val_accuracy: 0.7208\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7848 - val_loss: 0.7749 - val_accuracy: 0.7013\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7674 - val_loss: 0.8410 - val_accuracy: 0.7078\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7848 - val_loss: 0.7277 - val_accuracy: 0.7208\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7957 - val_loss: 0.8315 - val_accuracy: 0.7208\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7717 - val_loss: 0.7812 - val_accuracy: 0.7078\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7826 - val_loss: 0.7714 - val_accuracy: 0.7468\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7913 - val_loss: 0.8577 - val_accuracy: 0.6883\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7978 - val_loss: 0.7818 - val_accuracy: 0.7338\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7935 - val_loss: 0.7531 - val_accuracy: 0.6948\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7913 - val_loss: 0.7324 - val_accuracy: 0.7078\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7848 - val_loss: 0.7694 - val_accuracy: 0.6883\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7891 - val_loss: 0.8181 - val_accuracy: 0.7338\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7674 - val_loss: 0.8333 - val_accuracy: 0.7208\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7739 - val_loss: 0.8109 - val_accuracy: 0.7338\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7935 - val_loss: 0.8525 - val_accuracy: 0.7273\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7913 - val_loss: 0.7538 - val_accuracy: 0.7208\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7717 - val_loss: 0.9129 - val_accuracy: 0.7143\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7674 - val_loss: 0.7767 - val_accuracy: 0.7208\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7761 - val_loss: 0.8680 - val_accuracy: 0.7143\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7652 - val_loss: 0.8068 - val_accuracy: 0.7078\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7717 - val_loss: 0.9742 - val_accuracy: 0.6753\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7674 - val_loss: 0.7756 - val_accuracy: 0.7143\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7804 - val_loss: 0.8684 - val_accuracy: 0.7078\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7609 - val_loss: 0.8643 - val_accuracy: 0.7013\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7870 - val_loss: 0.8779 - val_accuracy: 0.7143\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7935 - val_loss: 0.8611 - val_accuracy: 0.7078\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7957 - val_loss: 0.9462 - val_accuracy: 0.7143\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7826 - val_loss: 0.9207 - val_accuracy: 0.7208\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7957 - val_loss: 0.8889 - val_accuracy: 0.7078\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8043 - val_loss: 0.8999 - val_accuracy: 0.7338\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7978 - val_loss: 0.8786 - val_accuracy: 0.7273\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7717 - val_loss: 1.0568 - val_accuracy: 0.7013\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7891 - val_loss: 0.8638 - val_accuracy: 0.7338\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7826 - val_loss: 0.9458 - val_accuracy: 0.7013\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7630 - val_loss: 0.8359 - val_accuracy: 0.7208\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7870 - val_loss: 0.9036 - val_accuracy: 0.6948\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7761 - val_loss: 0.8861 - val_accuracy: 0.7078\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7935 - val_loss: 0.9901 - val_accuracy: 0.7143\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7870 - val_loss: 0.9694 - val_accuracy: 0.7143\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8022 - val_loss: 0.9046 - val_accuracy: 0.7143\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7913 - val_loss: 0.8339 - val_accuracy: 0.7143\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7717 - val_loss: 0.8174 - val_accuracy: 0.6948\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7848 - val_loss: 0.8650 - val_accuracy: 0.7208\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7826 - val_loss: 0.8280 - val_accuracy: 0.7078\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7913 - val_loss: 0.9061 - val_accuracy: 0.7143\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7978 - val_loss: 0.9036 - val_accuracy: 0.7338\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7935 - val_loss: 1.0011 - val_accuracy: 0.7078\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7957 - val_loss: 1.0744 - val_accuracy: 0.7273\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7978 - val_loss: 0.9697 - val_accuracy: 0.7338\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7935 - val_loss: 1.1023 - val_accuracy: 0.7078\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.7913 - val_loss: 1.0173 - val_accuracy: 0.7273\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8043 - val_loss: 1.0370 - val_accuracy: 0.7338\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7913 - val_loss: 1.0248 - val_accuracy: 0.7208\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7891 - val_loss: 1.0746 - val_accuracy: 0.6948\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7870 - val_loss: 0.9864 - val_accuracy: 0.6883\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7913 - val_loss: 0.9576 - val_accuracy: 0.7273\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8000 - val_loss: 1.0801 - val_accuracy: 0.7078\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8065 - val_loss: 1.0468 - val_accuracy: 0.7078\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7978 - val_loss: 1.1528 - val_accuracy: 0.7338\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7543 - val_loss: 0.8699 - val_accuracy: 0.7338\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model6.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "lmDiChIUHR0U",
    "outputId": "01db7d76-2444-4e4d-b5b4-d6bbd9e231dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "4vmtEG_9HvTc"
   },
   "outputs": [],
   "source": [
    "# Complete the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSi_9mVoKYUN",
    "outputId": "6e3cfc6f-3137-41fe-efdf-04751e0c8389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 36)                900       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,821\n",
      "Trainable params: 3,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "xz3kDR5zKmyW"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model7.add(Dense(24, activation='relu'))\n",
    "model7.add(Dense(24, activation='relu'))\n",
    "model7.add(Dense(36, activation='relu'))\n",
    "model7.add(Dense(24, activation='relu'))\n",
    "model7.add(Dense(24, activation='relu'))\n",
    "model7.add(Dense(12, activation='relu'))\n",
    "model7.add(Dense(8, activation='relu', kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)))\n",
    "model7.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "n7SdgMChK6a-"
   },
   "outputs": [],
   "source": [
    "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFsCNmwiLMZF",
    "outputId": "903fb505-0fb0-43d8-9e1b-9b51d51e8205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 4.4338 - accuracy: 0.3543 - val_loss: 1.8970 - val_accuracy: 0.4091\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.7036 - accuracy: 0.4870 - val_loss: 1.6012 - val_accuracy: 0.5909\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5525 - accuracy: 0.6457 - val_loss: 1.5713 - val_accuracy: 0.5909\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.5149 - accuracy: 0.6500 - val_loss: 1.5344 - val_accuracy: 0.5714\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4753 - accuracy: 0.6478 - val_loss: 1.4969 - val_accuracy: 0.5844\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4417 - accuracy: 0.6457 - val_loss: 1.4783 - val_accuracy: 0.5909\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.4168 - accuracy: 0.6543 - val_loss: 1.4496 - val_accuracy: 0.5909\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3889 - accuracy: 0.6370 - val_loss: 1.4104 - val_accuracy: 0.5844\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3564 - accuracy: 0.6674 - val_loss: 1.4055 - val_accuracy: 0.5909\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3359 - accuracy: 0.6457 - val_loss: 1.3730 - val_accuracy: 0.5909\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2998 - accuracy: 0.6478 - val_loss: 1.3336 - val_accuracy: 0.6104\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.2654 - accuracy: 0.6500 - val_loss: 1.3218 - val_accuracy: 0.6039\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.2337 - accuracy: 0.6565 - val_loss: 1.3006 - val_accuracy: 0.5974\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.2026 - accuracy: 0.6609 - val_loss: 1.2842 - val_accuracy: 0.6234\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1736 - accuracy: 0.6804 - val_loss: 1.2475 - val_accuracy: 0.6104\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.1553 - accuracy: 0.6870 - val_loss: 1.2247 - val_accuracy: 0.6104\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1368 - accuracy: 0.6652 - val_loss: 1.2384 - val_accuracy: 0.5649\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1138 - accuracy: 0.6913 - val_loss: 1.2299 - val_accuracy: 0.6039\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0960 - accuracy: 0.7043 - val_loss: 1.1589 - val_accuracy: 0.6364\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0722 - accuracy: 0.7022 - val_loss: 1.1784 - val_accuracy: 0.6234\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0559 - accuracy: 0.7109 - val_loss: 1.1420 - val_accuracy: 0.6429\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0386 - accuracy: 0.7370 - val_loss: 1.1156 - val_accuracy: 0.6429\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0280 - accuracy: 0.7239 - val_loss: 1.1140 - val_accuracy: 0.6494\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0030 - accuracy: 0.7348 - val_loss: 1.1191 - val_accuracy: 0.6558\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9914 - accuracy: 0.7370 - val_loss: 1.0851 - val_accuracy: 0.6688\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9786 - accuracy: 0.7196 - val_loss: 1.0715 - val_accuracy: 0.6429\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.7543 - val_loss: 1.1087 - val_accuracy: 0.6558\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9377 - accuracy: 0.7370 - val_loss: 1.0394 - val_accuracy: 0.6558\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.7326 - val_loss: 1.0277 - val_accuracy: 0.6883\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9101 - accuracy: 0.7326 - val_loss: 1.0573 - val_accuracy: 0.6558\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9040 - accuracy: 0.7435 - val_loss: 1.0172 - val_accuracy: 0.6753\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8917 - accuracy: 0.7391 - val_loss: 1.0479 - val_accuracy: 0.6558\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8785 - accuracy: 0.7370 - val_loss: 0.9899 - val_accuracy: 0.6558\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8771 - accuracy: 0.7370 - val_loss: 0.9682 - val_accuracy: 0.6753\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8723 - accuracy: 0.7391 - val_loss: 1.0009 - val_accuracy: 0.6753\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8463 - accuracy: 0.7413 - val_loss: 0.9382 - val_accuracy: 0.7013\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8396 - accuracy: 0.7457 - val_loss: 0.9651 - val_accuracy: 0.6688\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8234 - accuracy: 0.7435 - val_loss: 0.9402 - val_accuracy: 0.6753\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8114 - accuracy: 0.7457 - val_loss: 0.9301 - val_accuracy: 0.6883\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7914 - accuracy: 0.7739 - val_loss: 0.9834 - val_accuracy: 0.6623\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8079 - accuracy: 0.7500 - val_loss: 0.9202 - val_accuracy: 0.6753\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7918 - accuracy: 0.7500 - val_loss: 0.9287 - val_accuracy: 0.6818\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.7413 - val_loss: 0.9097 - val_accuracy: 0.6558\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7715 - accuracy: 0.7630 - val_loss: 0.9561 - val_accuracy: 0.6623\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7989 - accuracy: 0.7348 - val_loss: 0.8939 - val_accuracy: 0.6753\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.7283 - val_loss: 0.9348 - val_accuracy: 0.6818\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.7326 - val_loss: 0.8446 - val_accuracy: 0.6883\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.7391 - val_loss: 0.8822 - val_accuracy: 0.6753\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8263 - accuracy: 0.70 - 0s 4ms/step - loss: 0.7422 - accuracy: 0.7457 - val_loss: 0.8767 - val_accuracy: 0.6948\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.7043 - val_loss: 0.8356 - val_accuracy: 0.7013\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7717 - val_loss: 0.8652 - val_accuracy: 0.6818\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.7717 - val_loss: 0.8339 - val_accuracy: 0.6948\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7102 - accuracy: 0.7457 - val_loss: 0.8650 - val_accuracy: 0.6753\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.7391 - val_loss: 0.8254 - val_accuracy: 0.7208\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.7609 - val_loss: 0.8265 - val_accuracy: 0.7078\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.7435 - val_loss: 0.8536 - val_accuracy: 0.6623\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7522 - val_loss: 0.8120 - val_accuracy: 0.6688\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.7500 - val_loss: 0.8192 - val_accuracy: 0.6818\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.7565 - val_loss: 0.8168 - val_accuracy: 0.6883\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7652 - val_loss: 0.7998 - val_accuracy: 0.7013\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7565 - val_loss: 0.8035 - val_accuracy: 0.6753\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.7326 - val_loss: 0.8253 - val_accuracy: 0.6948\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6985 - accuracy: 0.7217 - val_loss: 0.7799 - val_accuracy: 0.7208\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.7413 - val_loss: 0.8134 - val_accuracy: 0.6558\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.7196 - val_loss: 0.7717 - val_accuracy: 0.6883\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.7739 - val_loss: 0.7913 - val_accuracy: 0.6883\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7522 - val_loss: 0.7603 - val_accuracy: 0.7078\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7587 - val_loss: 0.7602 - val_accuracy: 0.7078\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.7696 - val_loss: 0.7926 - val_accuracy: 0.6623\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7609 - val_loss: 0.7786 - val_accuracy: 0.6818\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.7478 - val_loss: 0.7599 - val_accuracy: 0.6948\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.7630 - val_loss: 0.7750 - val_accuracy: 0.6753\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7435 - val_loss: 0.7541 - val_accuracy: 0.7208\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.7630 - val_loss: 0.7789 - val_accuracy: 0.7013\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.7717 - val_loss: 0.7582 - val_accuracy: 0.6948\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.7783 - val_loss: 0.8124 - val_accuracy: 0.6688\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.7630 - val_loss: 0.7618 - val_accuracy: 0.6753\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.7761 - val_loss: 0.7784 - val_accuracy: 0.6753\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.7804 - val_loss: 0.7578 - val_accuracy: 0.6818\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7761 - val_loss: 0.7721 - val_accuracy: 0.6688\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7674 - val_loss: 0.7620 - val_accuracy: 0.6883\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7565 - val_loss: 0.7388 - val_accuracy: 0.7013\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7652 - val_loss: 0.7783 - val_accuracy: 0.6818\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7696 - val_loss: 0.7327 - val_accuracy: 0.7143\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7761 - val_loss: 0.7611 - val_accuracy: 0.6948\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7783 - val_loss: 0.7343 - val_accuracy: 0.7078\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7609 - val_loss: 0.7693 - val_accuracy: 0.6753\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7696 - val_loss: 0.7329 - val_accuracy: 0.7013\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7935 - val_loss: 0.7634 - val_accuracy: 0.6948\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5722 - accuracy: 0.7761 - val_loss: 0.7493 - val_accuracy: 0.6948\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7652 - val_loss: 0.7567 - val_accuracy: 0.6818\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7761 - val_loss: 0.7246 - val_accuracy: 0.6948\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7826 - val_loss: 0.7285 - val_accuracy: 0.7013\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7630 - val_loss: 0.7496 - val_accuracy: 0.6948\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7783 - val_loss: 0.7449 - val_accuracy: 0.6818\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5564 - accuracy: 0.7717 - val_loss: 0.7239 - val_accuracy: 0.7143\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7783 - val_loss: 0.7711 - val_accuracy: 0.6753\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7761 - val_loss: 0.7256 - val_accuracy: 0.6948\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7848 - val_loss: 0.7129 - val_accuracy: 0.7273\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7826 - val_loss: 0.7655 - val_accuracy: 0.6753\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7565 - val_loss: 0.7204 - val_accuracy: 0.7078\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7565 - val_loss: 0.7096 - val_accuracy: 0.6948\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7804 - val_loss: 0.7821 - val_accuracy: 0.6753\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7522 - val_loss: 0.7066 - val_accuracy: 0.6883\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7587 - val_loss: 0.7646 - val_accuracy: 0.6688\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7696 - val_loss: 0.7028 - val_accuracy: 0.6948\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7652 - val_loss: 0.7418 - val_accuracy: 0.6948\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7783 - val_loss: 0.7164 - val_accuracy: 0.6688\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7522 - val_loss: 0.7501 - val_accuracy: 0.6818\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7652 - val_loss: 0.6945 - val_accuracy: 0.6883\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7196 - val_loss: 0.7812 - val_accuracy: 0.6558\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7522 - val_loss: 0.7149 - val_accuracy: 0.6883\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7674 - val_loss: 0.7067 - val_accuracy: 0.6883\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7804 - val_loss: 0.7343 - val_accuracy: 0.6883\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7848 - val_loss: 0.6770 - val_accuracy: 0.7143\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7848 - val_loss: 0.7237 - val_accuracy: 0.6818\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7891 - val_loss: 0.6881 - val_accuracy: 0.7208\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7804 - val_loss: 0.7450 - val_accuracy: 0.6948\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7848 - val_loss: 0.6960 - val_accuracy: 0.7013\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7674 - val_loss: 0.7579 - val_accuracy: 0.6818\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7935 - val_loss: 0.7136 - val_accuracy: 0.6948\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7891 - val_loss: 0.7316 - val_accuracy: 0.6948\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7913 - val_loss: 0.7112 - val_accuracy: 0.6948\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.8043 - val_loss: 0.7310 - val_accuracy: 0.6948\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.8065 - val_loss: 0.7333 - val_accuracy: 0.6948\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7848 - val_loss: 0.7146 - val_accuracy: 0.6948\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7848 - val_loss: 0.7519 - val_accuracy: 0.6883\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7935 - val_loss: 0.6911 - val_accuracy: 0.7078\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7891 - val_loss: 0.7233 - val_accuracy: 0.7013\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7891 - val_loss: 0.6958 - val_accuracy: 0.7013\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7674 - val_loss: 0.7202 - val_accuracy: 0.6883\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7913 - val_loss: 0.7280 - val_accuracy: 0.7078\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4934 - accuracy: 0.7870 - val_loss: 0.6979 - val_accuracy: 0.7013\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7891 - val_loss: 0.7027 - val_accuracy: 0.7013\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7957 - val_loss: 0.7248 - val_accuracy: 0.6883\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.6907 - val_accuracy: 0.7013\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7978 - val_loss: 0.7268 - val_accuracy: 0.6753\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7717 - val_loss: 0.6955 - val_accuracy: 0.7013\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7957 - val_loss: 0.7380 - val_accuracy: 0.6753\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.8087 - val_loss: 0.6966 - val_accuracy: 0.7208\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7935 - val_loss: 0.7398 - val_accuracy: 0.6948\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7935 - val_loss: 0.7087 - val_accuracy: 0.7208\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7826 - val_loss: 0.7048 - val_accuracy: 0.6948\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7848 - val_loss: 0.6763 - val_accuracy: 0.7078\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.8109 - val_loss: 0.7313 - val_accuracy: 0.7078\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7935 - val_loss: 0.6966 - val_accuracy: 0.7013\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.8065 - val_loss: 0.7421 - val_accuracy: 0.6818\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7870 - val_loss: 0.7203 - val_accuracy: 0.6948\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7717 - val_loss: 0.7232 - val_accuracy: 0.7013\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7783 - val_loss: 0.7284 - val_accuracy: 0.6688\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7804 - val_loss: 0.6843 - val_accuracy: 0.7078\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7848 - val_loss: 0.7307 - val_accuracy: 0.7208\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.8000 - val_loss: 0.6988 - val_accuracy: 0.7143\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8109 - val_loss: 0.7030 - val_accuracy: 0.6883\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.8043 - val_loss: 0.6927 - val_accuracy: 0.7078\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8043 - val_loss: 0.7484 - val_accuracy: 0.6818\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7978 - val_loss: 0.7222 - val_accuracy: 0.7143\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7935 - val_loss: 0.7162 - val_accuracy: 0.6883\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8196 - val_loss: 0.7299 - val_accuracy: 0.6688\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7957 - val_loss: 0.6890 - val_accuracy: 0.7078\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8022 - val_loss: 0.7922 - val_accuracy: 0.6948\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.8000 - val_loss: 0.6905 - val_accuracy: 0.7208\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7935 - val_loss: 0.7102 - val_accuracy: 0.7013\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8217 - val_loss: 0.7060 - val_accuracy: 0.7208\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.8000 - val_loss: 0.7260 - val_accuracy: 0.6883\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8065 - val_loss: 0.7013 - val_accuracy: 0.7078\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7761 - val_loss: 0.7317 - val_accuracy: 0.6883\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7978 - val_loss: 0.8153 - val_accuracy: 0.6623\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7935 - val_loss: 0.7309 - val_accuracy: 0.6883\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7848 - val_loss: 0.7565 - val_accuracy: 0.6818\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7978 - val_loss: 0.7204 - val_accuracy: 0.7143\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8022 - val_loss: 0.6807 - val_accuracy: 0.7013\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7500 - val_loss: 0.7827 - val_accuracy: 0.6623\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7957 - val_loss: 0.6954 - val_accuracy: 0.7078\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7848 - val_loss: 0.7288 - val_accuracy: 0.7078\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7891 - val_loss: 0.7899 - val_accuracy: 0.6818\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7826 - val_loss: 0.6910 - val_accuracy: 0.7143\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7935 - val_loss: 0.7345 - val_accuracy: 0.7013\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8065 - val_loss: 0.7026 - val_accuracy: 0.7208\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8000 - val_loss: 0.6992 - val_accuracy: 0.7013\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7935 - val_loss: 0.7458 - val_accuracy: 0.6753\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7848 - val_loss: 0.6905 - val_accuracy: 0.7403\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7913 - val_loss: 0.7819 - val_accuracy: 0.7078\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7761 - val_loss: 0.7237 - val_accuracy: 0.6948\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8065 - val_loss: 0.7468 - val_accuracy: 0.7273\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7978 - val_loss: 0.7936 - val_accuracy: 0.6883\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8022 - val_loss: 0.7585 - val_accuracy: 0.6948\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8109 - val_loss: 0.7142 - val_accuracy: 0.7143\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8152 - val_loss: 0.8122 - val_accuracy: 0.6948\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8087 - val_loss: 0.7126 - val_accuracy: 0.7078\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7891 - val_loss: 0.8183 - val_accuracy: 0.6688\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.8022 - val_loss: 0.7405 - val_accuracy: 0.7143\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8022 - val_loss: 0.7143 - val_accuracy: 0.7208\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8022 - val_loss: 0.7410 - val_accuracy: 0.6948\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8022 - val_loss: 0.7590 - val_accuracy: 0.7013\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8043 - val_loss: 0.7829 - val_accuracy: 0.6883\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8065 - val_loss: 0.7172 - val_accuracy: 0.6883\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8109 - val_loss: 0.7512 - val_accuracy: 0.7078\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8283 - val_loss: 0.7497 - val_accuracy: 0.7273\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8130 - val_loss: 0.7099 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history = model7.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZdmROIDLNb9",
    "outputId": "90b5cb26-5c21-4c49-b7d6-3778f5bb767a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7026154398918152, 0.7272727489471436]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgRCZ4tMLX_a",
    "outputId": "c847d96c-e871-409e-fe23-ffc169ecff6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 998us/step - loss: 0.7199 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7199039459228516, 0.6883116960525513]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_twaWQ0LcD4",
    "outputId": "586aef37-1a36-411b-e255-3f5f9457b133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7199039459228516, 0.6883116960525513]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "f0AYjF9yLvLR"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l1\n",
    "\n",
    "model7 = Sequential()\n",
    "model7.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(36, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(24, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(12, activation='relu', kernel_regularizer=l1(0.1), bias_regularizer=l1(0.1)))\n",
    "model7.add(Dense(8, activation='relu'))\n",
    "model7.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "Ov3hy2BCNtQS"
   },
   "outputs": [],
   "source": [
    "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gbOxM8BNwEB",
    "outputId": "c27c1b7e-8c52-4585-ceaa-c38e2de4a123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 33ms/step - loss: 61.2333 - accuracy: 0.6457 - val_loss: 58.9344 - val_accuracy: 0.5909\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.9559 - accuracy: 0.6457 - val_loss: 56.5453 - val_accuracy: 0.5909\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 55.6402 - accuracy: 0.6457 - val_loss: 54.2631 - val_accuracy: 0.5909\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.3542 - accuracy: 0.6478 - val_loss: 52.0078 - val_accuracy: 0.5909\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.1052 - accuracy: 0.6370 - val_loss: 49.7801 - val_accuracy: 0.5844\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 48.8863 - accuracy: 0.6457 - val_loss: 47.5794 - val_accuracy: 0.5909\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 46.6931 - accuracy: 0.6435 - val_loss: 45.4044 - val_accuracy: 0.5844\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 44.5360 - accuracy: 0.6478 - val_loss: 43.2723 - val_accuracy: 0.5844\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.4245 - accuracy: 0.6457 - val_loss: 41.1947 - val_accuracy: 0.5779\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 40.3721 - accuracy: 0.6478 - val_loss: 39.1606 - val_accuracy: 0.5584\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 38.3567 - accuracy: 0.6435 - val_loss: 37.1742 - val_accuracy: 0.5844\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 36.3893 - accuracy: 0.6500 - val_loss: 35.2357 - val_accuracy: 0.5844\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34.4658 - accuracy: 0.6457 - val_loss: 33.3445 - val_accuracy: 0.5909\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 32.5918 - accuracy: 0.6457 - val_loss: 31.5038 - val_accuracy: 0.5909\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 30.7638 - accuracy: 0.6457 - val_loss: 29.7020 - val_accuracy: 0.5909\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28.9946 - accuracy: 0.6457 - val_loss: 27.9696 - val_accuracy: 0.5909\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 27.2772 - accuracy: 0.6457 - val_loss: 26.2769 - val_accuracy: 0.5909\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.6138 - accuracy: 0.6457 - val_loss: 24.6499 - val_accuracy: 0.5909\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 24.0148 - accuracy: 0.6457 - val_loss: 23.0811 - val_accuracy: 0.5909\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 22.4654 - accuracy: 0.6457 - val_loss: 21.5602 - val_accuracy: 0.5909\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20.9645 - accuracy: 0.6457 - val_loss: 20.0896 - val_accuracy: 0.5909\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.5177 - accuracy: 0.6457 - val_loss: 18.6784 - val_accuracy: 0.5909\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.1317 - accuracy: 0.6457 - val_loss: 17.3275 - val_accuracy: 0.5909\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.8030 - accuracy: 0.6457 - val_loss: 16.0300 - val_accuracy: 0.5909\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.5282 - accuracy: 0.6457 - val_loss: 14.7879 - val_accuracy: 0.5909\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.3117 - accuracy: 0.6457 - val_loss: 13.6143 - val_accuracy: 0.5909\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.1596 - accuracy: 0.6457 - val_loss: 12.4942 - val_accuracy: 0.5909\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.0599 - accuracy: 0.6457 - val_loss: 11.4271 - val_accuracy: 0.5909\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.0168 - accuracy: 0.6457 - val_loss: 10.4273 - val_accuracy: 0.5909\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.0441 - accuracy: 0.6457 - val_loss: 9.4883 - val_accuracy: 0.5909\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.1216 - accuracy: 0.6457 - val_loss: 8.5982 - val_accuracy: 0.5909\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.2543 - accuracy: 0.6457 - val_loss: 7.7679 - val_accuracy: 0.5909\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.4460 - accuracy: 0.6457 - val_loss: 6.9956 - val_accuracy: 0.5909\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6966 - accuracy: 0.6457 - val_loss: 6.2864 - val_accuracy: 0.5909\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.0067 - accuracy: 0.6457 - val_loss: 5.6317 - val_accuracy: 0.5909\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.3781 - accuracy: 0.6457 - val_loss: 5.0456 - val_accuracy: 0.5909\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.8148 - accuracy: 0.6457 - val_loss: 4.5167 - val_accuracy: 0.5909\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.3069 - accuracy: 0.6457 - val_loss: 4.0495 - val_accuracy: 0.5909\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8666 - accuracy: 0.6457 - val_loss: 3.6535 - val_accuracy: 0.5909\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4932 - accuracy: 0.6457 - val_loss: 3.3091 - val_accuracy: 0.5909\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1632 - accuracy: 0.6457 - val_loss: 3.0108 - val_accuracy: 0.5909\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8816 - accuracy: 0.6457 - val_loss: 2.7542 - val_accuracy: 0.5909\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6410 - accuracy: 0.6457 - val_loss: 2.5350 - val_accuracy: 0.5909\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4295 - accuracy: 0.6457 - val_loss: 2.3458 - val_accuracy: 0.5909\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2561 - accuracy: 0.6457 - val_loss: 2.1844 - val_accuracy: 0.5909\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0978 - accuracy: 0.6457 - val_loss: 2.0361 - val_accuracy: 0.5909\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.9578 - accuracy: 0.6457 - val_loss: 1.9082 - val_accuracy: 0.5909\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.8338 - accuracy: 0.6457 - val_loss: 1.7914 - val_accuracy: 0.5909\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.7201 - accuracy: 0.6457 - val_loss: 1.6848 - val_accuracy: 0.5909\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.6204 - accuracy: 0.6457 - val_loss: 1.5966 - val_accuracy: 0.5909\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.5346 - accuracy: 0.6457 - val_loss: 1.5176 - val_accuracy: 0.5909\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.4609 - accuracy: 0.6457 - val_loss: 1.4461 - val_accuracy: 0.5909\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.6457 - val_loss: 1.3804 - val_accuracy: 0.5909\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.3267 - accuracy: 0.6457 - val_loss: 1.3205 - val_accuracy: 0.5909\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2682 - accuracy: 0.6457 - val_loss: 1.2650 - val_accuracy: 0.5909\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2143 - accuracy: 0.6457 - val_loss: 1.2141 - val_accuracy: 0.5909\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1658 - accuracy: 0.6457 - val_loss: 1.1711 - val_accuracy: 0.5909\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.1235 - accuracy: 0.6457 - val_loss: 1.1303 - val_accuracy: 0.5909\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0838 - accuracy: 0.6457 - val_loss: 1.0929 - val_accuracy: 0.5909\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.0477 - accuracy: 0.6457 - val_loss: 1.0571 - val_accuracy: 0.5909\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0121 - accuracy: 0.6457 - val_loss: 1.0235 - val_accuracy: 0.5909\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.6457 - val_loss: 0.9945 - val_accuracy: 0.5909\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9507 - accuracy: 0.6457 - val_loss: 0.9650 - val_accuracy: 0.5909\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9233 - accuracy: 0.6457 - val_loss: 0.9421 - val_accuracy: 0.5909\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.6457 - val_loss: 0.9217 - val_accuracy: 0.5909\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8812 - accuracy: 0.6457 - val_loss: 0.9030 - val_accuracy: 0.5909\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8635 - accuracy: 0.6457 - val_loss: 0.8865 - val_accuracy: 0.5909\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8483 - accuracy: 0.6457 - val_loss: 0.8721 - val_accuracy: 0.5909\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8333 - accuracy: 0.6457 - val_loss: 0.8573 - val_accuracy: 0.5909\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.6457 - val_loss: 0.8433 - val_accuracy: 0.5909\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8051 - accuracy: 0.6457 - val_loss: 0.8301 - val_accuracy: 0.5909\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.6457 - val_loss: 0.8189 - val_accuracy: 0.5909\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7820 - accuracy: 0.6457 - val_loss: 0.8090 - val_accuracy: 0.5909\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.6457 - val_loss: 0.7995 - val_accuracy: 0.5909\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.6457 - val_loss: 0.7908 - val_accuracy: 0.5909\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7544 - accuracy: 0.6457 - val_loss: 0.7840 - val_accuracy: 0.5909\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.6457 - val_loss: 0.7778 - val_accuracy: 0.5909\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.6457 - val_loss: 0.7729 - val_accuracy: 0.5909\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7381 - accuracy: 0.6457 - val_loss: 0.7689 - val_accuracy: 0.5909\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.6457 - val_loss: 0.7640 - val_accuracy: 0.5909\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.6457 - val_loss: 0.7587 - val_accuracy: 0.5909\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.6457 - val_loss: 0.7545 - val_accuracy: 0.5909\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7214 - accuracy: 0.6457 - val_loss: 0.7519 - val_accuracy: 0.5909\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.6457 - val_loss: 0.7468 - val_accuracy: 0.5909\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7140 - accuracy: 0.6457 - val_loss: 0.7442 - val_accuracy: 0.5909\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7116 - accuracy: 0.6457 - val_loss: 0.7435 - val_accuracy: 0.5909\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7102 - accuracy: 0.6457 - val_loss: 0.7403 - val_accuracy: 0.5909\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.6457 - val_loss: 0.7375 - val_accuracy: 0.5909\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7054 - accuracy: 0.6457 - val_loss: 0.7366 - val_accuracy: 0.5909\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7052 - accuracy: 0.6457 - val_loss: 0.7354 - val_accuracy: 0.5909\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.6457 - val_loss: 0.7326 - val_accuracy: 0.5909\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.6457 - val_loss: 0.7317 - val_accuracy: 0.5909\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.6457 - val_loss: 0.7313 - val_accuracy: 0.5909\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.6457 - val_loss: 0.7302 - val_accuracy: 0.5909\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.67 - 0s 4ms/step - loss: 0.6984 - accuracy: 0.6457 - val_loss: 0.7284 - val_accuracy: 0.5909\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6956 - accuracy: 0.6457 - val_loss: 0.7274 - val_accuracy: 0.5909\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.6457 - val_loss: 0.7243 - val_accuracy: 0.5909\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7239 - val_accuracy: 0.5909\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7247 - val_accuracy: 0.5909\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7236 - val_accuracy: 0.5909\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7235 - val_accuracy: 0.5909\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7238 - val_accuracy: 0.5909\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7248 - val_accuracy: 0.5909\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7240 - val_accuracy: 0.5909\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6457 - val_loss: 0.7237 - val_accuracy: 0.5909\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7239 - val_accuracy: 0.5909\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7240 - val_accuracy: 0.5909\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7246 - val_accuracy: 0.5909\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7247 - val_accuracy: 0.5909\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.65 - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7245 - val_accuracy: 0.5909\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7245 - val_accuracy: 0.5909\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7245 - val_accuracy: 0.5909\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7268 - val_accuracy: 0.5909\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7246 - val_accuracy: 0.5909\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6403 - accuracy: 0.73 - 0s 4ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7242 - val_accuracy: 0.5909\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "history = model7.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi4EMA6GNyzO",
    "outputId": "2e57b1df-3b9a-4b52-c844-81e579ea1214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 999us/step - loss: 0.6428 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6428117752075195, 0.7272727489471436]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "wCYOrsu5SeaT"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "    #  import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yczYlXoPRtkt",
    "outputId": "2ca7f246-684b-48dc-e8b4-5abac5d35a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7259 - val_accuracy: 0.5909\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7259 - val_accuracy: 0.5909\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7272 - val_accuracy: 0.5909\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7247 - val_accuracy: 0.5909\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7248 - val_accuracy: 0.5909\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7259 - val_accuracy: 0.5909\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.64 - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7241 - val_accuracy: 0.5909\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7274 - val_accuracy: 0.5909\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7272 - val_accuracy: 0.5909\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7279 - val_accuracy: 0.5909\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7281 - val_accuracy: 0.5909\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7275 - val_accuracy: 0.5909\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7272 - val_accuracy: 0.5909\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7274 - val_accuracy: 0.5909\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7249 - val_accuracy: 0.5909\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7252 - val_accuracy: 0.5909\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7260 - val_accuracy: 0.5909\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7274 - val_accuracy: 0.5909\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7259 - val_accuracy: 0.5909\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7270 - val_accuracy: 0.5909\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7259 - val_accuracy: 0.5909\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7257 - val_accuracy: 0.5909\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7255 - val_accuracy: 0.5909\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7264 - val_accuracy: 0.5909\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7275 - val_accuracy: 0.5909\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7269 - val_accuracy: 0.5909\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7274 - val_accuracy: 0.5909\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7275 - val_accuracy: 0.5909\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7272 - val_accuracy: 0.5909\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7281 - val_accuracy: 0.5909\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6457 - val_loss: 0.7271 - val_accuracy: 0.5909\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7261 - val_accuracy: 0.5909\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7263 - val_accuracy: 0.5909\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7247 - val_accuracy: 0.5909\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7247 - val_accuracy: 0.5909\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7251 - val_accuracy: 0.5909\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7250 - val_accuracy: 0.5909\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7265 - val_accuracy: 0.5909\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7254 - val_accuracy: 0.5909\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.6457 - val_loss: 0.7253 - val_accuracy: 0.5909\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7266 - val_accuracy: 0.5909\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7268 - val_accuracy: 0.5909\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7267 - val_accuracy: 0.5909\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.7276 - val_accuracy: 0.5909\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7279 - val_accuracy: 0.5909\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.6457 - val_loss: 0.7280 - val_accuracy: 0.5909\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7284 - val_accuracy: 0.5909\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.6457 - val_loss: 0.7278 - val_accuracy: 0.5909\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.6457 - val_loss: 0.7287 - val_accuracy: 0.5909\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.6457 - val_loss: 0.7286 - val_accuracy: 0.5909\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.6457 - val_loss: 0.7278 - val_accuracy: 0.5909\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.6457 - val_loss: 0.7289 - val_accuracy: 0.5909\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.6457 - val_loss: 0.7283 - val_accuracy: 0.5909\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.6457 - val_loss: 0.7268 - val_accuracy: 0.5909\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7268 - val_accuracy: 0.5909\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.6457 - val_loss: 0.7281 - val_accuracy: 0.5909\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.6457 - val_loss: 0.7258 - val_accuracy: 0.5909\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6457 - val_loss: 0.7256 - val_accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "history = model7.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    "     callbacks=[tensorboard_callback]\n",
    ")\n",
    "# model7.fit(x=x_train, \n",
    "#           y=y_train, \n",
    "#           epochs=5, \n",
    "#           validation_data=(x_test, y_test), \n",
    "#           callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4-MzjTGUweu",
    "outputId": "b4d35c94-adc5-4255-991c-089e303c15fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 36)                900       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,821\n",
      "Trainable params: 3,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "NPL8p7cnTSuJ"
   },
   "outputs": [],
   "source": [
    "# Take a break for 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEagQk69aT-0",
    "outputId": "021f10e7-0911-4e4d-d98a-6dfe9de91ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 36)                900       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,821\n",
      "Trainable params: 3,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "3qdcgj3Cb3CV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "fF98VxR5baPR"
   },
   "outputs": [],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Dense(12, activation='relu', input_shape=(8,)))\n",
    "model8.add(Dense(24, activation='relu'))\n",
    "\n",
    "model8.add(Dense(24, activation='relu'))\n",
    "model8.add(Dense(36, activation='relu'))\n",
    "\n",
    "\n",
    "model8.add(Dense(24, activation='relu'))\n",
    "model8.add(Dense(24, activation='relu'))\n",
    "model8.add(Dropout(0.2))\n",
    "model8.add(Dense(12, activation='relu'))\n",
    "model8.add(Dense(8, activation='relu'))\n",
    "model8.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "RzY0BzX5cE11"
   },
   "outputs": [],
   "source": [
    "model8.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tceDp9HKcVCC",
    "outputId": "d16cd742-039b-4102-fea1-7a761703107f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 36)                900       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,821\n",
      "Trainable params: 3,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGQK_DhRcLaS",
    "outputId": "4aa8dd41-178d-4d49-ebc2-4f81f7a15897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 35ms/step - loss: 1.8163 - accuracy: 0.4500 - val_loss: 0.8836 - val_accuracy: 0.5909\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7920 - accuracy: 0.6261 - val_loss: 0.7708 - val_accuracy: 0.6039\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.5826 - val_loss: 0.7127 - val_accuracy: 0.5779\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.5761 - val_loss: 0.6706 - val_accuracy: 0.6364\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7193 - accuracy: 0.5848 - val_loss: 0.6596 - val_accuracy: 0.6818\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6174 - val_loss: 0.6867 - val_accuracy: 0.6039\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6152 - val_loss: 0.6969 - val_accuracy: 0.5909\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.6457 - val_loss: 0.6477 - val_accuracy: 0.6688\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.6130 - val_loss: 0.6538 - val_accuracy: 0.6364\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6261 - val_loss: 0.6539 - val_accuracy: 0.6753\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.6348 - val_loss: 0.6579 - val_accuracy: 0.6104\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6216 - accuracy: 0.6870 - val_loss: 0.6468 - val_accuracy: 0.6818\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6739 - val_loss: 0.6695 - val_accuracy: 0.6039\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6543 - val_loss: 0.6402 - val_accuracy: 0.6364\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6674 - val_loss: 0.6543 - val_accuracy: 0.6234\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.6826 - val_loss: 0.6352 - val_accuracy: 0.6688\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6138 - accuracy: 0.6804 - val_loss: 0.6691 - val_accuracy: 0.6104\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6229 - accuracy: 0.6543 - val_loss: 0.6408 - val_accuracy: 0.6753\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.6739 - val_loss: 0.6527 - val_accuracy: 0.6429\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.6870 - val_loss: 0.6525 - val_accuracy: 0.6429\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6565 - val_loss: 0.6293 - val_accuracy: 0.6623\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.6826 - val_loss: 0.6485 - val_accuracy: 0.6623\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.6587 - val_loss: 0.6418 - val_accuracy: 0.6948\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5994 - accuracy: 0.6870 - val_loss: 0.6285 - val_accuracy: 0.6883\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6053 - accuracy: 0.6522 - val_loss: 0.6536 - val_accuracy: 0.6364\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.6717 - val_loss: 0.6900 - val_accuracy: 0.6429\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6156 - accuracy: 0.6739 - val_loss: 0.6419 - val_accuracy: 0.7143\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.6870 - val_loss: 0.6722 - val_accuracy: 0.6558\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.6783 - val_loss: 0.6508 - val_accuracy: 0.6429\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6891 - val_loss: 0.6357 - val_accuracy: 0.6688\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.6978 - val_loss: 0.6525 - val_accuracy: 0.6494\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.6739 - val_loss: 0.6456 - val_accuracy: 0.6558\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.6957 - val_loss: 0.6533 - val_accuracy: 0.6948\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.7000 - val_loss: 0.6550 - val_accuracy: 0.6623\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.6783 - val_loss: 0.7120 - val_accuracy: 0.6234\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.6804 - val_loss: 0.6371 - val_accuracy: 0.6883\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.6913 - val_loss: 0.6843 - val_accuracy: 0.6429\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.6935 - val_loss: 0.6300 - val_accuracy: 0.6818\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5627 - accuracy: 0.6978 - val_loss: 0.7485 - val_accuracy: 0.6558\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.7152 - val_loss: 0.6397 - val_accuracy: 0.7013\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.7174 - val_loss: 0.6896 - val_accuracy: 0.6623\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7152 - val_loss: 0.6466 - val_accuracy: 0.6558\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7109 - val_loss: 0.6881 - val_accuracy: 0.6494\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.7022 - val_loss: 0.6295 - val_accuracy: 0.7143\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5720 - accuracy: 0.7065 - val_loss: 0.7128 - val_accuracy: 0.6623\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.6935 - val_loss: 0.6304 - val_accuracy: 0.7078\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7022 - val_loss: 0.6582 - val_accuracy: 0.6753\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.7130 - val_loss: 0.6896 - val_accuracy: 0.6494\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7043 - val_loss: 0.7019 - val_accuracy: 0.6364\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7130 - val_loss: 0.6538 - val_accuracy: 0.6623\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.7283 - val_loss: 0.6521 - val_accuracy: 0.7013\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7261 - val_loss: 0.6871 - val_accuracy: 0.6753\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7130 - val_loss: 0.6601 - val_accuracy: 0.6883\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7239 - val_loss: 0.7139 - val_accuracy: 0.6558\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7109 - val_loss: 0.6240 - val_accuracy: 0.7208\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.6870 - val_loss: 0.6993 - val_accuracy: 0.6494\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7196 - val_loss: 0.6585 - val_accuracy: 0.7078\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.6978 - val_loss: 0.6685 - val_accuracy: 0.7078\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7152 - val_loss: 0.6904 - val_accuracy: 0.6883\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7043 - val_loss: 0.6651 - val_accuracy: 0.7013\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7087 - val_loss: 0.7292 - val_accuracy: 0.6623\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.7304 - val_loss: 0.6798 - val_accuracy: 0.6494\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7196 - val_loss: 0.6969 - val_accuracy: 0.6688\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7283 - val_loss: 0.6614 - val_accuracy: 0.7143\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7174 - val_loss: 0.8224 - val_accuracy: 0.6688\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.6957 - val_loss: 0.6365 - val_accuracy: 0.7532\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7152 - val_loss: 0.7213 - val_accuracy: 0.6623\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7109 - val_loss: 0.7024 - val_accuracy: 0.6883\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7391 - val_loss: 0.6603 - val_accuracy: 0.7273\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7283 - val_loss: 0.7350 - val_accuracy: 0.6623\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7261 - val_loss: 0.6365 - val_accuracy: 0.6818\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7174 - val_loss: 0.6928 - val_accuracy: 0.6299\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7370 - val_loss: 0.6762 - val_accuracy: 0.7208\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7217 - val_loss: 0.7008 - val_accuracy: 0.6818\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7174 - val_loss: 0.6762 - val_accuracy: 0.7013\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.7239 - val_loss: 0.6830 - val_accuracy: 0.6948\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7217 - val_loss: 0.6803 - val_accuracy: 0.7013\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7391 - val_loss: 0.6507 - val_accuracy: 0.7078\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7283 - val_loss: 0.7268 - val_accuracy: 0.6299\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7217 - val_loss: 0.6459 - val_accuracy: 0.7403\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7239 - val_loss: 0.7782 - val_accuracy: 0.6299\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7217 - val_loss: 0.6481 - val_accuracy: 0.7013\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7543 - val_loss: 0.7999 - val_accuracy: 0.6818\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7196 - val_loss: 0.6411 - val_accuracy: 0.7078\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7152 - val_loss: 0.7807 - val_accuracy: 0.6623\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7304 - val_loss: 0.6813 - val_accuracy: 0.6883\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7261 - val_loss: 0.6687 - val_accuracy: 0.6948\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7478 - val_loss: 0.6758 - val_accuracy: 0.7078\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7326 - val_loss: 0.6610 - val_accuracy: 0.7208\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.6957 - val_loss: 0.7119 - val_accuracy: 0.6688\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7109 - val_loss: 0.6774 - val_accuracy: 0.6688\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7326 - val_loss: 0.6547 - val_accuracy: 0.6948\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7370 - val_loss: 0.7020 - val_accuracy: 0.6688\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7217 - val_loss: 0.6915 - val_accuracy: 0.7013\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7565 - val_loss: 0.6980 - val_accuracy: 0.7143\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7304 - val_loss: 0.7635 - val_accuracy: 0.6623\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7109 - val_loss: 0.6647 - val_accuracy: 0.7143\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7370 - val_loss: 0.7377 - val_accuracy: 0.6818\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7348 - val_loss: 0.7223 - val_accuracy: 0.7143\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.7435 - val_loss: 0.6833 - val_accuracy: 0.6753\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7304 - val_loss: 0.6848 - val_accuracy: 0.6948\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7457 - val_loss: 0.6775 - val_accuracy: 0.6948\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7326 - val_loss: 0.6804 - val_accuracy: 0.7273\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7283 - val_loss: 0.7230 - val_accuracy: 0.7013\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7457 - val_loss: 0.7165 - val_accuracy: 0.6883\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7304 - val_loss: 0.7461 - val_accuracy: 0.6623\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7370 - val_loss: 0.6687 - val_accuracy: 0.7013\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7435 - val_loss: 0.7602 - val_accuracy: 0.6623\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7457 - val_loss: 0.6583 - val_accuracy: 0.7208\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7304 - val_loss: 0.7224 - val_accuracy: 0.6883\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7304 - val_loss: 0.7009 - val_accuracy: 0.6883\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7348 - val_loss: 0.7479 - val_accuracy: 0.7208\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7348 - val_loss: 0.7064 - val_accuracy: 0.7273\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7239 - val_loss: 0.6980 - val_accuracy: 0.7143\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7543 - val_loss: 0.6922 - val_accuracy: 0.7143\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7435 - val_loss: 0.7082 - val_accuracy: 0.7532\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.7626 - val_accuracy: 0.6883\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7152 - val_loss: 0.6683 - val_accuracy: 0.7532\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7652 - val_loss: 0.7151 - val_accuracy: 0.7013\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7087 - val_loss: 0.7092 - val_accuracy: 0.7273\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7717 - val_loss: 0.7185 - val_accuracy: 0.7078\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7500 - val_loss: 0.6671 - val_accuracy: 0.7597\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7565 - val_loss: 0.7714 - val_accuracy: 0.6558\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7239 - val_loss: 0.6875 - val_accuracy: 0.6558\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7348 - val_loss: 0.6904 - val_accuracy: 0.6753\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7565 - val_loss: 0.6632 - val_accuracy: 0.7208\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7522 - val_loss: 0.7824 - val_accuracy: 0.6818\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5101 - accuracy: 0.7413 - val_loss: 0.6525 - val_accuracy: 0.7273\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7022 - val_loss: 0.7491 - val_accuracy: 0.6364\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7087 - val_loss: 0.6676 - val_accuracy: 0.6948\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7696 - val_loss: 0.7132 - val_accuracy: 0.6948\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7239 - val_loss: 0.6987 - val_accuracy: 0.6948\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7587 - val_loss: 0.7171 - val_accuracy: 0.7208\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7478 - val_loss: 0.6734 - val_accuracy: 0.7403\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7043 - val_loss: 0.6517 - val_accuracy: 0.6948\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7326 - val_loss: 0.7137 - val_accuracy: 0.6429\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.7739 - val_loss: 0.6766 - val_accuracy: 0.7208\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7326 - val_loss: 0.7181 - val_accuracy: 0.7078\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7196 - val_loss: 0.7046 - val_accuracy: 0.7013\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7543 - val_loss: 0.7132 - val_accuracy: 0.6948\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7326 - val_loss: 0.7197 - val_accuracy: 0.6818\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7457 - val_loss: 0.6955 - val_accuracy: 0.7208\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7435 - val_loss: 0.6822 - val_accuracy: 0.7403\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7457 - val_loss: 0.6980 - val_accuracy: 0.7143\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7522 - val_loss: 0.7747 - val_accuracy: 0.6948\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7587 - val_loss: 0.6463 - val_accuracy: 0.7273\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7043 - val_loss: 0.7344 - val_accuracy: 0.6818\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7543 - val_loss: 0.6973 - val_accuracy: 0.7273\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7500 - val_loss: 0.7024 - val_accuracy: 0.7078\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7674 - val_loss: 0.7244 - val_accuracy: 0.7013\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7543 - val_loss: 0.6961 - val_accuracy: 0.7013\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7609 - val_loss: 0.7282 - val_accuracy: 0.6948\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.7739 - val_loss: 0.7395 - val_accuracy: 0.6818\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7565 - val_loss: 0.7221 - val_accuracy: 0.6753\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7500 - val_loss: 0.6768 - val_accuracy: 0.7143\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7609 - val_loss: 0.7358 - val_accuracy: 0.7013\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7717 - val_loss: 0.7332 - val_accuracy: 0.6948\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7543 - val_loss: 0.6758 - val_accuracy: 0.7208\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7457 - val_loss: 0.6847 - val_accuracy: 0.7273\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7652 - val_loss: 0.7427 - val_accuracy: 0.6948\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7522 - val_loss: 0.7297 - val_accuracy: 0.6948\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7609 - val_loss: 0.7142 - val_accuracy: 0.7078\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7457 - val_loss: 0.7118 - val_accuracy: 0.7273\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7609 - val_loss: 0.7173 - val_accuracy: 0.7143\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7717 - val_loss: 0.7349 - val_accuracy: 0.6818\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7783 - val_loss: 0.7004 - val_accuracy: 0.7273\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.7587 - val_loss: 0.7247 - val_accuracy: 0.7078\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7565 - val_loss: 0.6769 - val_accuracy: 0.7403\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7565 - val_loss: 0.7284 - val_accuracy: 0.7013\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7239 - val_loss: 0.7326 - val_accuracy: 0.6494\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7065 - val_loss: 0.6897 - val_accuracy: 0.6818\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5192 - accuracy: 0.7543 - val_loss: 0.6562 - val_accuracy: 0.6883\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7435 - val_loss: 0.7757 - val_accuracy: 0.6558\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7413 - val_loss: 0.7595 - val_accuracy: 0.7143\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7435 - val_loss: 0.8199 - val_accuracy: 0.6818\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7674 - val_loss: 0.7136 - val_accuracy: 0.7013\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.7532 - val_accuracy: 0.7078\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7739 - val_loss: 0.7750 - val_accuracy: 0.6883\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7696 - val_loss: 0.7143 - val_accuracy: 0.7208\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7652 - val_loss: 0.7463 - val_accuracy: 0.7208\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7717 - val_loss: 0.8280 - val_accuracy: 0.6948\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7565 - val_loss: 0.7608 - val_accuracy: 0.7078\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7630 - val_loss: 0.7268 - val_accuracy: 0.7143\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7609 - val_loss: 0.7269 - val_accuracy: 0.7143\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7587 - val_loss: 0.7247 - val_accuracy: 0.7208\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7500 - val_loss: 0.7714 - val_accuracy: 0.6558\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7370 - val_loss: 0.7354 - val_accuracy: 0.6818\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7500 - val_loss: 0.7151 - val_accuracy: 0.6753\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7652 - val_loss: 0.7359 - val_accuracy: 0.6948\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7543 - val_loss: 0.7893 - val_accuracy: 0.6753\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7457 - val_loss: 0.6902 - val_accuracy: 0.7143\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7543 - val_loss: 0.7877 - val_accuracy: 0.6753\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.8000 - val_loss: 0.7162 - val_accuracy: 0.7273\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7783 - val_loss: 0.7977 - val_accuracy: 0.7013\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7609 - val_loss: 0.7441 - val_accuracy: 0.7208\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7696 - val_loss: 0.7644 - val_accuracy: 0.6948\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7696 - val_loss: 0.7252 - val_accuracy: 0.7078\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7630 - val_loss: 0.7781 - val_accuracy: 0.7013\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7696 - val_loss: 0.7964 - val_accuracy: 0.6948\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7826 - val_loss: 0.7301 - val_accuracy: 0.7078\n"
     ]
    }
   ],
   "source": [
    "history = model8.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=200,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mq1gecUfcQYc",
    "outputId": "9949484e-ae4b-4e49-94d0-114dd01198f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6613280773162842, 0.7142857313156128]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "A-dxfJPucyXG"
   },
   "outputs": [],
   "source": [
    "# Try dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "aRLvRD5cfUg2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wfm_fmKUfkj6",
    "outputId": "6a447894-54ef-40d1-cd0e-92d1659155ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "LaAjzBEkflR2",
    "outputId": "6116752f-01f3-43e3-d643-9f0f7bffd19e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['sepal_length','sepal_width', 'petal_length', 'petal_width']]\n",
    "# X = df.drop(columns='Outcome')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAjG76wbftP4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "_bQttGJ8hDrk"
   },
   "outputs": [],
   "source": [
    "df.species = pd.Categorical(df.species)\n",
    "df['species'] = df.species.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "pmcClTZ8hRH6",
    "outputId": "ac80eb4a-1731-4500-8b51-14784ad21cb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "iWol7kI0hTJk",
    "outputId": "9f4381ef-e7b0-4dd3-abde-7f0689dd6965"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     species\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "..       ...\n",
       "145        2\n",
       "146        2\n",
       "147        2\n",
       "148        2\n",
       "149        2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[['species']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "YBQDbHr1hyb1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzPWWzSFiGAw",
    "outputId": "a3da4a06-bce4-49be-944c-a69284b2500e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GokjXiT9iHm-",
    "outputId": "036d621b-5fd1-4445-d665-4269a1a1dcae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRH0Dw2fiKcd",
    "outputId": "15f818ae-7a13-4af4-bf70-3ec71d3cabf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "XFeUTPfHlIW7"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hNoFK94lW9Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "au8hTG-Ikhaq"
   },
   "outputs": [],
   "source": [
    "model9 = Sequential()\n",
    "model9.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "model9.add(Dense(9, activation='relu'))\n",
    "model9.add(Dense(3, activation='softmax'))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "oy5T03cHiMPI"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model9.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KL3VC9bHiU4d",
    "outputId": "f510df79-9640-43c3-b76b-1b2765f8da6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "3/3 [==============================] - 1s 93ms/step - loss: 1.0341 - accuracy: 0.3556 - val_loss: 1.0162 - val_accuracy: 0.6333\n",
      "Epoch 2/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0282 - accuracy: 0.5333 - val_loss: 1.0090 - val_accuracy: 0.7667\n",
      "Epoch 3/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0233 - accuracy: 0.5444 - val_loss: 1.0033 - val_accuracy: 0.7000\n",
      "Epoch 4/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0186 - accuracy: 0.5556 - val_loss: 0.9987 - val_accuracy: 0.7000\n",
      "Epoch 5/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0152 - accuracy: 0.5556 - val_loss: 0.9948 - val_accuracy: 0.6000\n",
      "Epoch 6/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0117 - accuracy: 0.5556 - val_loss: 0.9903 - val_accuracy: 0.6000\n",
      "Epoch 7/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0081 - accuracy: 0.5556 - val_loss: 0.9850 - val_accuracy: 0.6000\n",
      "Epoch 8/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0040 - accuracy: 0.5667 - val_loss: 0.9794 - val_accuracy: 0.6000\n",
      "Epoch 9/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9999 - accuracy: 0.5667 - val_loss: 0.9734 - val_accuracy: 0.6333\n",
      "Epoch 10/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9953 - accuracy: 0.5556 - val_loss: 0.9669 - val_accuracy: 0.7000\n",
      "Epoch 11/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9900 - accuracy: 0.5556 - val_loss: 0.9601 - val_accuracy: 0.7000\n",
      "Epoch 12/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9846 - accuracy: 0.5556 - val_loss: 0.9526 - val_accuracy: 0.7000\n",
      "Epoch 13/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9794 - accuracy: 0.5556 - val_loss: 0.9454 - val_accuracy: 0.7333\n",
      "Epoch 14/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9726 - accuracy: 0.5778 - val_loss: 0.9395 - val_accuracy: 0.7000\n",
      "Epoch 15/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9669 - accuracy: 0.5778 - val_loss: 0.9341 - val_accuracy: 0.7000\n",
      "Epoch 16/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9595 - accuracy: 0.5778 - val_loss: 0.9291 - val_accuracy: 0.7000\n",
      "Epoch 17/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9548 - accuracy: 0.5667 - val_loss: 0.9246 - val_accuracy: 0.7000\n",
      "Epoch 18/250\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9273 - accuracy: 0.68 - 0s 12ms/step - loss: 0.9514 - accuracy: 0.5556 - val_loss: 0.9201 - val_accuracy: 0.6667\n",
      "Epoch 19/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9475 - accuracy: 0.5556 - val_loss: 0.9138 - val_accuracy: 0.6667\n",
      "Epoch 20/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9423 - accuracy: 0.5556 - val_loss: 0.9069 - val_accuracy: 0.7000\n",
      "Epoch 21/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9377 - accuracy: 0.5667 - val_loss: 0.8999 - val_accuracy: 0.7000\n",
      "Epoch 22/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9326 - accuracy: 0.5778 - val_loss: 0.8932 - val_accuracy: 0.7333\n",
      "Epoch 23/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9282 - accuracy: 0.5778 - val_loss: 0.8872 - val_accuracy: 0.7333\n",
      "Epoch 24/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9237 - accuracy: 0.5778 - val_loss: 0.8812 - val_accuracy: 0.7333\n",
      "Epoch 25/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9197 - accuracy: 0.5889 - val_loss: 0.8748 - val_accuracy: 0.7333\n",
      "Epoch 26/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9147 - accuracy: 0.5889 - val_loss: 0.8687 - val_accuracy: 0.7667\n",
      "Epoch 27/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9099 - accuracy: 0.6000 - val_loss: 0.8627 - val_accuracy: 0.7667\n",
      "Epoch 28/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9055 - accuracy: 0.6000 - val_loss: 0.8566 - val_accuracy: 0.7667\n",
      "Epoch 29/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9008 - accuracy: 0.6000 - val_loss: 0.8507 - val_accuracy: 0.7667\n",
      "Epoch 30/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8963 - accuracy: 0.6000 - val_loss: 0.8448 - val_accuracy: 0.8000\n",
      "Epoch 31/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8917 - accuracy: 0.6111 - val_loss: 0.8387 - val_accuracy: 0.8000\n",
      "Epoch 32/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8871 - accuracy: 0.6222 - val_loss: 0.8327 - val_accuracy: 0.8000\n",
      "Epoch 33/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8823 - accuracy: 0.6556 - val_loss: 0.8269 - val_accuracy: 0.8000\n",
      "Epoch 34/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8777 - accuracy: 0.6556 - val_loss: 0.8210 - val_accuracy: 0.8000\n",
      "Epoch 35/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8730 - accuracy: 0.6667 - val_loss: 0.8152 - val_accuracy: 0.8000\n",
      "Epoch 36/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8687 - accuracy: 0.6778 - val_loss: 0.8092 - val_accuracy: 0.8000\n",
      "Epoch 37/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8638 - accuracy: 0.6889 - val_loss: 0.8036 - val_accuracy: 0.8000\n",
      "Epoch 38/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8593 - accuracy: 0.7000 - val_loss: 0.7978 - val_accuracy: 0.8000\n",
      "Epoch 39/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8549 - accuracy: 0.7000 - val_loss: 0.7922 - val_accuracy: 0.8000\n",
      "Epoch 40/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8506 - accuracy: 0.7000 - val_loss: 0.7864 - val_accuracy: 0.8000\n",
      "Epoch 41/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8460 - accuracy: 0.7111 - val_loss: 0.7807 - val_accuracy: 0.8000\n",
      "Epoch 42/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8413 - accuracy: 0.7111 - val_loss: 0.7753 - val_accuracy: 0.8000\n",
      "Epoch 43/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8369 - accuracy: 0.7222 - val_loss: 0.7699 - val_accuracy: 0.8000\n",
      "Epoch 44/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8327 - accuracy: 0.7222 - val_loss: 0.7645 - val_accuracy: 0.8000\n",
      "Epoch 45/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8282 - accuracy: 0.7222 - val_loss: 0.7593 - val_accuracy: 0.7667\n",
      "Epoch 46/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8238 - accuracy: 0.7222 - val_loss: 0.7541 - val_accuracy: 0.7667\n",
      "Epoch 47/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8198 - accuracy: 0.7222 - val_loss: 0.7489 - val_accuracy: 0.7667\n",
      "Epoch 48/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8154 - accuracy: 0.7444 - val_loss: 0.7437 - val_accuracy: 0.7667\n",
      "Epoch 49/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8112 - accuracy: 0.7333 - val_loss: 0.7388 - val_accuracy: 0.7667\n",
      "Epoch 50/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8073 - accuracy: 0.7556 - val_loss: 0.7337 - val_accuracy: 0.7667\n",
      "Epoch 51/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8032 - accuracy: 0.7444 - val_loss: 0.7288 - val_accuracy: 0.7667\n",
      "Epoch 52/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7997 - accuracy: 0.7444 - val_loss: 0.7238 - val_accuracy: 0.8000\n",
      "Epoch 53/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7956 - accuracy: 0.7444 - val_loss: 0.7190 - val_accuracy: 0.8000\n",
      "Epoch 54/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7917 - accuracy: 0.7444 - val_loss: 0.7145 - val_accuracy: 0.8000\n",
      "Epoch 55/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7879 - accuracy: 0.7556 - val_loss: 0.7099 - val_accuracy: 0.7667\n",
      "Epoch 56/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7840 - accuracy: 0.7556 - val_loss: 0.7055 - val_accuracy: 0.7667\n",
      "Epoch 57/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7804 - accuracy: 0.7556 - val_loss: 0.7009 - val_accuracy: 0.8000\n",
      "Epoch 58/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7765 - accuracy: 0.7667 - val_loss: 0.6964 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7729 - accuracy: 0.7778 - val_loss: 0.6921 - val_accuracy: 0.8000\n",
      "Epoch 60/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7692 - accuracy: 0.7778 - val_loss: 0.6878 - val_accuracy: 0.8000\n",
      "Epoch 61/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7656 - accuracy: 0.7778 - val_loss: 0.6836 - val_accuracy: 0.8000\n",
      "Epoch 62/250\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8067 - accuracy: 0.68 - 0s 8ms/step - loss: 0.7620 - accuracy: 0.7778 - val_loss: 0.6797 - val_accuracy: 0.8000\n",
      "Epoch 63/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7584 - accuracy: 0.7778 - val_loss: 0.6757 - val_accuracy: 0.8000\n",
      "Epoch 64/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7548 - accuracy: 0.7778 - val_loss: 0.6719 - val_accuracy: 0.8000\n",
      "Epoch 65/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7514 - accuracy: 0.7778 - val_loss: 0.6681 - val_accuracy: 0.8333\n",
      "Epoch 66/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7480 - accuracy: 0.7778 - val_loss: 0.6643 - val_accuracy: 0.8333\n",
      "Epoch 67/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7446 - accuracy: 0.7778 - val_loss: 0.6605 - val_accuracy: 0.8333\n",
      "Epoch 68/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7411 - accuracy: 0.7778 - val_loss: 0.6570 - val_accuracy: 0.8333\n",
      "Epoch 69/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7378 - accuracy: 0.7778 - val_loss: 0.6533 - val_accuracy: 0.8333\n",
      "Epoch 70/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7345 - accuracy: 0.7778 - val_loss: 0.6500 - val_accuracy: 0.8333\n",
      "Epoch 71/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7312 - accuracy: 0.7778 - val_loss: 0.6465 - val_accuracy: 0.8333\n",
      "Epoch 72/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7280 - accuracy: 0.7889 - val_loss: 0.6430 - val_accuracy: 0.8333\n",
      "Epoch 73/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.7889 - val_loss: 0.6396 - val_accuracy: 0.8333\n",
      "Epoch 74/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7215 - accuracy: 0.7889 - val_loss: 0.6362 - val_accuracy: 0.8667\n",
      "Epoch 75/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7183 - accuracy: 0.8111 - val_loss: 0.6327 - val_accuracy: 0.8667\n",
      "Epoch 76/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7153 - accuracy: 0.8111 - val_loss: 0.6295 - val_accuracy: 0.8667\n",
      "Epoch 77/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7120 - accuracy: 0.8111 - val_loss: 0.6263 - val_accuracy: 0.9000\n",
      "Epoch 78/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7089 - accuracy: 0.8111 - val_loss: 0.6231 - val_accuracy: 0.9000\n",
      "Epoch 79/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7058 - accuracy: 0.8222 - val_loss: 0.6198 - val_accuracy: 0.9000\n",
      "Epoch 80/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7027 - accuracy: 0.8333 - val_loss: 0.6166 - val_accuracy: 0.9000\n",
      "Epoch 81/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6997 - accuracy: 0.8333 - val_loss: 0.6135 - val_accuracy: 0.9333\n",
      "Epoch 82/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6966 - accuracy: 0.8333 - val_loss: 0.6107 - val_accuracy: 0.9333\n",
      "Epoch 83/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.8333 - val_loss: 0.6077 - val_accuracy: 0.9333\n",
      "Epoch 84/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6907 - accuracy: 0.8333 - val_loss: 0.6050 - val_accuracy: 0.9333\n",
      "Epoch 85/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.8333 - val_loss: 0.6021 - val_accuracy: 0.9333\n",
      "Epoch 86/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.8556 - val_loss: 0.5994 - val_accuracy: 0.9333\n",
      "Epoch 87/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.8556 - val_loss: 0.5967 - val_accuracy: 0.9000\n",
      "Epoch 88/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.8556 - val_loss: 0.5942 - val_accuracy: 0.9000\n",
      "Epoch 89/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6763 - accuracy: 0.8556 - val_loss: 0.5916 - val_accuracy: 0.8667\n",
      "Epoch 90/250\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6736 - accuracy: 0.8444 - val_loss: 0.5889 - val_accuracy: 0.8667\n",
      "Epoch 91/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6707 - accuracy: 0.8444 - val_loss: 0.5859 - val_accuracy: 0.8667\n",
      "Epoch 92/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6680 - accuracy: 0.8444 - val_loss: 0.5829 - val_accuracy: 0.8667\n",
      "Epoch 93/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6653 - accuracy: 0.8444 - val_loss: 0.5801 - val_accuracy: 0.8667\n",
      "Epoch 94/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6626 - accuracy: 0.8444 - val_loss: 0.5779 - val_accuracy: 0.8667\n",
      "Epoch 95/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.8444 - val_loss: 0.5754 - val_accuracy: 0.9000\n",
      "Epoch 96/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6573 - accuracy: 0.8556 - val_loss: 0.5728 - val_accuracy: 0.9333\n",
      "Epoch 97/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6547 - accuracy: 0.8667 - val_loss: 0.5700 - val_accuracy: 0.9333\n",
      "Epoch 98/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.8556 - val_loss: 0.5676 - val_accuracy: 0.9333\n",
      "Epoch 99/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6494 - accuracy: 0.8556 - val_loss: 0.5654 - val_accuracy: 0.9333\n",
      "Epoch 100/250\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6468 - accuracy: 0.8556 - val_loss: 0.5635 - val_accuracy: 0.9333\n",
      "Epoch 101/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6443 - accuracy: 0.8667 - val_loss: 0.5612 - val_accuracy: 0.9333\n",
      "Epoch 102/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.8889 - val_loss: 0.5587 - val_accuracy: 0.9333\n",
      "Epoch 103/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6392 - accuracy: 0.8778 - val_loss: 0.5562 - val_accuracy: 0.9333\n",
      "Epoch 104/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6367 - accuracy: 0.8667 - val_loss: 0.5534 - val_accuracy: 0.9333\n",
      "Epoch 105/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6342 - accuracy: 0.8778 - val_loss: 0.5510 - val_accuracy: 0.9333\n",
      "Epoch 106/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6318 - accuracy: 0.8778 - val_loss: 0.5489 - val_accuracy: 0.9333\n",
      "Epoch 107/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6292 - accuracy: 0.8778 - val_loss: 0.5471 - val_accuracy: 0.9333\n",
      "Epoch 108/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6268 - accuracy: 0.8889 - val_loss: 0.5452 - val_accuracy: 0.9333\n",
      "Epoch 109/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6244 - accuracy: 0.8889 - val_loss: 0.5431 - val_accuracy: 0.9333\n",
      "Epoch 110/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6220 - accuracy: 0.8889 - val_loss: 0.5405 - val_accuracy: 0.9333\n",
      "Epoch 111/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6195 - accuracy: 0.8889 - val_loss: 0.5378 - val_accuracy: 0.9333\n",
      "Epoch 112/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6170 - accuracy: 0.8889 - val_loss: 0.5355 - val_accuracy: 0.9333\n",
      "Epoch 113/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6147 - accuracy: 0.8889 - val_loss: 0.5335 - val_accuracy: 0.9333\n",
      "Epoch 114/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.9000 - val_loss: 0.5316 - val_accuracy: 0.9333\n",
      "Epoch 115/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6099 - accuracy: 0.9000 - val_loss: 0.5299 - val_accuracy: 0.9333\n",
      "Epoch 116/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6075 - accuracy: 0.9111 - val_loss: 0.5281 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6052 - accuracy: 0.9111 - val_loss: 0.5259 - val_accuracy: 0.9333\n",
      "Epoch 118/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6029 - accuracy: 0.9111 - val_loss: 0.5235 - val_accuracy: 0.9333\n",
      "Epoch 119/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6005 - accuracy: 0.9111 - val_loss: 0.5209 - val_accuracy: 0.9333\n",
      "Epoch 120/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5982 - accuracy: 0.9111 - val_loss: 0.5188 - val_accuracy: 0.9333\n",
      "Epoch 121/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5958 - accuracy: 0.9111 - val_loss: 0.5169 - val_accuracy: 0.9333\n",
      "Epoch 122/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5935 - accuracy: 0.9111 - val_loss: 0.5151 - val_accuracy: 0.9333\n",
      "Epoch 123/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5911 - accuracy: 0.9111 - val_loss: 0.5132 - val_accuracy: 0.9333\n",
      "Epoch 124/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.9222 - val_loss: 0.5111 - val_accuracy: 0.9333\n",
      "Epoch 125/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5865 - accuracy: 0.9222 - val_loss: 0.5094 - val_accuracy: 0.9333\n",
      "Epoch 126/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.9222 - val_loss: 0.5078 - val_accuracy: 0.9333\n",
      "Epoch 127/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5819 - accuracy: 0.9222 - val_loss: 0.5057 - val_accuracy: 0.9333\n",
      "Epoch 128/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5796 - accuracy: 0.9222 - val_loss: 0.5039 - val_accuracy: 0.9333\n",
      "Epoch 129/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.9111 - val_loss: 0.5020 - val_accuracy: 0.9333\n",
      "Epoch 130/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.9111 - val_loss: 0.5004 - val_accuracy: 0.9333\n",
      "Epoch 131/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5728 - accuracy: 0.9222 - val_loss: 0.4985 - val_accuracy: 0.9333\n",
      "Epoch 132/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5703 - accuracy: 0.9333 - val_loss: 0.4969 - val_accuracy: 0.9333\n",
      "Epoch 133/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5682 - accuracy: 0.9333 - val_loss: 0.4952 - val_accuracy: 0.9333\n",
      "Epoch 134/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.9333 - val_loss: 0.4931 - val_accuracy: 0.9333\n",
      "Epoch 135/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5634 - accuracy: 0.9333 - val_loss: 0.4910 - val_accuracy: 0.9333\n",
      "Epoch 136/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5612 - accuracy: 0.9333 - val_loss: 0.4890 - val_accuracy: 0.9333\n",
      "Epoch 137/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5591 - accuracy: 0.9222 - val_loss: 0.4873 - val_accuracy: 0.9667\n",
      "Epoch 138/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5567 - accuracy: 0.9333 - val_loss: 0.4853 - val_accuracy: 0.9667\n",
      "Epoch 139/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5545 - accuracy: 0.9333 - val_loss: 0.4837 - val_accuracy: 0.9667\n",
      "Epoch 140/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5523 - accuracy: 0.9333 - val_loss: 0.4819 - val_accuracy: 0.9667\n",
      "Epoch 141/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5502 - accuracy: 0.9333 - val_loss: 0.4799 - val_accuracy: 0.9667\n",
      "Epoch 142/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.9333 - val_loss: 0.4782 - val_accuracy: 0.9667\n",
      "Epoch 143/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5457 - accuracy: 0.9333 - val_loss: 0.4768 - val_accuracy: 0.9667\n",
      "Epoch 144/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5433 - accuracy: 0.9333 - val_loss: 0.4747 - val_accuracy: 0.9667\n",
      "Epoch 145/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5412 - accuracy: 0.9333 - val_loss: 0.4726 - val_accuracy: 0.9667\n",
      "Epoch 146/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5390 - accuracy: 0.9333 - val_loss: 0.4707 - val_accuracy: 0.9667\n",
      "Epoch 147/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5368 - accuracy: 0.9333 - val_loss: 0.4691 - val_accuracy: 0.9667\n",
      "Epoch 148/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5347 - accuracy: 0.9333 - val_loss: 0.4675 - val_accuracy: 0.9667\n",
      "Epoch 149/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5323 - accuracy: 0.9444 - val_loss: 0.4656 - val_accuracy: 0.9667\n",
      "Epoch 150/250\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.90 - 0s 10ms/step - loss: 0.5301 - accuracy: 0.9444 - val_loss: 0.4636 - val_accuracy: 0.9667\n",
      "Epoch 151/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5279 - accuracy: 0.9444 - val_loss: 0.4611 - val_accuracy: 0.9667\n",
      "Epoch 152/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5260 - accuracy: 0.9444 - val_loss: 0.4591 - val_accuracy: 0.9667\n",
      "Epoch 153/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5241 - accuracy: 0.9444 - val_loss: 0.4579 - val_accuracy: 0.9667\n",
      "Epoch 154/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5214 - accuracy: 0.9444 - val_loss: 0.4565 - val_accuracy: 0.9667\n",
      "Epoch 155/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.9444 - val_loss: 0.4553 - val_accuracy: 0.9667\n",
      "Epoch 156/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.9444 - val_loss: 0.4539 - val_accuracy: 0.9667\n",
      "Epoch 157/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.9444 - val_loss: 0.4524 - val_accuracy: 0.9667\n",
      "Epoch 158/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.9444 - val_loss: 0.4504 - val_accuracy: 0.9667\n",
      "Epoch 159/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.9444 - val_loss: 0.4480 - val_accuracy: 0.9667\n",
      "Epoch 160/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5083 - accuracy: 0.9444 - val_loss: 0.4457 - val_accuracy: 0.9667\n",
      "Epoch 161/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5062 - accuracy: 0.9444 - val_loss: 0.4439 - val_accuracy: 0.9667\n",
      "Epoch 162/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.9444 - val_loss: 0.4419 - val_accuracy: 0.9667\n",
      "Epoch 163/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.9444 - val_loss: 0.4396 - val_accuracy: 0.9667\n",
      "Epoch 164/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.9444 - val_loss: 0.4382 - val_accuracy: 0.9667\n",
      "Epoch 165/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4974 - accuracy: 0.9444 - val_loss: 0.4371 - val_accuracy: 0.9667\n",
      "Epoch 166/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4952 - accuracy: 0.9444 - val_loss: 0.4359 - val_accuracy: 0.9667\n",
      "Epoch 167/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4930 - accuracy: 0.9444 - val_loss: 0.4346 - val_accuracy: 0.9667\n",
      "Epoch 168/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4909 - accuracy: 0.9444 - val_loss: 0.4331 - val_accuracy: 0.9667\n",
      "Epoch 169/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4891 - accuracy: 0.9444 - val_loss: 0.4315 - val_accuracy: 0.9667\n",
      "Epoch 170/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4871 - accuracy: 0.9444 - val_loss: 0.4294 - val_accuracy: 0.9667\n",
      "Epoch 171/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4845 - accuracy: 0.9556 - val_loss: 0.4271 - val_accuracy: 0.9667\n",
      "Epoch 172/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4826 - accuracy: 0.9556 - val_loss: 0.4251 - val_accuracy: 0.9667\n",
      "Epoch 173/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4802 - accuracy: 0.9556 - val_loss: 0.4240 - val_accuracy: 0.9667\n",
      "Epoch 174/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4780 - accuracy: 0.9556 - val_loss: 0.4227 - val_accuracy: 0.9667\n",
      "Epoch 175/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4762 - accuracy: 0.9556 - val_loss: 0.4207 - val_accuracy: 0.9667\n",
      "Epoch 176/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4738 - accuracy: 0.9556 - val_loss: 0.4190 - val_accuracy: 0.9667\n",
      "Epoch 177/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4717 - accuracy: 0.9556 - val_loss: 0.4174 - val_accuracy: 0.9667\n",
      "Epoch 178/250\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4698 - accuracy: 0.9556 - val_loss: 0.4151 - val_accuracy: 0.9667\n",
      "Epoch 179/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4674 - accuracy: 0.9556 - val_loss: 0.4131 - val_accuracy: 0.9667\n",
      "Epoch 180/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.9556 - val_loss: 0.4107 - val_accuracy: 0.9667\n",
      "Epoch 181/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4630 - accuracy: 0.9556 - val_loss: 0.4085 - val_accuracy: 0.9667\n",
      "Epoch 182/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4611 - accuracy: 0.9556 - val_loss: 0.4066 - val_accuracy: 0.9667\n",
      "Epoch 183/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.9444 - val_loss: 0.4049 - val_accuracy: 0.9667\n",
      "Epoch 184/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4569 - accuracy: 0.9444 - val_loss: 0.4033 - val_accuracy: 0.9667\n",
      "Epoch 185/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.9444 - val_loss: 0.4018 - val_accuracy: 0.9667\n",
      "Epoch 186/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4527 - accuracy: 0.9444 - val_loss: 0.4004 - val_accuracy: 0.9667\n",
      "Epoch 187/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.9556 - val_loss: 0.3983 - val_accuracy: 0.9667\n",
      "Epoch 188/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.9556 - val_loss: 0.3961 - val_accuracy: 0.9667\n",
      "Epoch 189/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.9667 - val_loss: 0.3941 - val_accuracy: 0.9667\n",
      "Epoch 190/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.9667 - val_loss: 0.3928 - val_accuracy: 0.9667\n",
      "Epoch 191/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.9556 - val_loss: 0.3912 - val_accuracy: 0.9667\n",
      "Epoch 192/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.9556 - val_loss: 0.3894 - val_accuracy: 0.9667\n",
      "Epoch 193/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4384 - accuracy: 0.9667 - val_loss: 0.3873 - val_accuracy: 0.9667\n",
      "Epoch 194/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.9667 - val_loss: 0.3853 - val_accuracy: 0.9667\n",
      "Epoch 195/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4341 - accuracy: 0.9667 - val_loss: 0.3837 - val_accuracy: 0.9667\n",
      "Epoch 196/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.9667 - val_loss: 0.3820 - val_accuracy: 0.9667\n",
      "Epoch 197/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4301 - accuracy: 0.9667 - val_loss: 0.3803 - val_accuracy: 0.9667\n",
      "Epoch 198/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.9667 - val_loss: 0.3784 - val_accuracy: 0.9667\n",
      "Epoch 199/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.9667 - val_loss: 0.3760 - val_accuracy: 0.9667\n",
      "Epoch 200/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.9667 - val_loss: 0.3742 - val_accuracy: 0.9667\n",
      "Epoch 201/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.9667 - val_loss: 0.3732 - val_accuracy: 0.9667\n",
      "Epoch 202/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.9667 - val_loss: 0.3704 - val_accuracy: 0.9667\n",
      "Epoch 203/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4182 - accuracy: 0.9667 - val_loss: 0.3687 - val_accuracy: 0.9667\n",
      "Epoch 204/250\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.9667 - val_loss: 0.3668 - val_accuracy: 0.9667\n",
      "Epoch 205/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4143 - accuracy: 0.9667 - val_loss: 0.3652 - val_accuracy: 0.9667\n",
      "Epoch 206/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.9667 - val_loss: 0.3636 - val_accuracy: 0.9667\n",
      "Epoch 207/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4103 - accuracy: 0.9667 - val_loss: 0.3617 - val_accuracy: 0.9667\n",
      "Epoch 208/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4085 - accuracy: 0.9667 - val_loss: 0.3599 - val_accuracy: 0.9667\n",
      "Epoch 209/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4066 - accuracy: 0.9667 - val_loss: 0.3583 - val_accuracy: 0.9667\n",
      "Epoch 210/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4045 - accuracy: 0.9667 - val_loss: 0.3568 - val_accuracy: 0.9667\n",
      "Epoch 211/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4026 - accuracy: 0.9667 - val_loss: 0.3551 - val_accuracy: 0.9667\n",
      "Epoch 212/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4008 - accuracy: 0.9667 - val_loss: 0.3534 - val_accuracy: 0.9667\n",
      "Epoch 213/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3995 - accuracy: 0.9667 - val_loss: 0.3513 - val_accuracy: 0.9667\n",
      "Epoch 214/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.9667 - val_loss: 0.3498 - val_accuracy: 0.9667\n",
      "Epoch 215/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.9667 - val_loss: 0.3478 - val_accuracy: 0.9667\n",
      "Epoch 216/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3933 - accuracy: 0.9667 - val_loss: 0.3458 - val_accuracy: 0.9667\n",
      "Epoch 217/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.9667 - val_loss: 0.3441 - val_accuracy: 0.9667\n",
      "Epoch 218/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3897 - accuracy: 0.9667 - val_loss: 0.3427 - val_accuracy: 0.9667\n",
      "Epoch 219/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.9667 - val_loss: 0.3417 - val_accuracy: 0.9667\n",
      "Epoch 220/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3858 - accuracy: 0.9667 - val_loss: 0.3400 - val_accuracy: 0.9667\n",
      "Epoch 221/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3840 - accuracy: 0.9667 - val_loss: 0.3384 - val_accuracy: 0.9667\n",
      "Epoch 222/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3822 - accuracy: 0.9667 - val_loss: 0.3365 - val_accuracy: 0.9667\n",
      "Epoch 223/250\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3803 - accuracy: 0.9667 - val_loss: 0.3346 - val_accuracy: 0.9667\n",
      "Epoch 224/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3787 - accuracy: 0.9667 - val_loss: 0.3326 - val_accuracy: 0.9667\n",
      "Epoch 225/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3769 - accuracy: 0.9667 - val_loss: 0.3308 - val_accuracy: 0.9667\n",
      "Epoch 226/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3752 - accuracy: 0.9667 - val_loss: 0.3297 - val_accuracy: 0.9667\n",
      "Epoch 227/250\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3733 - accuracy: 0.9667 - val_loss: 0.3281 - val_accuracy: 0.9667\n",
      "Epoch 228/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3715 - accuracy: 0.9667 - val_loss: 0.3263 - val_accuracy: 0.9667\n",
      "Epoch 229/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3701 - accuracy: 0.9667 - val_loss: 0.3242 - val_accuracy: 0.9667\n",
      "Epoch 230/250\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3679 - accuracy: 0.9667 - val_loss: 0.3227 - val_accuracy: 0.9667\n",
      "Epoch 231/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3662 - accuracy: 0.9667 - val_loss: 0.3215 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3644 - accuracy: 0.9667 - val_loss: 0.3198 - val_accuracy: 0.9667\n",
      "Epoch 233/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3628 - accuracy: 0.9667 - val_loss: 0.3181 - val_accuracy: 0.9667\n",
      "Epoch 234/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3611 - accuracy: 0.9667 - val_loss: 0.3162 - val_accuracy: 0.9667\n",
      "Epoch 235/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3592 - accuracy: 0.9667 - val_loss: 0.3145 - val_accuracy: 0.9667\n",
      "Epoch 236/250\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3574 - accuracy: 0.9667 - val_loss: 0.3131 - val_accuracy: 0.9667\n",
      "Epoch 237/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3557 - accuracy: 0.9667 - val_loss: 0.3122 - val_accuracy: 0.9667\n",
      "Epoch 238/250\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3541 - accuracy: 0.9667 - val_loss: 0.3111 - val_accuracy: 0.9667\n",
      "Epoch 239/250\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3527 - accuracy: 0.9667 - val_loss: 0.3115 - val_accuracy: 0.9667\n",
      "Epoch 240/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3508 - accuracy: 0.9667 - val_loss: 0.3106 - val_accuracy: 0.9667\n",
      "Epoch 241/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.9667 - val_loss: 0.3091 - val_accuracy: 0.9667\n",
      "Epoch 242/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3472 - accuracy: 0.9667 - val_loss: 0.3070 - val_accuracy: 0.9667\n",
      "Epoch 243/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.9667 - val_loss: 0.3048 - val_accuracy: 0.9667\n",
      "Epoch 244/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3439 - accuracy: 0.9667 - val_loss: 0.3031 - val_accuracy: 0.9667\n",
      "Epoch 245/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3423 - accuracy: 0.9667 - val_loss: 0.3008 - val_accuracy: 0.9667\n",
      "Epoch 246/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3409 - accuracy: 0.9667 - val_loss: 0.2988 - val_accuracy: 0.9667\n",
      "Epoch 247/250\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3390 - accuracy: 0.9667 - val_loss: 0.2977 - val_accuracy: 0.9667\n",
      "Epoch 248/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3375 - accuracy: 0.9667 - val_loss: 0.2975 - val_accuracy: 0.9667\n",
      "Epoch 249/250\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.9667 - val_loss: 0.2962 - val_accuracy: 0.9667\n",
      "Epoch 250/250\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3344 - accuracy: 0.9667 - val_loss: 0.2973 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "history = model9.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=250,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "GN3tD9Y_Mw0v"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "uhrlBTvsNsci"
   },
   "outputs": [],
   "source": [
    "model9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oBNA2xSMxQ2",
    "outputId": "4c479818-833f-4bd4-8d3e-4980d612e8ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2555 - accuracy: 0.9667 - val_loss: 0.2191 - val_accuracy: 0.9667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2543 - accuracy: 0.9667 - val_loss: 0.2181 - val_accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2533 - accuracy: 0.9667 - val_loss: 0.2171 - val_accuracy: 0.9667\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2519 - accuracy: 0.9667 - val_loss: 0.2177 - val_accuracy: 0.9667\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2507 - accuracy: 0.9667 - val_loss: 0.2174 - val_accuracy: 0.9667\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2496 - accuracy: 0.9667 - val_loss: 0.2165 - val_accuracy: 0.9667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2483 - accuracy: 0.9667 - val_loss: 0.2143 - val_accuracy: 0.9667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2470 - accuracy: 0.9667 - val_loss: 0.2122 - val_accuracy: 0.9667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2460 - accuracy: 0.9667 - val_loss: 0.2097 - val_accuracy: 0.9667\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2447 - accuracy: 0.9667 - val_loss: 0.2080 - val_accuracy: 0.9667\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.9667 - val_loss: 0.2067 - val_accuracy: 0.9667\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2424 - accuracy: 0.9667 - val_loss: 0.2064 - val_accuracy: 0.9667\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2413 - accuracy: 0.9667 - val_loss: 0.2055 - val_accuracy: 0.9667\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9667 - val_loss: 0.2052 - val_accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2390 - accuracy: 0.9667 - val_loss: 0.2048 - val_accuracy: 0.9667\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2378 - accuracy: 0.9667 - val_loss: 0.2031 - val_accuracy: 0.9667\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2370 - accuracy: 0.9667 - val_loss: 0.2022 - val_accuracy: 0.9667\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2357 - accuracy: 0.9667 - val_loss: 0.2000 - val_accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2346 - accuracy: 0.9667 - val_loss: 0.1985 - val_accuracy: 0.9667\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2334 - accuracy: 0.9667 - val_loss: 0.1981 - val_accuracy: 0.9667\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2324 - accuracy: 0.9667 - val_loss: 0.1971 - val_accuracy: 0.9667\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2313 - accuracy: 0.9667 - val_loss: 0.1961 - val_accuracy: 0.9667\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2303 - accuracy: 0.9667 - val_loss: 0.1952 - val_accuracy: 0.9667\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2293 - accuracy: 0.9667 - val_loss: 0.1946 - val_accuracy: 0.9667\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2283 - accuracy: 0.9667 - val_loss: 0.1937 - val_accuracy: 0.9667\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2272 - accuracy: 0.9667 - val_loss: 0.1924 - val_accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2261 - accuracy: 0.9667 - val_loss: 0.1901 - val_accuracy: 0.9667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2253 - accuracy: 0.9667 - val_loss: 0.1880 - val_accuracy: 0.9667\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2242 - accuracy: 0.9667 - val_loss: 0.1863 - val_accuracy: 0.9667\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2232 - accuracy: 0.9667 - val_loss: 0.1859 - val_accuracy: 0.9667\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2223 - accuracy: 0.9667 - val_loss: 0.1861 - val_accuracy: 0.9667\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2213 - accuracy: 0.9667 - val_loss: 0.1859 - val_accuracy: 0.9667\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2202 - accuracy: 0.9667 - val_loss: 0.1845 - val_accuracy: 0.9667\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2193 - accuracy: 0.9667 - val_loss: 0.1841 - val_accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2183 - accuracy: 0.9667 - val_loss: 0.1825 - val_accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2173 - accuracy: 0.9667 - val_loss: 0.1814 - val_accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2164 - accuracy: 0.9667 - val_loss: 0.1802 - val_accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2156 - accuracy: 0.9667 - val_loss: 0.1782 - val_accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2145 - accuracy: 0.9667 - val_loss: 0.1772 - val_accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2140 - accuracy: 0.9667 - val_loss: 0.1776 - val_accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2129 - accuracy: 0.9667 - val_loss: 0.1759 - val_accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2120 - accuracy: 0.9667 - val_loss: 0.1763 - val_accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2110 - accuracy: 0.9667 - val_loss: 0.1755 - val_accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2106 - accuracy: 0.9667 - val_loss: 0.1735 - val_accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2092 - accuracy: 0.9667 - val_loss: 0.1733 - val_accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2084 - accuracy: 0.9667 - val_loss: 0.1734 - val_accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2075 - accuracy: 0.9667 - val_loss: 0.1720 - val_accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2067 - accuracy: 0.9667 - val_loss: 0.1700 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2058 - accuracy: 0.9667 - val_loss: 0.1688 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2051 - accuracy: 0.9667 - val_loss: 0.1692 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\" #File name includes epoch and validation accuracy.\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "log_csv = CSVLogger('my_logs.csv', separator=',', append=False)\n",
    "\n",
    "callbacks_list = [early_stop, log_csv]\n",
    "history = model9.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iztEijufiaVz",
    "outputId": "99d9ae5f-49f0-4a93-8234-2be740c309e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1531 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1531112790107727, 0.9666666388511658]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model9.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "f1IaRs0_i0ec"
   },
   "outputs": [],
   "source": [
    "t1= X_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPf1Zwysm0FK",
    "outputId": "3f781375-5480-4663-cdd6-7014fd63671e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "73            6.1          2.8           4.7          1.2\n",
      "31            5.4          3.4           1.5          0.4\n",
      "51            6.4          3.2           4.5          1.5\n",
      "81            5.5          2.4           3.7          1.0\n",
      "9             4.9          3.1           1.5          0.1\n",
      "122           7.7          2.8           6.7          2.0\n",
      "11            4.8          3.4           1.6          0.2\n",
      "75            6.6          3.0           4.4          1.4\n",
      "36            5.5          3.5           1.3          0.2\n",
      "40            5.0          3.5           1.3          0.3\n",
      "133           6.3          2.8           5.1          1.5\n",
      "96            5.7          2.9           4.2          1.3\n",
      "15            5.7          4.4           1.5          0.4\n",
      "78            6.0          2.9           4.5          1.5\n",
      "66            5.6          3.0           4.5          1.5\n",
      "69            5.6          2.5           3.9          1.1\n",
      "68            6.2          2.2           4.5          1.5\n",
      "64            5.6          2.9           3.6          1.3\n",
      "142           5.8          2.7           5.1          1.9\n",
      "76            6.8          2.8           4.8          1.4 [[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(t1, y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "_UxosatPm0ln"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction = np.round(model9.predict(t1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-luOLNrnACP",
    "outputId": "f33a04e0-a8ec-4a7a-917d-0b41ba5bd29a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIOTtCpVnu1o",
    "outputId": "9dc0059d-3150-41bd-f474-2a68b24c0008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06 0.84 0.1 ] [0. 1. 0.]\n",
      "[0.98 0.02 0.  ] [1. 0. 0.]\n",
      "[0.1  0.89 0.01] [0. 1. 0.]\n",
      "[0.15 0.85 0.  ] [0. 1. 0.]\n",
      "[0.97 0.03 0.  ] [1. 0. 0.]\n",
      "[0.01 0.18 0.81] [0. 0. 1.]\n",
      "[0.96 0.04 0.  ] [1. 0. 0.]\n",
      "[0.17 0.83 0.  ] [0. 1. 0.]\n",
      "[0.99 0.01 0.  ] [1. 0. 0.]\n",
      "[0.98 0.02 0.  ] [1. 0. 0.]\n",
      "[0.02 0.39 0.59] [0. 0. 1.]\n",
      "[0.07 0.89 0.04] [0. 1. 0.]\n",
      "[0.99 0.01 0.  ] [1. 0. 0.]\n",
      "[0.06 0.82 0.12] [0. 1. 0.]\n",
      "[0.02 0.44 0.54] [0. 1. 0.]\n",
      "[0.11 0.88 0.01] [0. 1. 0.]\n",
      "[0.07 0.86 0.08] [0. 1. 0.]\n",
      "[0.17 0.83 0.  ] [0. 1. 0.]\n",
      "[0.01 0.18 0.81] [0. 0. 1.]\n",
      "[0.1  0.89 0.01] [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "  print(prediction[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "D94LPz83oTc6"
   },
   "outputs": [],
   "source": [
    "# Try this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "ZsaTwNuzpIdf",
    "outputId": "60d9b539-a11d-4442-9745-a532e5a08004"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'val loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhQ2VGuLpMFQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
